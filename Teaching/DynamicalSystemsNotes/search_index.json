[["index.html", "MT4508: Dynamical Systems (Revision Notes) Module Handbook Structure Logistics Assessment Student Support Acknowledgements", " MT4508: Dynamical Systems (Revision Notes) F. Olukoya 18 April 2022 Module Handbook Welcome to MT4508: Dynamical Systems. In this module you will study dynamical systems. A dynamical system consists of a set of possible states and a rule that determines the present state based on past states. The module is split into two parts based on the two types of dynamical systems we will encounter: discrete and continuous dynamical systems. The aim is largely applied: we will look at techniques that help us understand long term behaviours of the dynamical system, particularly stability and chaos. Our discussion will mainly be motivated by a selection of hands-on examples which model dynamics of interest. In this sense the module is more practical than theoretical— the emphasis will be on applying techniques to examples with brief indications of why the techniques should be expected to work more generally. Structure The module follows closely the book Chaos - An introduction to Dynamical systems (Alligood, Sauer, and Yorke 2000) as such we have indicated below the Chapters/Sections of the book that will be covered in each week of the semester. The module is comprised of the following parts: Introduction to dynamical systems (covers Chapter 1 from Section 1.1 to Section 1.3). Periodic points and stability (covers Section 1.4 of Chapter 1 up to Section 2.5 Definition 2.12 of Chapter 2). Higher-dimensional dynamics (covers Chapter 2 Section 2.5 Example 2.13 to Section 2.6 Example 2.20 of Chapter 2). Higher-dimensional stability (covers Chapter 3 Sections 3.1 and 3.2 and Chapter 4 Sections 4.1 to 4.4). Fractals (covers Chapter 4 from Section 4.5 to Definition 5.1 of Chapter 5). Chaos in Higher Dimensions (covers Chapter 5 Sections 5.1 and 5.6 up; Chapter 6 Sections 6.1 and 6.2; Chapter 7 Section 7.1). Equilibria and stability in continuous time dynamical systems (covers Chapter 7 Sections 7.2 to 7.5). Lyapunov Functions (covers Chapter 7 Section 7.6 to Chapter 8 Section 8.1 (Theorem 8.3)). Limit sets in 2-dimensions (covers Chapter 8 Section 8.1 and 8.2 and Sections 9.1 and 9.2 of Chapter 9). Lorenz chaos and bifurcation (Covers Chapter 11 Sections 11.1 and 11.2). Prerequisites MT3504 Lecture notes and bibliography The lecture note are based on the following text (Alligood, Sauer, and Yorke 2000) Alligood, Sauer, Yorke, Chaos - An introduction to Dynamical systems, Springer 200. There are hard and electronic copies available from the University library; Other recommended texts: Ott, Chaos in Dynamical SYstems, Cambridge UP, 1993 (2nd Edition 2002) Strogatz, Nonlinear Dynamics and Chaos, Westview Press, 2000 Baker and Gollub, Chaotic Dynamics- An Introduction, Cambridge UP, 1990 (2nd edition 1996) Drazin, Nonlinear Systems, Cambridge UP, 1992 Guckenheimer and Holmes, Nonlinear Oscillations, Dynamical Systems and Bifurcations of Vetcor Fields, Springer 1983. Logistics Lectures The module runs in Semester 2 with 2.5 lectures each week: 3 in even weeks (Monday, Tuesday and Thursday) and 2 in odd weeks (Tuesday and Thursday). In weeks 1-5, Lectures will be delivered live online at 10am on Monday (even weeks), Tuesday and Thursday; in weeks 6-11 Lectures will be delivered in person in Maths Lecture Theatre C and livestreamed over teams. A recording of each lecture with be made available on Panopto after the class. Table 0.2 sets out a timetable for the semester. If you have any questions while going through the content then do email me fo55@st-andrews.ac.uk. I am more than happy to arrange a meeting over teams or in person. Lecturers This semester Dr. Feyisayo (Shayo) Olukoya will be the sole lecturer on the module. As mentioned above you can reach me by email; you should also feel free to arrange an in-person meeting my office is Room 217 in the mathematics building; meeting virtually over teams is also an option. Tutorials Starting in Week 2 there will be one tutorial per week. There are 2 groups; you will need to sign up. Table 0.1: Tutorial groups Group 1 Tuesday 13:00 Maths Lecture Theatre B Group 2 Thursday 13:00 Maths Lecture Theatre B (Livestreamed &amp; recorded) Tutorial sheets will be uploaded on Moodle the week before the relevant tutorial and solutions will appear on Moodle on Friday at 17:00 the week after. If you are unable to make it in-person to a tutorial then do join in the Thursday tutorial which will be live-streamed on Teams (the Thursday tutorial will also be recorded with the recording made available via Moodle after the class). The Tuesday tutorial is an in-person only class, it will not be recorded or livestreamed. Moodle All resources for the module (lecture notes, problem sheets, solutions e.t.c) will be made available on moodle at the appropriate time. Scheduling Table 0.2 displays the schedule for the semester. The key below explains what all the symbols mean. Table 0.2: Timetable Week Beginning Week Mon Tue Wed Thu Fri 17 Jan 1 L L 24 2 Tut L L L 31 3 Tut L L 7 Feb 4 Tut L L L 14 5 Tut L L 21 Vacation 28 6 Tut L L L 7 Mar 7 Tut L Reading Party 14 8 Tut L L L 21 9 Tut L L 28 10 Tut L L L 4 Apr 11 Tut L 11 Revision L = Lecture (10am on Teams &amp; in-person in Weeks 6 - 11 in Maths Lecture Theatre C) Tut = Tutorial (In-person) Reading party: Honours reading party; Thursday lecture and tutorial cancelled. Assessment The module is assessed entirely by a final exam. 90% Rule You must complete 90% of assessment in a module to have the opportunity to gain credit in the module. If you do not complete at least 90% of assessment, you will be given a FINAL academic alert in the module and receive a grade 0X. In MT4508, this only applies if you fail to sit the final exam. Student Support For advice on any non-academic issue (including financial, international, personal or health matters) or if you are unsure who to go to for help, please contact the Advice and Support Centre. You can drop-in on 79 North Street, phone 01334 462020 or email theasc@st-andrews.ac.uk. You can also contact the school’s well-being officer by email at tdhc@st-andrews.ac.uk. Acknowledgements I would like to thank Seonaid McCormack, Aidan Lau, Antonia Eder and Emilie Bone for their comments that have helped to improve these notes. References "],["intro.html", "Chapter 1 Introduction 1.1 What is a “Dynamical System”? 1.2 Cobweb Plots 1.3 Problem Sheet 1", " Chapter 1 Introduction Covers up to and including Section 1.3 of Chapter 1 (Alligood, Sauer, and Yorke 2000). 1.1 What is a “Dynamical System”? Definition 1.1 A dynamical system consists of a set of possible states, together with a rule that determines the present state in terms of past states. Example 1.1 Let us assume that \\(t\\) denotes time. The set of states is the set of real numbers \\(\\R\\). The rule is given by a differential equation. For example, something of the form: \\[ \\frac{\\d u}{ \\d t} = F(u)\\] where \\(F: \\R \\to \\R\\) is a function. Time \\(t\\) is called a continuous parameter in this system and such a system is called a continuous time dynamical system. Our set of states is again the set of real numbers \\(\\R\\). Our rule is as follows: \\[x_{n} = f(x_{n-1})\\] where \\(f: \\R \\to \\R\\) is a function and \\(n \\in \\N\\). The index \\(n\\) takes the role of \\(t\\) in 1. above. Note that this is a discrete parameter. Such a dynamical system is therefore called a discrete time dynamical system. Figure 1.1: Continuous and Discrete dynamical systems Initially, we will consider discrete time dynamical systems as they are simpler to study. We will then consider continuous time dynamical system. All dynamical systems in the course will have the following property: the present state is uniquely determined by past states. Dynamical systems with this property are called deterministic. More generally, we have random or stochastic processes where the current state is stochastically determined from past states e.g. by flipping a coin or rolling a die. We will not be studying these. We begin out study of discrete time dynamical systems with one-dimensional maps. 1.1.1 One-dimensional (1D) maps First, the definition of a map. Definition 1.2 A function whose domain (input) space and range (output) space are the same, is called a map. A 1D-map is a map with domain space (and so range space) equal to a subset of \\(\\R\\). Note In this module, unless explicitly stated otherwise, all functions will be differentiable infinitely often (so-called smooth functions). Example 1.2 Consider the 1D-map \\[f: \\R \\to \\R, \\ x \\mapsto 2x.\\] This gives rise to a discrete time dynamical system: \\[ x_n = 2x_{n-1}.\\] We can imagine that this models how a population of bacteria grows with time. At some initial time, \\(1\\), we have an initial population \\(x_1\\) of bacteria; at each time step (say hourly intervals), the population of bacteria is twice the population at the previous time step. In general, so long as we know the value of the initial population, \\(x_1\\), we can calculate the population at all later times by successively applying the map \\(f\\). For instance: \\[\\begin{align*} x_2 &amp;= f(x_1) = 2x_1, \\\\ x_3 &amp;= f(x_2) = f(f(x_1)) = f^2(x_1) = 4 x_1 \\\\ &amp;\\ \\ \\vdots \\\\ x_n &amp;= f(x_{n-1}) = f^2(x_{n-2}) = f^{n-1}(x_1) = 2^{n-1} x_1 \\end{align*}\\] As can be seen, in this discerete time dynamical system, the population will grow without bound. This type of growth, in which the population is multiplied by a constant factor at each time step (\\(2\\) in this example) is called exponential growth. Example 1.2 is rather unphysical since in reality population growth is limited (e.g by a finite food supply). Perhaps we can find a better model by introducing to a term to account for increased competition for resources. Example 1.3 (The logistic map) Define a map \\(g: [0,1] \\to [0,1]\\) by \\(g(x) = 2x(1-x)\\). We have a corresponding discrete time dynamical system \\[x_n = g(x_{n-1}) = 2x_{n-1}(1-x_{n-1}).\\] We consider the behaviour of \\(g\\) in two different regimes: for \\(x\\) very small, \\(g(x) = 2x (1- x) \\simeq 2x\\) for \\(x\\) very close to but strictly less than \\(1\\), \\(g(x) = 2x (1-x) \\simeq 2(1-x) &lt; 1\\). We see that for small \\(x\\) we have a similar doubling behaviour as in Example 1.2, however, for large \\(x\\) the population begins to decrease. This new behaviour is due to the non-linear dependence of \\(g\\) in \\(x\\). It is an extremely important ingredient for the rich behaviour of all dynamical systems. 1.1.2 Orbits and fixed points We introduce some properties of maps. Definition 1.3 Let \\(f\\) be a map and \\(x\\) a point in the domain space of \\(f\\). The orbit of \\(x\\) under \\(f\\) is the set \\[\\{ x, f(x), f^2(x), f^3(x), \\ldots\\}\\] of iterates of \\(x\\) under \\(f\\). The starting point \\(x\\) of the orbit is called the initial value of the orbit. A point \\(p\\) in the domain space of \\(f\\) is called a fixed point of \\(f\\) if its orbit has size \\(1\\), that is \\(f(p) = p\\). Let us compute the orbit of a generic point \\(x_0 \\in [0,1]\\) under the logistic map of Example 1.3: \\[\\begin{align*} &amp;n=1, \\quad x_1 = 2(1-x_0)x_0 \\\\ &amp;n=2, \\quad x_2 = 2(1-x_1) x_1 = 2(1- 2(1-x_0)x_0) \\cdot 2(1-x_0)x_0 \\\\ &amp;n=3, \\quad x_3 = 2(1-x_2)x_2 = \\ldots \\\\ &amp; \\ \\ \\ \\ \\ \\vdots \\end{align*}\\] One might hope that such an orbit will approach a specific value. We can perform some computational experiments. Figure 1.2: Computational experiments Code Challenge The code for the plot is shown below. Do experiment with the code by changing the parameter and initial value. Are you able to write a more efficient code? Show Python Code Python Code # Logistic map x_(n+1) = a*x_n*(1.0-x_n) # simple orbit plotting # Change parameter 0&lt; a &lt;= 4.0 to get # different types of orbits from numpy import * from matplotlib.pyplot import * a = 2 # set logistic map parameter (between 0.0 and 4.0) # single non-zero stable fixed point for 1.0 &lt;a &lt; 3.0 # stable period-2 orbit for 3.0 &lt; a &lt; 1 + sqrt(6) = 3.45 #**************************************************** # define a function for the RHS of the logistic map def log_map(x): return a*x*(1.0-x) #**************************************************** x01 = 0.1 # set first initial condition (between 0 and 1) x02 = 0.9 # set second initial condition (between 0 and 1) nmax = 30 # set maximum number of iterations # generate the lists etc for plotting n = linspace(0,nmax,nmax+1) x1 = zeros(len(n)) x2 = zeros(len(n)) # assign initial conditions to first #coordinates x1[0] = x01 x2[0] = x02 # calculate next i points in orbit for i in range(1,nmax+1,1): x1[i] = log_map(x1[i-1]) x2[i] = log_map(x2[i-1]) # the plot commands next, with axes labels etc # plot first orbit with red circles scatter(n,x1, facecolors=&quot;none&quot;,edgecolors=&#39;r&#39;,\\ label = &#39;Intial value %.2f&#39; % (x01)) # overplot a second orbit in blue scatter(n,x2,facecolors=&quot;none&quot;,edgecolors=&#39;b&#39;,\\ label=&#39;Intial value %.2f&#39; % (x02)) # title of plot title(&#39;Logistic map with a = %.2f&#39; % (a)) #label axes xlabel(&#39;n&#39;) ylabel(&#39;x&#39;) # x-y range of plot axis([-1, nmax+1, -0.0, 1.0]) # show legend legend() # show the plot show() R variant The same graph can be plotted in R, although we will mainly use python for our computational experiments in this module. Show R code R code logistic.map&lt;- function(r, x, N, M){ # r: logistic map parameter # x: initial value # N: number of iterations # M: number of iteration points to be returned z &lt;- 1:N z[1] &lt;- x for (i in c(1:(N-1))){ z[i+1] &lt;- r*z[i] * (1 - z[i]) } # Return last M iterations z[c((N-M):N)] } my.r&lt;- 2 #value of logistic parameter x_1&lt;- 0.1 #first initial value x_2&lt;- 0.9 #second initial value x.axis&lt;- seq(1, 30) #points on x axis #compute orbits of first initial value Orbit_1 &lt;- logistic.map(my.r, x_1, N=30, M=30) #compute orbits of second intial value Orbit_2 &lt;- logistic.map(my.r, x_2, N=30, M=30) plot(Orbit_1~x.axis, pch=1, col=&quot;red&quot;, ylab=&quot;x&quot;, xlab=&quot;n&quot;, ylim = c(0,1.0), main=paste(&quot;Logistic map with a = &quot;, my.r, sep=&quot;&quot;)) #plot second orbit points(Orbit_2~x.axis, col=&quot;blue&quot;) #add first orbit to plot legend(&quot;topright&quot;, c(paste(&quot;x_1=&quot;,x_1, sep=&quot;&quot;), paste(&quot;x_1=&quot;,x_2, sep=&quot;&quot;)), fill=c(&quot;blue&quot;,&quot;red&quot;)) Figures 1.2 above shows the orbits under the logistic map with initial values \\(0.1\\) and \\(0.9\\) respectively. We see that the orbits converge towards the value \\(x =1/2\\), that is \\(\\lim_{n \\to \\infty} f^{n}(x_0) = 1/2\\). The point \\(1/2\\) is in fact a fixed point of the discrete time dynamical system corresponding to the logistic map. We can explicitly compute the fixed points of the logistic map by solving the equation \\(g(p) = 2(1-p)p = p\\). This gives rise to the quadratic \\[ 2p^2 -p = 0\\] which has solutions \\(p = 0\\) and \\(p = 1/2\\). It is in fact the case that for all initial values (except 0 and 1 which converge to \\(0\\)), the system converges to the fixed point at \\(x= 1/2\\). (The reader is encouraged to perform their own experiments with different initial values either in R or in Python in order to confirm this.) Thus, the system settles to a steady state (a point from which it never changes) for all initial values. 1.2 Cobweb Plots Cobweb plots are a tool that enable us to graphically visualise the orbit of a point under a one-dimensional map. They can be useful in investigating the qualitative behaviour of the related dynamical system. For instance, in subsection 1.1.2 we investigated orbits of the the logistic map with parameter \\(2\\) with different initial values. We saw that for all initial values in the open interval \\((0,1)\\), the orbits converged to the fixed point at \\(1/2\\). Cobweb plots enable us to infer such long-term status of an initial condition under repeated application of a map. 1.2.1 Constructing cobweb plots We construct a cobweb plot for a generic \\(1\\)D map \\(f:U \\to U\\) (where \\(U\\) is a subset of \\(R\\)) with an initial value \\(x_0\\) as follows: First we plot the the curve representing \\(y = f(x)\\) and the line \\(y=x\\). Draw a vertical from the point \\((x_0,0)\\) on the \\(x\\)-axis until we hit the curve \\(y=f(x)\\) at the point \\((x_0, f(x_0))\\) Draw a horizontal line from the point \\((x_0, f(x_0))\\) to the line \\(y=x\\) (this of course hits the line at coordinate \\((f(x_0), f(x_0))\\)). Draw a vertical line from the point \\((f(x_0), f(x_0))\\) on the line \\(y=x\\) to the point \\((f(x_0), f(f(x_0)))\\) on the curve \\(y= f(x)\\). Repeat steps 2-4 with \\((f(x_0),f(f(x_0)))\\) in place of \\((x_0, f(x_0))\\). Notice that points on the intersection of the line \\(y=x\\) with the curve \\(y=f(x)\\) are fixed points. We characterise two types of fixed points based on the behaviour of the cobweb plot near the fixed point. Fixed points which have an “inward spiral” (that is if we construct the cobweb plot with an initial value closed to the fixed point, we spiral in towards the fixed point) are called stable/attracting fixed points. Fixed points with an “outward spiral” (cobweb plots with an initial value closed to the fixed point, spiral out and away from the fixed point) are called unstable/repelling fixed points. Let us construct the cobweb plot for the logistic map \\(g(x) = 2x (1-x)\\). Figure 1.3: Cobweb plot of the logistic map with parameter 2 Code Challenge The code for the plot is shown below. Do experiment with the code by changing the parameter and initial value. Show Code Code from numpy import * from matplotlib.pyplot import * r = 2 # set logistic map parameter (between 0.0 and 4.0) # single non-zero stable fixed point for 1.0 &lt;a &lt; 3.0 # stable period-2 orbit for 3.0 &lt; a &lt; 1 + sqrt(6) = 3.45 # #********************************************************* def log_map(x): return r*x*(1.0-x) # define a function for the RHS of the logistic map def cobweb(f, x0, N, a, b): # f is function; x0 is starting point, #N is number of iterated # a and b are range of domain; typically 0,1 # plot the function being iterated t = linspace(a,b, 100) ##array of 100 evenly spaced numbers between a and b ##need sufficently many steps for good graph plot(t, f(t), &#39;k&#39;) # plot dashed line y=x plot(t,t, &#39;k--&#39;) #plot the iterates x,y, f(x0) x,y = x0,f(x0) # initiating x= x0 and y = f(x0) for _ in range(N): fy = f(y) plot([x,y], [y,y], &#39;r&#39;, linewidth=1) plot([y,y], [y,fy], &#39;r&#39;, linewidth=1) x ,y= y, fy #iterating x= f(x0) = y, f = f^2*(x0)# axes().set_aspect(1) # title of plot title(&#39;Cobweb diagram of Logistic map with r= %.2f&#39; % (r)) # label of x-axis xlabel(&#39;x&#39;) # label of y-axis ylabel(&#39;y&#39;) show() We can experiment with different parameter values (and feel free to make your own experiments with the code). Figure 1.4: Cobweb comparison for different parameter values Figure 1.4 shows cobweb plots of the logistic map with parameters \\(2\\) and \\(2.93\\). We see that for parameter \\(2.93\\) convergence to the fixed point at \\(0.6587\\) is slower than for parameter \\(r=2\\) with the same initial starting point of \\(0.2\\). We can fix the logistic parameter and vary the starting points instead as in Figure 1.5. Figure 1.5: Cobweb comparison for different initial values 1.2.2 Stability of fixed points We characterised fixed points by investigating the properties of the cobweb diagram ‘near’ the fixed points. Let us make this a little more precise. For \\(\\epsilon &gt;0\\), write \\(N_{\\epsilon}(p)\\) for the set of points which are a distance of at most \\(\\epsilon\\) from \\(p\\). That is \\[ N_{\\epsilon}(p) = \\{ x \\in \\R : |x-p| &lt; \\epsilon \\}. \\] We call \\(N_{\\epsilon}(p)\\) the \\(\\epsilon\\)-neighbourhood at \\(p\\). We now give a formal definition of attracting and repelling fixed points using this notation. Definition 1.4 Let \\(U \\subseteq \\R\\) and \\(f: U \\to U\\) be a map with a fixed point \\(p\\). Then \\(p\\) is a called a sink/attracting fixed point if there is an \\(\\epsilon &gt; 0\\) such that \\(\\lim_{k \\to \\infty} f^{k}(x) = p\\) for all \\(x\\) in the domain of \\(f\\) which are in \\(N_{\\epsilon} (p)\\). If there is an \\(\\epsilon&gt; 0\\) such that for all \\(x \\ne p\\) in the domain of \\(f\\) which also lie in \\(N_{\\epsilon}(p)\\), there is a \\(k \\in \\N\\) with \\(f^{k}(x) \\notin N_{\\epsilon}(p)\\), then \\(p\\) is called a source/repelling fixed point. Thus points near to attracting fixed points draw nearer and nearer to the fixed points, while points close to repelling fixed points are repelled further and further from the fixed point. Suppose we have a fixed point \\(p\\) and an initial value \\(x_{n-1} = p+ \\epsilon\\) close to the fixed point (\\(\\epsilon \\ll 1\\)). We calculate \\(x_n = f(x_{n-1}) = f(p+ \\epsilon)\\). Taking a Taylor expansion for \\(f\\) about \\(p\\) we estimate \\[ x_n = f(p) + f&#39;(p) \\epsilon + f&#39;&#39;(p) \\frac{\\epsilon^2}{2} + \\ldots \\]. Using the fact that \\(p\\) is a fixed point, we have \\(x_n \\simeq p + f&#39;(p) \\epsilon\\) and so \\[ |x_n - p| \\simeq |f&#39;(p)||\\epsilon|.\\] Thus if the derivative of \\(f\\) at \\(p\\) is strictly greater than \\(1\\), we expect the distance \\(|x_n-p|\\) to grow and \\(p\\) to be a source; if the derivative of \\(f\\) at \\(p\\) is strictly less than \\(1\\) on the other hand, we expect the distance \\(|x_n -p|\\) to decrease and \\(p\\) to be a sink. This is exactly what Theorem 1.1 says. Theorem 1.1 (Stability of fixed points) Let \\(U \\subseteq \\R\\) and \\(f: U \\to U\\) be a map with a fixed point \\(p\\). If \\(|f&#39;(p)| &lt; 1\\) then \\(p\\) is a sink. If \\(|f&#39;(p)| &gt; 1\\) then \\(p\\) is a source. NOTE It is the derivative of \\(f\\) at the fixed point \\(p\\) that determines the stability of \\(p\\). Theorem 1.1 is a one way implication. That is, the theorem does not imply that if \\(p\\) is a sink then \\(|f&#39;(p)| &lt;\\) or if \\(p\\) is a source then \\(|f&#39;(p)|&gt;1\\). Although the definition of \\(p\\) simply requires finding an \\(\\epsilon\\)-neighbourhood at \\(p\\) for which points are attracted to \\(p\\) under iterations of \\(f\\), this does not rule out the possibility that some points outside the \\(\\epsilon\\)-neighbourhood are attracted to \\(p\\) under iterations of the map \\(f\\). Definition 1.5 Let \\(f\\) be a 1D map and \\(p\\) an attracting fixed point of \\(f\\). The set of all points which are attracted to \\(p\\) under iterations of \\(f\\) is called the basin of attraction of \\(p\\). That is, the basin of attraction of a sink \\(p\\) is the set of all points \\(x\\) for which \\(\\lim_{k \\to \\infty}f^{k}(x) = p\\). The basin of attraction can exhibit many interesting properties especially at its boundary and we will investigate these in subsequent lectures. 1.3 Problem Sheet 1 For Week 2. Question 1.1 Consider the 1D map \\[ f(x) = ax + x^3\\] where \\(a\\) is a real parameter. Find the fixed points of \\(f\\). Investigate how the stability of the fixed points depends on \\(a\\). For \\(a = 1\\) there is exactly one fixed point. Is this fixed point stable or unstable? Show Solution 1.1 Solution 1.1 The fixed points are found by solving the equation \\(f(x) = x\\). That is we want to find all \\(x\\) such that \\[ x = ax + x^3.\\] Rearranging and taking out a factor of \\(x\\) gives \\[ x( x^2 + (a-1)) = 0.\\] This has solutions \\(x =0\\) and \\(x = \\pm\\sqrt{1-a}\\). Clearly non-zero real solutions only when \\(a &gt;1\\). If \\(|f&#39;(x)|&lt;1\\) at the fixed point then the fixed point is stable and \\(|f&#39;(x)|&gt;1\\) the fixed point is unstable (Theorem 1.1). Calculating the derivative of \\(f\\) we have: \\[ f&#39;(x) = a + 3x^2.\\] Hence, \\[\\begin{align*} &amp;f&#39;(0) = a \\\\ &amp;f&#39;(\\pm\\sqrt{1-a}.) = a + 3(1-a) = 3-2a. \\end{align*}\\] Hence the fixed point at \\(0\\) is stable for \\(a&lt;1\\) and unstable for \\(a &gt; 1\\). The fixed points at \\(\\pm\\sqrt{1-a}\\) are both unstable since we need \\(a\\le 1\\) for these to exist. For \\(a=1\\), the function has derivative \\(f&#39;(x) = 1 + 3x^2\\ge 1\\). In particular the function is monotonically increasing and has derivative strictly bigger than \\(1\\) at all non-zero points. Thus we expect that \\(|f(x)|&gt; x\\) in a neighbourhood of \\(0\\). We can see this as follows: \\[|x_n| = |x_{n-1} + x_{n-1}^3| = |x_{n-1}| |1 + x_{n-1}^2| &gt; |x_{n-1}|.\\] We conclude that \\(x=0\\) is a source. Question 1.2 Find the fixed points of the map \\[ f(x) = 2x^2-5x\\] and check their stability. Verify that \\(\\{ 1-\\sqrt{2}, 1 + \\sqrt{2}\\}\\) is a period-\\(2\\) orbit of the map. Is this period-\\(2\\) orbit stable. Show Solution 1.2 Solution 1.2 To find the fixed points we solve \\(2x^2 - 5x = x\\). Rearranging this gives \\(2x(x-3) = 0\\) which has solutions \\(x=0\\) and \\(x = 3\\). The derivative of \\(f\\) is \\(f&#39;(x) = 4x -5\\). Clearly \\(|f&#39;(0)| = 5 &gt;1\\) while \\(|f&#39;(3)| = 7 &gt;1\\). Now we are only asked to verify that \\(\\{ 1-\\sqrt{2}, 1 + \\sqrt{2}\\} = \\{x_{\\pm}\\}\\) are period-2 points of \\(x\\). This means we only need check that \\(f^2 (x_{\\pm}) = x_{\\pm}\\). Consider \\(x_{+} = 1 + \\sqrt{2}\\), \\[f (x_{+}) = 2(3 + 2\\sqrt{2}) -5(1 + \\sqrt{2}) = 1 - \\sqrt{2}.\\] Therefore to show that \\((x_{+}, x_{-})\\) is a period \\(2\\) orbit, it suffices to verify that \\(f(x_{-}) = x_{+}\\). We compute \\[ f(x_{-}) = 2( 3 - 2 \\sqrt{2}) - 5(1 - \\sqrt{2}) = 1 + \\sqrt{2}.\\] An alternative approach is to calculate \\[f^2(x) = 2(2x^2 - 5x)^2 - 5(2x^2 - 5x) = 8x^4 -40x^3 + 40 x^2 + 25 x.\\] And find the roots of \\(f^2(x) -x = 8x^4 -40x^3 + 40 x^2 + 24x.\\) Since \\(x=0\\) and \\(x=3\\) are roots it follows, as \\(8x^4 -20x^3 + 40 x^2 + 24x = 8x(x^3 -5x^2 + 5x + 3)\\), that \\((x-3)\\) divides \\(x^3 -20x^2 + 5x + 3\\). We can the use long-division to factorise \\[x^3 -20x^2 + 5x + 3 = (x-3)(x^2 -2x -1).\\] The roots of \\((x^2 -2x -1)\\) then give the two period \\(2\\) points. The stability of the period-\\(2\\) points can be determined by examining the derivative of \\(f^2\\) at the fixed points. By the chain rule \\[ (f(f(x)))&#39; = f&#39;(f(x))f&#39;(x).\\] At \\(x = x_{\\pm}\\), \\[(f(f(x))))&#39; = f&#39;(x_{+}) f&#39;(x_{-}) = (4 x_{+} -5) (4 x_{-} -5).\\] Substituting \\(x_{+} = 1 + \\sqrt{2}\\) and \\(x_{-} = 1- \\sqrt{2}\\) we have: \\[ \\left|\\der{f}{x}(x_{\\pm}) \\right| = 31.\\] Thus the period-\\(2\\) orbit \\((x_{+},x_{-})\\) is not stable. Question 1.3 Assume the growth of a population of bacteria is described by the discrete time dynamical system \\[ x_{n} = \\frac{2}{1+ \\frac{x_{n-1}}{k}} x_{n-1}, \\] where \\(x_{n}\\) is the population of bacteria at time \\(n\\) and \\(k\\) is a positive constant. How does the system evolve in the two limiting cases \\(x_n\\) small (\\(x_n/k \\ll 1\\)), \\(x_n\\) large (\\(x_n/k \\gg 1\\)). For an arbitrary initial population \\(x_0\\), find the value of \\(x_n\\) for every \\(n\\). [Hint: Use \\(y_{n} = 1/x_{n}\\) to rewrite the equation of the system.] What is the limiting value of \\(x_n\\) as \\(n \\to \\infty\\)? Determine the fixed points of the system and their stability. Discuss the connection between the exact solution and the fixed points. Show Solution 1.3 Solution 1.3 When \\(x_n/k \\ll 1\\), \\(2/(1 + \\frac{x_{n-1}}{k}) \\simeq 2\\) and so \\(x_n \\simeq x_{n-1}\\) and the population of bacteria roughly doubles with each time step. For the case where \\(x_n/k \\gg 1\\), \\(1 + x_{n-1}/k \\simeq x_{n-1}/k\\) and so \\(2/(1 + \\frac{x_{n-1}}{k}) \\simeq 2k/x_{n-1} x_{n-1} \\simeq 2k\\). The population roughly remains constant for \\(x_{n}\\) very large. We make use of the hint given in the question. Set \\(y_n := 1/x_{n}\\), then \\[ y_{n} = \\dfrac{k + x_{n-1}}{2kx_{n-1}} = \\dfrac{1}{2x_{n-1}} + \\dfrac{1}{2} =\\frac{y_{n}}{2} + \\frac{1}{2k}. \\] Let \\(y_0 = 1/x_0\\) for an initial value \\(x_0\\). We have: \\[\\begin{align*} y_1 &amp;= \\frac{y_0}{2} + \\frac{1}{2k}\\\\ y_2 &amp;= \\frac{y_0}{4} + \\frac{1}{k}(\\frac{1}{2} + \\frac{1}{4}) \\\\ y_3 &amp;= \\frac{y_0}{8} + \\frac{1}{k}(\\frac{1}{2} + \\frac{1}{4} + \\frac{1}{8}) \\\\ &amp;\\vdots \\\\ y_n &amp;= \\frac{y_0}{2^{n}} + \\frac{1}{k} \\sum_{i=1}^{n}\\frac{1}{2^i} = \\frac{y_0}{2^{n}} + \\frac{1}{k}\\frac{2^{n} -1}{2^{n}}. \\end{align*}\\] Hence, \\[ x_{n} = \\frac{k 2^{n}}{\\frac{k}{x_0} + 2^{n} -1}.\\] As \\(n\\) gets larger and larger \\(x_{n} \\to k\\). The fixed points are found by solving \\[ x = \\frac{2kx}{k + x}. \\] This has solutions \\(x = 0\\) and \\(x = k\\). To investigate stability of the fixed points we compute \\[ f&#39;(x) = \\frac{2k(k+x) - 2kx}{(k+x)^2} = \\frac{2k^2}{(k+x)^2}\\] where \\(f(x) = \\frac{2kx}{k + x}\\). When \\(x=0\\), \\(|f&#39;(x)| = 2 &gt;1\\), therefore \\(0\\) is an unstable fixed point; it’s a source. When \\(x =k\\), \\(|f&#39;(x)| = 1/2&lt;1\\) and so \\(x=k\\) is a stable fixed point. This aligns with the exact solution since as \\(n\\) tends to infinity the exact solution approaches the fixed point \\(x=k\\). References "],["periodicpoints.html", "Chapter 2 Periodic points and stability 2.1 Stability of periodic points 2.2 The family of logistic maps 2.3 Higher-dimensional maps 2.4 Problem Sheet 2", " Chapter 2 Periodic points and stability Covers Section 1.4 of Chapter 1 to Section 2.5 Definition 2.12 of Chapter 2 (Alligood, Sauer, and Yorke 2000). In Chapter 1 we investigated the logistic map mainly for parameters in the open interval \\((2, 3)\\). We saw largely uniform behaviour for parameters in this interval, namely that all values in the interval \\((0,1)\\) converged to a single attracting fixed point. However, we get quite different behaviour when we consider logistic parameter bigger than \\(3\\). Indeed applying Theorem 1.1 to the logistic map \\(g_{r}(x) = r x (1-x)\\) for an arbitrary value of \\(r\\) we see that the stability of the fixed points depends on the parameter \\(r\\). The fixed points of \\(g_{r}(x)\\) are obtained by solving \\(p = r p(1-p)\\). Rearranging yields: \\[p(r (1-p) - 1) = 0.\\] This has solutions \\(p = 0\\) and \\(p = 0\\) and \\(p = \\frac{r -1}{r}\\) (of course \\(r\\) is non-zero). Computing the derivative of \\(g_{r}\\) at these fixed points, we obtain: \\[g&#39;(0) = r \\qquad \\mathrm{ and } \\qquad g&#39;\\left(\\frac{r -1}{r}\\right) = 2-r.\\] Therefore in order to have a stable fixed point at zero we require \\(|r| &lt;1\\); the non-zero fixed point is stable/attracting when \\(1 &lt; r &lt;3\\). We expect therefore to have different behaviour for \\(r&gt;3\\). Let us investigate what happens for \\(r\\) just bigger than \\(3\\). Figure 2.1: Orbits of logistic map for r =3.3 The plots will seem to indicate that for initial values in \\((0,1)\\) orbits eventually oscillate between two values. This is indeed what happens. 2.1 Stability of periodic points We introduce terminology to characterise this new type of orbit. Definition 2.1 Let \\(f\\) be a map. We call a point \\(p\\) in the domain of \\(p\\) a periodic point of period k/period-k point if \\[f^k(p) = p\\] and \\(k\\) is the minimal positive integer for which this happens. The orbit with initial point \\(p\\) is called a periodic orbit of period k/period-k orbit. In other words, a periodic point is a point which will repeat itself under iterations of the dynamical system. A dynamical system which exhibits a stable periodic orbit is often called an oscillator. Notice that a periodic point of period \\(k\\) is simply a fixed point of \\(f^{k}\\). Definition 2.2 Let \\(f\\) be a map and \\(p\\) a period-k point. Then the period-k orbit of \\(p\\) is a sink/periodic sink/stable if \\(p\\) is a sink of \\(f^{k}\\). Likewise, the period-k orbit of \\(p\\) is a source/periodic source/unstable if \\(p\\) is a source of \\(f^{k}\\). Definition 2.2 is tricky to apply in practise as it requires computing \\(f^{k}\\). At this stage it is useful to recall Theorem 1.1 which gives a test of stability of a map \\(f\\) at a point \\(p\\) depending on the size of the derivative of the map at the fixed point \\(p\\). We can apply this test to determine stability of a periodic orbit so long as we are able to compute \\((f^{k})&#39;\\). Thankfully, this is can be done by repeated application of the chain rule. Recall that the chain rule states that \\((f\\circ g)&#39;(x) = f&#39;(g(x)) g&#39;(x)\\). Applying the chain rule to \\(f^2\\) gives: \\[\\begin{equation} (f^2)&#39;(x) = f&#39;(f(x)) f&#39;(x). \\tag{2.1} \\end{equation}\\] Consider two points \\(p:=p_1\\) and \\(p_2\\) in a period-2 orbit of a 1D map \\(f\\). Equation (2.1) implies \\[(f^2)&#39;(p) = f&#39;(p_2)f&#39;(p_1).\\] Thus if \\[|f&#39;(p_1)f&#39;(p_2)| &lt;1\\] then the periodic orbit \\((p=p_1, p_2)\\) of period 2 is stable. The above can be generalised by induction to an orbit of period \\(k\\). Stability test for periodic orbits Given a one-dimensional map \\(f\\) with a periodic orbit \\((p_1, p_2, \\ldots, p_k)\\) of period \\(k\\), then \\[(f^{k})&#39;(p_1) = f&#39;(p_k)f&#39;(p_{k-1}) \\ldots f&#39;(p_1).\\] Consequently, if \\[|f&#39;(p_k)f&#39;(p_{k-1}) \\ldots f&#39;(p_1)| &lt;1\\] the periodic orbit \\((p_1, p_2, \\ldots, p_k)\\) is stable/a sink; the period-k orbit \\((p_1, p_2, \\ldots, p_k)\\) is unstable/a source if \\[ |f&#39;(p_k)f&#39;(p_{k-1}) \\ldots f&#39;(p_1)| &gt;1.\\] Example 2.1 (Periodic 2 orbits of the logistic map) Let us compute the period 2 orbits of the logistic map \\(g(x) = r x (1-x)\\) for \\(r&gt;0\\). These of course will be the fixed points of \\(g^2\\) except those which are also fixed points of \\(g\\) (\\(0\\) and \\(\\frac{r-1}{r}\\)). We compute \\[g^2(x) = g(g(x)) = g(rx(1-x)) = r^2x(1-x)(1- rx(1-x)).\\] Thus we want to find values \\(p\\) such that \\(p = r^2p(1-p)(1-rp(1-p))\\). Rearranging we have \\[p \\left( r^2(1-p)(1-rp(1-p)) -1 \\right) = 0.\\] We now make use of the fact that both \\(p\\) and \\(r(1-p) -1\\) are roots of \\(r^2p(1-p)(1-rp(1-p))\\) (since \\(p = 0\\) and \\(p = \\frac{r-1}{r}\\) are both fixed points of \\(g^2\\)) to deduce that \\(r(1-p) -1\\) is a factor of \\(r^2(1-p)(1-rp(1-p)) -1\\). Thus there are \\(a,b,c \\in \\R\\) such that \\[ (r(1-p) -1) (ap^2 + bp + c) = r^2(1-p)(1-rp(1-p)) -1. \\] We compare coefficients to figure out what \\(a,b,c\\) are. \\[\\begin{align*} &amp; p^3: -ar = -r^3 \\\\ &amp; p^2: ar-br - a = 2r^3 \\\\ &amp; p^1: -rc - b + br = -r^2 -r^3 \\\\ &amp; p^0: rc -c = r^2 - 1 \\end{align*}\\] Looking at the \\(p^3\\) and \\(p^0\\) coefficients we see that \\(a = r^2\\) and \\(c = r+1\\). From either the \\(p\\) coefficients or \\(p^2\\) coefficients we see that \\(b = -r(r+1)\\). Putting these together we get: \\[r^2(1-p)(1-rp(1-p)) -1 = (r(1-p) -1) (r^2p^2 - r(r+1)p + r+1).\\] We find the period 2 points by factorising the term \\(r^2p^2 - r(r+1)p + r+1\\). We can do so using the quadratic formula to get: \\[\\begin{align*} p_{1,2} &amp;= \\frac{r(r+1) \\pm \\sqrt{r^2 (r+1)^2 - 4 r^2 (r+1)}}{2 r^2} \\\\ &amp;= \\frac{r+1 \\pm \\sqrt{(r+1)^2 - 4(r+1)}}{2r} \\\\ &amp;= \\frac{r+1 \\pm \\sqrt{(r+1)(r-3)}}{2r}. \\end{align*}\\] Observe that if \\(r&lt;3\\) then the above has no real solutions. Let us construct a cobweb plot to investigate the stability of the period two points for a parameter value just bigger than \\(3\\). Figure 2.2: Cobweb diagram illustrating stable period 2 orbit. Figure 2.2 demonstrates that for \\(r=3.3\\) the period 2 points are stable. For the generic logistic map, stability of the period \\(2\\) orbits depends on the parameter \\(r\\). First we compute \\(g&#39;(x) = r(1-2x)\\). Thus, \\[\\begin{align*} |g&#39;(p_1)g&#39;(p_2)| &amp;= |g&#39;(p_1)||g&#39;(p_2)| \\\\ &amp;= r^2(1 - 2p_1 - 2p_2 + 4 p_1p_2) \\\\ &amp;= r^2 -2r(r+1) + 4(r+1) \\\\ &amp;= |-r^2 +2r + 4| \\end{align*}\\] Thus, for stability of the period two points, we require \\(|-r^2 +2r + 4| &lt;1\\) which gives \\(3 &lt; r &lt; 1 + \\sqrt{6}\\). We note that for these values of \\(r\\) the period \\(1\\) points are unstable fixed points. 2.2 The family of logistic maps Let us summarise what we have learnt about the logistic map \\(g(x) = rx(1-x)\\) so far. We have shown that for values of \\(r\\) between \\(0 \\le r &lt;1\\) there is a single sink at \\(x=0\\). For \\(1 &lt; r &lt; 3\\), we have seen that there is a single sink at \\(x = \\dfrac{r-1}{r}\\). Lastly in Subsection 2.1 we saw that period 2 orbits emerge for \\(r &gt;3\\) and these are stable when \\(3&lt; r &lt; 1+ \\sqrt{6}\\). We now investigate what happens when \\(r \\ge 1+ \\sqrt{6}\\). Of course we know that the period \\(2\\) orbits become unstable in this regime. Overall, the behaviour of the dynamical system changes significantly. We get what is called bifurcation, more precisely period-doubling bifurcation/ period-doubling cascade. Let us introduce some terminology for this new dynamic. Definition 2.3 (Period-doubling bifurcation) A change from a stable periodic orbit of size \\(N\\) to a stable periodic orbit of size \\(2N\\) which occurs when the parameter \\(r\\) is increased. Definition 2.4 (Birfucation diagram) A diagram that summarises the succession of period-doubling produced as \\(r\\) is increased. The diagram is constructed using the following steps: Pick an initial value of \\(r\\). Choose a random \\(x \\in (0,1)\\). Calculate the orbit of \\(x\\) under the logistic map \\(g(x)\\). Ignore the firs \\(100\\) orbits (to give time to settle to a periodic sink) and plot the the orbit beginning with iterate 101. Increment \\(r\\) and repeats Steps 1 - 5. In Figure 2.3 we plot the bifurcation diagram of the logistic map. Feel free to copy the code in order to perform your own experimentation. Figure 2.3: Bifurcation diagram of the logistic map Code Challenge The code for the plot is shown below. Do experiment with the code by changing the parameter range and initial values. Are you able to write a more efficient code/produce a more artistic diagram? Show Code Code from numpy import * from matplotlib.pyplot import * def log_map(r,x): return r*x*(1.0-x) # define a function for the RHS of the logistic map def bifurc(f, x0, a, N, M): #f is the map, x0 the initial value, #a is the range from which to begin incrementing r #N the number of iterations and # M the number of iterations to plot #incrementing r values between a and N r= np.linspace(a,4,N) # initiating initial values x= x0 * np.ones(N) #iterating the logmap on the initial values for i in range(N): x= log_map(r,x) if i &gt;= (N - M): # plotting the last M orbits; # green pixels with transparency .25 plot(r,x, &#39;g,&#39;, alpha=.25) axes().set_xlim(a,4) # setting x axis limit # title of plot title(&#39;Birfucation diagram of the Logistic map&#39;) # label of x-axis xlabel(&#39;r&#39;) # label of y-axis ylabel(&#39;x&#39;) # rescaling plot if necessary figure_size=gcf().get_size_inches() factor= 1 gcf().set_size_inches(factor * figure_size) show() #bifurcation diagram of the logistic map beginning at r=2.5 bifurc(log_map, 0.1, 2.5, 1500, 500) Figure 2.4: Bifurcation diagram of the logistic map zooming in on the range (3.5,4) We point out some key features of the bifurcation diagram 2.3 For \\(r &lt; 1\\), there is one attractor namely the sink at 0. For \\(1&lt; r &lt;3\\) there is one attractor \\(\\frac{r - 1}{r}\\). The first bifurcation occurs at r=3 and subsequently at r= 3.45, 3.54, 3.564, 3.569 and so on until just beyond \\(r \\simeq 3.57\\). That is at \\(r=3\\) we have the first period doubling from a period one sink to a period two sink, then at the next bifurcation an period 4 sink appears, then a period 8 sink at the next and so on illustrating the period doubling cascade mentioned above. For \\(r \\gtrsim 3.57\\) the diagram becomes very complicated. The system becomes chaotic. A key feature of this chaotic behaviour is that a small change in a state of the system (e.g. a small change in initial condition) can result in large differences in the next state. These changes are such that the system’s behaviour is unpredictable in general. At several values of \\(r\\) just beyond \\(3.57\\) a small number of \\(x\\) values are produced — these are the white spaces in the diagram. In these regions no fixed points or attracting orbits seem to exist. On the other hand, in the same \\(r\\) range, there are also black spaces filed in with attracting points/orbits these are called attracting sets/ chaotic attractors. A close-up of the bifurcation diagram shows that at \\(r=3.83\\), a period 3 attractor emerges which also exhibits a period-doubling cascade to period 6 orbits, then period 12 and so on. Generally, in the range \\((3.57, 4)\\) there is a rich interleaving of “chaos” and “order”. A small change in \\(r\\) can make a stable system chaotic and vice versa. The diagram stops at \\(r=4\\). After this point, no attracting sets exist. 2.2.1 Initial conditions and Chaos What do we mean by “chaotic behaviour”? There are two key features: Non-periodicity. Sensitive dependence on initial conditions. Let us say a little more about the 2nd condition. Suppose we start and orbit from an initial point \\(x_0^{(1)}\\) and another orbit from an initial point very close to the first \\(x_0^{(2)} = x_0^{(1)} + \\epsilon\\) where \\(0&lt; |\\epsilon| \\ll 1\\). If the orbits move strongly away from each other with \\(n\\), that is, \\(|x_n^{(1)} - x_{n}^{(2)}|\\) “becomes big”, then the system is sensitive to initial conditions. In such situations making long-term predictions of the behaviour of the dynamical system becomes very difficult, as slightly different initial conditions can result vastly different long-term behaviour. More precisely, we have the following definition. Definition 2.5 (Sensitive dependence on initial conditions) Let \\(f\\) be a 1D map. A point \\(x_0\\) has sensitive dependence on initial conditions if there is a \\(d&gt;0\\) such that for any \\(\\epsilon &gt;0\\) the \\(\\epsilon\\)-neighbourhood \\(N_{\\epsilon}(x_0)\\) of \\(x_0\\) contains a point \\(x\\) (in the domain of \\(f\\)) such that \\(|f^k(x) -f^{k}(x_0)| \\ge d\\) for some non-negative integer \\(k\\). That is, there are points arbitrarily close to \\(x_0\\) which are eventually mapped at least \\(d\\) units from the corresponding image of \\(x_0\\). Note that generally the closer \\(x\\) is to \\(x_0\\) the larger \\(k\\) will need to be. Such a point \\(x_0\\) is sometimes called a sensitive point. Figure 2.5 shows two orbits with initial values \\(x_0^{(1)} = 0.3\\) and \\(x_0^{(2)} = 0.3 + 0.001\\). We can see that there are several points at which corresponding images of both orbits are a distance \\(0.5\\) (for instance) from one another. Figure 2.5: Two orbits of the logistic map with parameter 4 with close initial points. Perhaps the most interesting chaotic dynamical systems are those that exhibit attracting behaviour (for example the logistic map with parameter values close (and equal) to 4). That is, systems with orbits whose trajectories converge to an attractor. 2.3 Higher-dimensional maps Now that we have established some key features of dynamical systems associated to one-dimensional maps, we begin to think about higher-dimensional maps. The features introduced for 1D maps are instances of more general phenomena in higher dimensions. Below is an example of the dynamical system associated to a 2-dimensional map. Example 2.2 (Hènon's map) Consider the map \\(f: \\R^2 \\to \\R^2\\) given by \\(f(x,y) = (a - x^2 + by, x)\\). This gives rise to the dynamical system: \\[\\begin{align*} &amp;x_{n+1} = a- x_n^2 + by_n\\\\ &amp;y_{n+1} = x_n \\end{align*}\\] 2.3.1 Sinks, sources and saddles Let us define the notion of an \\(\\epsilon\\)-neighbourhood in higher dimensions. Let \\(\\epsilon&gt;0\\), then we write: \\[N_{\\epsilon}(\\vec{p}) := \\{ \\vec{x} \\in \\R^{n} : |\\vec{x} - \\vec{p}| &lt; \\epsilon \\}\\] that is \\(N_{\\epsilon}(\\vec{p})\\) is the set of points in \\(\\R^{n}\\) which are a distance at most \\(\\epsilon\\) from \\(p\\). We can now define sources, and sinks as before. Definition 2.6 Let \\(\\vec{f}\\) be a map defined on a subset of \\(\\R^n\\) and let \\(\\vec{p}\\) be a fixed point of \\(\\vec{f}\\). If there is an \\(\\epsilon\\)-neighbourhood \\(N_{\\epsilon}(\\vec{p})\\) of \\(p\\) such that for all \\(\\vec{v}\\) in the domain of \\(\\vec{f}\\) with \\(\\vec{v} \\in N_{\\epsilon}(\\vec{p})\\), \\[\\lim_{k \\to \\infty} \\vec{f}^{k}(\\vec{v}) = \\vec{p},\\] then \\(\\vec{v}\\) is called a sink/attractor/stable fixed point. If, on the other hand, there is an \\(\\epsilon\\)-neighbourhood \\(N_{\\epsilon}(\\vec{p})\\) of \\(\\vec{p}\\) such that for all points \\(\\vec{v} \\ne \\vec{p}\\) in the domain of \\(\\vec{f}\\) with \\(\\vec{v} \\in N_{\\epsilon}(\\vec{p})\\), there is a \\(k \\in \\N\\) such that \\(f^{k}(\\vec{v}) \\notin N_{\\epsilon}(\\vec{p})\\), then \\(\\vec{p}\\) is called a source/repeller. Note that fixed points of a map \\(\\vec{f}\\) defined on a subset of \\(\\R^{n}\\) are exactly what we expect them to be, that is they are points \\(\\vec{x}\\in \\R^{n}\\) such that \\(\\vec{f}(\\vec{x}) = \\vec{x}\\). In higher dimensions a new dynamic emerges around fixed points giving rise to a new type of fixed point — a so called saddle point. Saddle points have at least one attracting direction and at least one repelling direction. Saddle points are unstable fixed points and are very important for chaotic behaviour. Figure 2.6: Higher-dimensional dynamics Let \\(\\vec{f} = (f_1, f_2, \\ldots, f_n)\\) be a map on a subset of \\(\\R^n\\) and consider the associated dynamical system \\(\\vec{x}_{n+1} = \\vec{f}(\\vec{x}_n)\\). Suppose \\(\\vec{p} = (p_1, p_2, \\ldots, p_n)\\) is a fixed point of \\(\\vec{f}\\). How do we determine the stability of this fixed point? Let us repeat a strategy we applied fruitfully in the 1D case but now generalised suitably for higher dimensional maps. Consider an initial value \\(\\vec{x}_0 = \\vec{p} + \\vec{\\epsilon}\\) close to the fixed point \\(\\vec{p}\\) where \\(\\vec{\\epsilon} = (\\epsilon_1, \\epsilon_2, \\ldots, \\epsilon_{n}) \\in \\R^{n}\\) and \\(|\\vec{\\epsilon}| \\ll 1\\). We can approximate the next point \\(\\vec{x}_{1} = \\vec{f}(\\vec{x}_0)\\) in the orbit of \\(\\vec{x}_0\\) by taking a multivariate Taylor expansion of \\(\\vec{f}\\) about the point \\(\\vec{p}\\). That is we have: \\[\\begin{align*} \\vec{x}_{1} &amp;= \\vec{f}(\\vec{p}) + \\sum_{i=1}^{n} \\dfrac{\\partial \\vec{f}(\\vec{p})}{\\partial x_{i}} \\epsilon_{i} + \\ldots \\\\ &amp;= \\vec{f}(\\vec{p}) + \\begin{pmatrix} \\sum_{i=1}^{n}\\dfrac{\\partial f_1}{\\partial x_i}(\\vec{p}) \\epsilon_{i} \\\\ \\sum_{i=1}^{n}\\dfrac{\\partial f_2}{\\partial x_i}(\\vec{p}) \\epsilon_{i}\\\\ \\vdots \\\\ \\sum_{i=1}^{n} \\dfrac{\\partial f_n}{\\partial x_i}(\\vec{p}) \\epsilon_{i} \\end{pmatrix} + \\ldots \\\\ &amp;\\simeq \\vec{f}(\\vec{p}) + \\begin{pmatrix} \\dfrac{\\partial f_1}{\\partial x_1}(\\vec{p}) \\epsilon_{1} + \\dfrac{\\partial f_1}{\\partial x_2}(\\vec{p}) \\epsilon_{2} + \\ldots + \\dfrac{\\partial f_1}{\\partial x_n}(\\vec{p}) \\epsilon_{n} \\\\ \\dfrac{\\partial f_2}{\\partial x_1}(\\vec{p}) \\epsilon_{1} + \\dfrac{\\partial f_2}{\\partial x_2}(\\vec{p}) \\epsilon_{2} + \\ldots + \\dfrac{\\partial f_2}{\\partial x_n}(\\vec{p}) \\epsilon_{n} \\\\ \\vdots \\\\ \\dfrac{\\partial f_n}{\\partial x_1}(\\vec{p}) \\epsilon_{1} + \\dfrac{\\partial f_n}{\\partial x_2}(\\vec{p}) \\epsilon_{2} + \\ldots + \\dfrac{\\partial f_n}{\\partial x_n}(\\vec{p}) \\epsilon_{n} \\\\ \\end{pmatrix} \\\\ &amp;= \\vec{p} + \\begin{pmatrix} \\pder{f_1}{x_1}(\\vec{p}) &amp; \\pder{f_1}{x_2}(\\vec{p}) &amp; \\ldots &amp; \\pder{f_1}{x_n}(\\vec{p}) \\\\ \\pder{f_2}{x_1}(\\vec{p}) &amp; \\pder{f_2}{x_2}(\\vec{p}) &amp; \\ldots &amp; \\pder{f_2}{x_n}(\\vec{p}) \\\\ \\vdots &amp; \\vdots &amp; &amp; \\vdots \\\\ \\pder{f_n}{x_1}(\\vec{p}) &amp; \\pder{f_n}{x_2}(\\vec{p}) &amp; \\ldots &amp; \\pder{f_n}{x_n}(\\vec{p}) \\end{pmatrix} \\cdot \\begin{pmatrix} \\epsilon_1 \\\\ \\epsilon_2 \\\\ \\vdots \\\\ \\epsilon_n \\end{pmatrix} \\end{align*}\\] The matrix \\[\\begin{pmatrix} \\pder{f_1}{x_1}(\\vec{p}) &amp; \\pder{f_1}{x_2}(\\vec{p}) &amp; \\ldots &amp; \\pder{f_1}{x_n}(\\vec{p}) \\\\ \\pder{f_2}{x_1}(\\vec{p}) &amp; \\pder{f_2}{x_2}(\\vec{p}) &amp; \\ldots &amp; \\pder{f_2}{x_n}(\\vec{p}) \\\\ \\vdots &amp; \\vdots &amp; &amp; \\vdots \\\\ \\pder{f_n}{x_1}(\\vec{p}) &amp; \\pder{f_n}{x_2}(\\vec{p}) &amp; \\ldots &amp; \\pder{f_n}{x_n}(\\vec{p}) \\end{pmatrix}\\] is called the Jacobian (matrix) of \\(\\vec{f}\\) at \\(\\vec{p}\\) and we write \\(\\jacob(p)\\) for this matrix. (The matrix is named after the mathematician Carl Gustav Jacob Jacobi). The matrix \\[\\begin{pmatrix} \\pder{f_1}{x_1} &amp; \\pder{f_1}{x_2} &amp; \\ldots &amp; \\pder{f_1}{x_n} \\\\ \\pder{f_2}{x_1} &amp; \\pder{f_2}{x_2}&amp; \\ldots &amp; \\pder{f_2}{x_n} \\\\ \\vdots &amp; \\vdots &amp; &amp; \\vdots \\\\ \\pder{f_n}{x_1} &amp; \\pder{f_n}{x_2} &amp; \\ldots &amp; \\pder{f_n}{x_n} \\end{pmatrix}\\] is the Jacobian matrix of \\(\\vec{f}\\). Write \\(A\\) for the matrix \\(\\jacob(p)\\), and recall (from MT3501 or MT2501) that the map \\(A: \\R^{n} \\to \\R^{n}\\) by \\(\\vec{x} \\mapsto A \\cdot \\vec{x}\\) is a linear map that is, it satisfies the condition \\(A(a \\vec{x} + b \\vec{y}) = aA\\vec{x} + b A\\vec{y}\\) for \\(a,b \\in \\R\\) and \\(\\vec{x}, \\vec{y} \\in \\R^{n}\\). Now if \\(A\\vec{\\epsilon}\\) remains small enough, we can repeat the process to approximate \\(\\vec{x}_2 = \\vec{f}(x_1)\\) as \\(\\vec{x_2} \\simeq \\vec{p} + A^2\\vec{\\epsilon}\\). In particular, so long as \\(A^{n}\\vec{\\epsilon}\\) is small, \\(x_{n+1} \\simeq A^{n+1}\\vec{\\epsilon}\\). Thus to understand when the distance \\(|\\vec{x}_{n} - \\vec{p}|\\) grows or shrinks, we need to understand how \\(A=\\jacob(p)\\) acts on \\(\\R^{n}\\). The effect of \\(A\\) on a small disc about centred at the origin can be determined by the eigenvalues of \\(A\\). Recall that an eigenvector \\(\\vec{v}\\) of \\(A\\) with eigenvalue \\(\\lambda \\in \\R\\) is a vector satisfying the equation \\(A\\vec{v} = \\lambda \\vec{v}\\). Thus if \\(\\vec{v}\\) is an eigenvector of \\(A\\) with eigenvalue \\(\\lambda\\) where \\(|\\lambda|&gt;1\\), then \\(|A\\vec{v}| &gt; |\\vec{v}|\\). In particular if we chose \\(\\vec{\\epsilon}\\) to be a multiple of an eigenvector \\(\\vec{v}\\) of \\(A\\) with eigenvalue \\(\\lambda\\), then \\[|\\vec{x}_1 - \\vec{p}| \\simeq |A \\vec{\\epsilon}| = |\\lambda| |\\vec{\\epsilon}|.\\] More generally, \\[|\\vec{x}_{n} -\\vec{p}| \\simeq |A^{n} \\vec{\\epsilon}| = |\\lambda|^{n} |\\vec{\\epsilon}|.\\] Therefore, we get growth away from the fixed point if \\(|\\lambda|&gt;1\\) and if \\(|\\lambda|&lt;1\\) the orbit moves closer to the fixed point. We can now state the following analogue of Theorem 1.1 which gives a stability test for higher dimensional maps. Theorem 2.1 Let \\(\\vec{f}\\) be a map on a subset of \\(\\R^n\\) and \\(\\vec{p}\\) a fixed point of \\(\\vec{f}\\). If the magnitude of each eigenvalue of \\(\\jacob(\\vec{p})\\) is strictly less than \\(1\\), then \\(\\vec{p}\\) is a sink. If the magnitude of each eigenvalue of \\(\\jacob(\\vec{p})\\) is strictly greater than \\(1\\), then \\(\\vec{p}\\) is a source. If at least one eigenvalue of \\(\\jacob(\\vec{p})\\) has magnitude strictly bigger than \\(1\\), then \\(\\vec{p}\\) is unstable. We can further characterise fixed points based on the eigenvalues of the Jacobian. Definition 2.7 (Classification of fixed points) Let \\(\\vec{f}\\) be a map on a subset of \\(\\R^{n}\\) and \\(\\vec{p}\\) be a fixed point of \\(f\\). Then \\(\\vec{p}\\) is hyperbolic if none of the eigenvalues of \\(\\jacob(\\vec{p})\\) has magnitude \\(1\\); if \\(\\vec{p}\\) is hyperbolic and \\(\\jacob(\\vec{p})\\) has at least one eigenvalue with magnitude strictly bigger than \\(1\\) and at least one eigenvalue with magnitude strictly less than \\(1\\), then a \\(\\vec{p}\\) is called a saddle (point). As in Definition 2.2 we can extend the above definition to period-k orbits by replacing \\(\\v{f}\\) with \\(\\v{f}^{k}\\). For instance a period \\(k\\) orbit with initial vector \\(\\vec{p}\\) is a saddle if \\(\\vec{p}\\) is a saddle of \\(\\v{f}^{k}\\). 2.4 Problem Sheet 2 For Week 3. Question 2.1 Consider the 1D map \\(f\\) defined on the closed unit interval as \\[ f(x) = \\begin{cases} 2x &amp; \\text{ if } 0 \\le x \\le 1/2 \\\\ 2(1-x) &amp; \\text{ if } 1/2 \\le x \\le 1. \\end{cases} \\] Carefully sketch \\(y = f(x)\\) for \\(0 \\le x \\le 1\\) and the diagonal \\(y=x\\). On the basis of your diagram how many fixed points do you expect the map to have. [Hint: A fairly accurate diagram is useful here. This question might be easier done via python.] For each of the suspected fixed points of \\(f(x)\\) chose an initial condition \\(x_1 \\in [0,1]\\) close to the fixed point and sketch the first 3 steps of a cobweb plot (you can use the diagram sketched in part a.). Use your cobweb plots to comment on the expected stability properties of each fixed point. Calculate all fixed points of the map and determine their stability. Briefly compare your result with what you expected from parts a. and b. Find the period-2 orbit of this map and determine its stability. Show Solution 2.1 Solution 2.1 From the sketch (Figure 2.7) below we expect \\(f\\) to have two fixed points: one at zero and one at \\(2/3\\). Figure 2.7: Map sketch We choose initial conditions \\(0.01\\) and \\(0.660\\). The cobweb plot of the first three points is shown (Figure 2.8) in each case. Both fixed points appear to be unstable. Figure 2.8: Cobweb The fixed points of the map are given by solving \\(2x = x\\) and \\(2(1-x) = x\\). This gives solutions \\(x=0\\) and \\(x = 2/3\\), which is what was indicated by our “sketch”. The absolute value of the derivative at both fixed points is \\(2\\) and so both are unstable by Theorem 1.1. Let us compute \\(f^2\\). First suppose \\(f(x)\\) is in the range \\([0,1/2]\\), then \\(f(f(x)) = 2f(x)\\) and \\(x\\) is either in the range \\([0,1/4]\\) or \\([3/4,1]\\). Therefore for \\(x \\in [0,1/4]\\), \\(f^2(x) = 4x\\) and for \\(x \\in [3/4,1]\\), \\(f^2(x) = 4(1-x)\\). If \\(f(x) \\in [1/2,1]\\), then \\(x \\in [1/4, 1/2] \\sqcup [1/2, 3/4]\\). Therefore if \\(x \\in [1/4, 1/2]\\), \\(f^2(x) = 2(1-2x)\\) and if \\(x \\in [1/2, 3/4]\\), \\(f^2(x) = 2(1-2(1-x))=-2(1-2x)\\). Therefore we have \\[ f^2 = \\begin{cases} 4x &amp; \\text{ if } 0 \\le x \\le 1/4 \\\\ 2(1-2x) &amp; \\text{ if } 1/4 \\le x \\le 1/2 \\\\ -2(1-2x) &amp; \\text{ if } 1/2 \\le x \\le 3/4 \\\\ 4(1-x) &amp; \\text{ if } 3/4 \\le x \\le 1/2 \\end{cases}. \\] The period two points are now the fixed points of \\(f^2\\) that are not fixed points of \\(f\\). These are \\(x = 2/5\\) and \\(x=4/5\\). The absolute value of \\(f^2\\) at the period-2 points is equal to \\(4\\). Hence the period-2 orbit is unstable. Question 2.2 Given \\(x_{n} = ax_{n-1} - x_{n-1}^3\\), \\(n = 1,2,3 \\ldots\\) and \\(a \\in \\R\\) Verify that \\(\\{ \\sqrt{1 + a}, - \\sqrt{1+a}\\}\\) for \\(a &gt; -1\\) is a period-2 orbit. Investigate the stability of this orbit. Show Solution 2.2 Solution 2.2 This is a verify question so we meed only check that \\(f(\\sqrt{1 + a}) = -\\sqrt{1 + a}\\) and \\(f(-\\sqrt{1 + a}) = \\sqrt{1 + a}\\). However, notice that \\(f(-x) =-f(x)\\) i.e. \\(f\\) is an odd function therefore we need only check that \\(f(\\sqrt{1 + a}) = -\\sqrt{1 + a}\\). We compute \\[ f(\\sqrt{1 + a}) = \\sqrt{1 + a}(a - 1- a) = - \\sqrt{1 + a} \\] as required. Set \\(f:=ax - x^3\\). Then \\(f&#39;(x) = a - 3x^2\\), \\(f&#39;(\\sqrt{1 + a}) = f&#39;(-\\sqrt{1 + a}) = a - 3 - 3a = -(3+2a)\\). Therefore \\[|f&#39;(\\sqrt{1 + a})||f&#39;(-\\sqrt{1 + a})| = (3+2a)^2\\]. Certainly for \\(a&gt;-1\\) the period \\(2\\) point is unstable by Theorem 1.1. Note that when \\(a=-1\\), we no longer have a period-2 orbit, he orbit reduces to the fixed point at \\(x=0\\). In this case \\(x = -(x + x^3)\\) and as in Problem Sheet 1 Question 1, \\(0\\) is an unstable fixed point. Question 2.3 Determine the eigenvalues and eigenvectors of the following matrices: \\[A=\\begin{pmatrix} a &amp; 0 \\\\ 0 &amp; b \\end{pmatrix} \\qquad B=\\begin{pmatrix} a &amp; b \\\\ 0 &amp; a \\end{pmatrix} \\qquad C=\\begin{pmatrix} 0 &amp; -a \\\\ a &amp; 0 \\end{pmatrix}. \\] Show Solution 2.3 Solution 2.3 Eigenvalues are found by solving the equation \\(\\det(xI - D) = 0\\). For the matrices given we compute: \\[\\begin{align*} \\det(xI-A) &amp;= (x-a)(x-b)\\\\ \\det(xI-B) &amp;= (x-a)^2 \\\\ \\det(xI-C) &amp; = x^2 + a^2. \\end{align*}\\] Hence the eigenvalues of \\(A\\) are \\(a\\) and \\(b\\), the eigenvalue of \\(B\\) is \\(a\\), and, the eigenvalues of \\(c\\) are \\(\\pm ia\\). Eigenvectors are found by solving the equation \\((D-\\lambda I)\\v{v} = \\v{0}\\) where \\(\\v{v}\\) is a vector, \\(\\lambda\\) is an eigenvector of the matrix \\(D\\) and \\(\\v{0}\\) is the zero vector. For the matrix \\(A\\): For eigenvalue \\(a\\) we solve: \\[\\begin{pmatrix}0 &amp; 0 \\\\ 0 &amp; b-a \\end{pmatrix} \\begin{pmatrix} x \\\\ y \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ (b-a)y \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}.\\] We get that \\(x\\) can be any value and \\(y\\) must be \\(0\\). That is the eigenvectors of \\(a\\) are precisely those spanned by \\(\\begin{pmatrix} 1&amp; 0 \\end{pmatrix}\\). The eigenvalue \\(b\\) is similar to \\(a\\) with coordinates swapped. In this case, we find that eigenvectors are those spanned by \\(\\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}\\). For the matrix \\(B\\): We compute \\[\\begin{pmatrix}0 &amp; b \\\\ 0 &amp; 0 \\end{pmatrix} \\begin{pmatrix} x \\\\ y \\end{pmatrix} = \\begin{pmatrix} by \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}.\\] Hence \\(y = 0\\) and \\(x\\) can be any value. In particular the eigenvectors are spanned by \\(\\begin{pmatrix} 1&amp; \\\\0 \\end{pmatrix}\\). For matrix \\(C\\): For eigenvalue \\(ia\\) we compute: \\[\\begin{pmatrix}-ia &amp; -a \\\\ a &amp; -ia \\end{pmatrix} \\begin{pmatrix} x \\\\ y \\end{pmatrix} = \\begin{pmatrix} -ia x -ay \\\\ ax -iay \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}.\\] Now over the reals this has no only the trivial solution. Over \\(\\C^{2}\\), this is reduced to one equation \\(ix +y = 0\\) since \\(-i(ix +y) = x -iy\\). In particular, we have a choice of parameter. Take \\(y = t\\), for \\(t \\in \\C\\), then \\(x = it\\) and our eigenvectors are spanned by \\(\\begin{pmatrix} i \\\\ 1 \\end{pmatrix}\\) over the complex field. For the eigenvalue \\(-ia\\), we compute: \\[\\begin{pmatrix}ia &amp; -a \\\\ a &amp; ia \\end{pmatrix} \\begin{pmatrix} x \\\\ y \\end{pmatrix} = \\begin{pmatrix} ia x -ay \\\\ ax +iay \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}.\\] Again, over \\(\\C^2\\) this reduced to the equation \\(ix -y = 0\\). We choose \\(y = t\\) for \\(t \\in \\C\\) and this gives \\(x = -iy\\). Our eigenvectors are spanned by \\(\\begin{pmatrix} -i \\\\ 1 \\end{pmatrix}\\). References "],["higher-dim-dynamics.html", "Chapter 3 Higher-dimensional dynamics 3.1 Example 3.2 Stability of manifolds associated with a saddle 3.3 Problem Sheet 3", " Chapter 3 Higher-dimensional dynamics Covers Chapter 2 Section 2.5 Example 2.13 to Section 2.6 Example 2.20 of Chapter 2 (Alligood, Sauer, and Yorke 2000). 3.1 Example Let us apply Theorem 2.1 to an example we encountered earlier on: the Hènon map. Example 3.1 (The Hènon map II) The Hènon map is the map \\(\\vec{f}_{a,b}(x,y) = (a - x^2 + by, x)\\). For this example we take \\(a=0\\) and \\(b = 0.4\\) to get: \\[\\vec{f}(x,y) = \\vec{f}_{0,0.4}(x,y)= (-x^2 + by, x).\\] We compute the fixed points by solving the equation \\[ \\vec{f}(x,y) = (x,y). \\] From the second coordinates we find that \\(x= y\\); the first coordinate then gives \\(x^2 - bx + x = 0\\). Solving this gives two solutions, \\(x = y = 0\\) and \\(x = y = b-1\\). To investigate the stability of the fixed point we need to compute the Jacobian of \\(\\vec{f}\\) at each of the two fixed points and compute the eigenvalues of the resulting two matrices. We write \\(\\vec{f} = (f_1(x,y), f_2(x,y))\\) where \\(f_1(x,y) = -x^2 + by\\) and \\(f_2(x,y) = x\\). Thus, \\[ \\jacob{(x,y)} = \\begin{pmatrix} \\pder{f_1}{x} &amp; \\pder{f_1}{y} \\\\ \\pder{f_2}{x} &amp; \\pder{f_2}{y} \\end{pmatrix} = \\begin{pmatrix} -2x &amp; b \\\\ 1 &amp; 0 \\end{pmatrix} \\] For \\(x = y= 0\\): We have \\[\\jacob{(0,0)} = \\begin{pmatrix} 0 &amp; b \\\\ 1 &amp; 0 \\end{pmatrix} \\] We find the eigenvalues by solving the characteristic equation: \\(\\det(\\lambda I - \\jacob{(0,0)}) = 0\\). This gives: \\[ \\begin{vmatrix} \\lambda &amp; -b \\\\ -1 &amp; \\lambda \\end{vmatrix} = \\lambda^2 - b = 0 \\] This has solutions \\(\\lambda = \\pm \\sqrt{b}\\). Clearly the magnitude of the eigenvalues, \\(\\sqrt{0.4}\\), is strictly less than \\(1\\) and so we conclude that \\((0,0)\\) is a sink. For \\(x = y = b-1\\): We have \\[\\jacob{(-3/5,-3/5)}=\\begin{pmatrix} 2(1-b) &amp; -b \\\\ -1 &amp; 0 \\end{pmatrix} \\] We solve the characteristic equation as before. \\[ \\det(\\lambda I - \\jacob{(b-1,b-1)}) = \\begin{vmatrix} \\lambda + 2(b-1) &amp; b \\\\ 1 &amp; \\lambda \\end{vmatrix} = \\lambda^2 + 2(b-1) \\lambda - b = 0. \\] This gives \\[\\lambda = (1-b) \\pm \\sqrt{(b-1)^2 + b} = (1-b) \\pm \\sqrt{ b^2 - b + 1}.\\] For \\(b = 0.4\\), we get eigenvalues \\(\\lambda_1 = (3 + \\sqrt{19})/5\\) and \\(\\lambda_2 = (3- \\sqrt{19})/5\\). Thus by Theorem 2.1 \\((-0.6, -0.6)\\) is a saddle point. To get an idea of the dynamics of the Hènon map, we plot below a bifurcation diagram where we keep \\(b\\) fixed at \\(0.4\\) and allow \\(a\\) to vary between \\(0\\) and \\(1.25\\). On the \\(y\\) axis we plot only the \\(x\\) values after sufficiently many iterates have been obtained. Feel free to experiment with the code. Figure 3.1: Bifurcation diagram of Hènon’s map Code Challenge The code for the plot is shown below. Do experiment with the code by changing the parameter range and initial value. Are you able to write a more efficient code? How about randomising the initial x values? Show code code from numpy import * from matplotlib.pyplot import * #define a function for the RHS of the Hènon map def hern_map(a,b,x,y): return (a- x**2 + b*y, x) def bifurc(f, x0, y0, r, b0, N, M): #f is the map, #r is the range from which to begin incrementing a #(x0,y0) is the coordinate of initial point #b0 is the fixed value of b #N the number of iterations and # M the number of iterations to plot #incrementing a values between r and 1.25 a= np.linspace(r,1.25,N) #initiating x and y values x= x0*np.ones(N) y= y0*np.ones(N) # fixed b b= b0*np.ones(N) # iterating the Henon map on the initial values for i in range(N): x,y=hern_map(a,b,x,y) if i &gt;= (N - M): # plotting the last M orbits; #green pixels with transparency .25 plot(a,x, &#39;g,&#39;, alpha=.25) axes().set_xlim(r,1.25) # setting x axis limit # title of plot title(&#39;Birfucation diagram of the Hènon map&#39;) # label of axes xlabel(&#39;a&#39;) ylabel(&#39;x&#39;) # rescaling plot if necessary figure_size=gcf().get_size_inches() factor= 0.65 gcf().set_size_inches(factor * figure_size) show() bifurc(hern_map,0.1,0.0,0,0.4,1500,300) We make some observations on the bifurcation diagram 3.1. The bifurcation diagram shows striking similarities with the bifurcation diagram of the logistic map (Figure 2.3). At a=0.27, a period-doubling bifurcation occurs: the fixed point loses stability and a period 2 orbit (which is a sink) emerges. The period \\(2\\) orbit becomes unstable at 0.85, at which point a period \\(4\\) orbit, an attracting orbit, emerges and so on. In general, for \\(b=0.4\\) and \\(a&gt; 0.85\\), the attractors of the Hènon map become more complex. 3.1.1 Stable and Unstable Manifolds In order to explore the dynamics of dynamical systems corresponding to higher dimensional maps, we require some more terminology – the notion of a manifold. Loosely speaking an \\(n\\)-dimensional manifold is a set of point whose geometry/topology “locally resembles” \\(\\R^{n}\\). That is a small segment of the manifold looks like a small segment of \\(\\R^{n}\\). For instance a \\(1\\)-dimensional manifold “locally resembles” a curve. Examples of one dimensional manifolds are a circle “o” or the disjoint union of two circles. The letters “A” and “X” are not manifolds, for instance, a small neighbourhood at the centre of “X” where different line segments meet does not resemble a line segment. The letter \\(S\\) is not a manifold as zooming in near either of its end points, we resemble a half line instead of a line. If we remove the two end points of \\(S\\), then it becomes a manifold.The letter \\(S\\) with its end points is a so-called manifold with boundary. Examples of 2-dimensional manifolds are spheres, tori since locally they look like a plane. Note that the unions of two manifolds is again a manifold. Let us now apply these definitions to dynamics of higher-dimensional maps. Recall that a fixed/periodic point of a map \\(f\\) is called a saddle/periodic saddle point if it has at least one attracting direction and one repelling direction. We can consider the set of all points which are attracted to the saddle point under iterations of the map, and likewise the set of all points which are repelled from the saddle under iterations of the map. These are respectively termed the stable manifold and unstable manifold of the saddle point \\(p.\\) The terminology is not accidental and we shall later see why stable and unstable manifolds of a fixed point are indeed manifolds. For the moment let us illustrate a saddle point with an example. Example 3.2 (Movement towards and away from a saddle point) Consider the map \\(\\vec{f}: \\R^2 \\to \\R^2\\) given by \\((x,y) \\mapsto (2x, y/2)\\). This map has one fixed point at \\(x = y = 0\\). The Jacobian matrix of \\(\\vec{f}\\) at the point \\((0,0)\\) is the matrix \\[\\begin{pmatrix} 2 &amp; 0 \\\\ 0 &amp; 1/2 \\end{pmatrix} \\] which has eigenvalues \\((2, 1/2)\\) (eigenvectors corresponding to the \\(x\\) and \\(y\\) axis respectively). Thus we see that along the \\(x\\) axis we have movement away from the saddle point at the origin and along the \\(y\\) axis we have movement towards the origin. 3.2 Stability of manifolds associated with a saddle In this module most higher dimensional maps we consider will be one-to-one/injective. This property means that for most functions we consider, their inverses exist. Definition 3.1 Let \\(\\vec{f}\\) be a map on a subset of \\(\\R^{n}\\). Then \\(\\vec{f}\\) is called one-to-one/injective if for \\(\\vec{v}_1, \\vec{v}_2\\) in the domain of \\(\\vec{f}\\) \\[ \\vec{f}(\\vec{v}_1) = \\vec{f}(\\vec{v}_2) \\implies \\vec{v}_1 = \\vec{v}_2.\\] That is, \\(\\vec{f}\\) is injective if and only if distinct points in its domain have distinct images. The one-to-one property means that we can “reverse” the map in order to find the inverse of \\(\\vec{f}\\). That is if \\(\\vec{f}(\\vec{v}_1) = \\vec{v}_2\\), then \\(\\vec{f}^{-1}(\\v{v}_2) = \\v{v}_1\\). Being one-to-one guarantees that there is no ambiguity in this definition; there is one and only one element in the domain of \\(\\vec{f}\\) whose image under \\(\\vec{f}\\) is \\(\\vec{v}_2\\). Let us now formally define stable and unstable manifolds of a saddle fixed/periodic point. Definition 3.2 (Stable and unstable manifolds) Let \\(\\vec{f}\\) be a (smooth) one-to-one map on a subset of \\(\\R^{n}\\) and let \\(\\vec{p}\\) be a saddle fixed or saddle periodic point of \\(\\vec{f}\\). The stable manifold of \\(\\vec{p}\\) denoted \\(\\stab{\\vec{p}}\\) is the set of points \\(\\vec{v}\\) in the domain of \\(\\vec{p}\\) such that \\[ \\lim_{k \\to \\infty} |\\vec{f}^{k}(\\vec{v}) - \\vec{f}^{k}(\\vec{p})| = 0. \\] The unstable manifold of \\(\\vec{p}\\) denoted \\(\\unstab{\\vec{p}}\\) is the set of points \\(\\vec{v}\\) in the domain of \\(\\vec{p}\\) such that \\[ \\lim_{k \\to \\infty} |\\vec{f}^{-k}(\\vec{v}) - \\vec{f}^{-k}(\\vec{p})| = 0. \\] Notice that the unstable manifold of \\(\\vec{p}\\) is simply the stable manifold of \\(\\vec{p}\\) under the inverse map. Also observe that \\(\\stab{\\v{P}}\\) and \\(\\unstab{\\v{p}}\\) both contain \\(\\v{p}\\). 3.2.1 Inverse Maps – a reminder As discussed earlier on, for a one-to-one map \\(\\vec{f}\\) on a subset of \\(\\R^{n}\\) its inverse map \\(\\vec{f}^{-1}\\) exists. In particular such a map \\(\\vec{f}\\) is called invertible. Example 3.3 Consider the map \\(\\vec{f}_{1}: \\R^2 \\to \\R^2\\) by \\((x,y) \\mapsto (x^2, y^2)\\). This is not a one-to-one map on \\(\\R^2\\), for instance \\(\\vec{f}_1(-1, -1) = \\vec{f}_1(1, -1) = \\vec{f}_1(-1,1)\\) and so on. If, however, we restrict the domain to the set \\(\\R^{2+}\\) of pairs of positive real numbers, then \\(\\vec{f}\\) is indeed one-to-one (no two distinct positive real numbers square to the same value). The inverse of \\(\\vec{f}_{1}\\) as a map on \\(\\R^{2+}\\) is simply \\(\\vec{f}_1^{-1}(x,y) = (\\sqrt{x}, \\sqrt{y})\\). The map \\(\\vec{f}_{2}: \\R^2 \\to \\R^2\\) by \\((x,y) \\mapsto (x^3, y^3)\\) is a one-to-one map. Now two distinct real numbers cube to the same value. The inverse map of \\(\\vec{f}_{2}\\) is given by taking cube roots. That is \\(\\vec{f}_2^{-1}(x,y) = (\\sqrt[3]{x}, \\sqrt[3]{y})\\). How do we compute the inverse map in general? In general we make use of the one-to-one property as follows. Suppose \\(\\vec{f}^{-1}(\\vec{v}_1) = \\v{v}_2\\), then \\(\\vec{f}(\\vec{v}_2) = \\v{v}_1\\). We then solve the latter equation to obtain the coordinates of \\(\\v{v}_2\\) in terms of the coordinates of \\(\\v{v}_{1}\\). Let us illustrate this with an example. Example 3.4 Let \\(\\vec{f}= (x+2y, x^3)\\) be a map on \\(\\R^2\\). Let \\((x_1, y_1)\\) be such that \\(f(x_1, y_1) = (x, y)\\) (note that \\(\\v{f}^{-1}(x,y) = (x_1, y_1)\\) necessarily as \\(\\v{f}\\) is one-to=one). Then \\[\\begin{align*} &amp;x = x_1 + 2y_1\\\\ &amp;y = x_1^3 \\end{align*}\\] Thus we get \\[\\begin{align*} &amp;x_1 = y^{1/3}\\\\ &amp;y_1 = (x - x_1)/2 = (x -y^{1/3})/2 \\end{align*}\\] Therefore \\(\\v{f}^{-1}(x,y) = (x_1,y_1) = (y^{1/3}, (x- y^{1/3})/2)\\). The reader can verify that \\(\\v{f}(\\v{f}^{-1}(x,y)) = (x,y)\\). 3.2.2 How do we characterise the stable and unstable manifolds of a saddle? Identifying the stable and unstable manifolds of a saddle fixed point using Definition 3.2, in general, is quite tricky especially when we have no nice closed form expression for \\(\\v{f}^{k}(\\v{x})\\) and \\(\\v{f}^{-k}(\\v{x})\\). However, Definition 2.7 gives us a clue. The stable manifold must be tangent, at the saddle point, to the line that passes through the saddle in the direction of the eigenvector corresponding to the (contracting) eigenvalue which is strictly less than \\(1\\); the unstable manifold must be tangent at the saddle point to the line that passes through the saddle in the direction of the (expanding) eigenvector corresponding to the eigenvalue which is strictly larger than \\(1\\). This together with the fact that that stable and unstable manifolds of saddles are indeed manifolds can be enough. For example if we know that the stable and unstable manifolds must be \\(1\\)-dimensional manifolds, then all we need to do is find a curve which contains the saddle, is tangent to the relevant line and satisfies the relevant condition in Definition 3.2. In general though, we will need to estimate the manifolds of the saddle via some computational means. If we restrict simply to the plane, then with the aid of the Stable Manifold Theorem1, we can say quite a bit. Plane Maps For a map \\(\\v{f}\\) of the plane, as a consequence of the Stable Manifold Theorem, stable and unstable manifolds of a saddle fixed point \\(\\v{p}\\) are always one-dimensional manifolds i.e. either straight lines or curves. Therefore, in the plane, in order to identify the stable and unstable manifold of a saddle we need to find a one-dimensional manifold \\(C\\) satisfying the following conditions: \\(C\\) passes though the saddle, \\(C\\) is invariant under \\(\\v{f}\\) and \\(\\v{f}^{-1}\\), that is \\[C = \\v{f}(C) = \\v{f}^{-1}(C),\\] \\(C\\) is tangent at the saddle either to the line through the saddle in the direction of the contracting eigenvector (if \\(C\\) is the stable manifold), or, to the line through the saddle in the direction of the expanding eigenvector (if \\(C\\) is the unstable manifold), For all \\(\\v{v} \\in C\\) either \\[\\lim_{k \\to \\infty} |\\v{f}^{k}(\\v{v}) - \\v{f^{k}}(\\v{p})| = 0\\] (if \\(C\\) is the stable manifold) or \\[\\lim_{k \\to \\infty} |\\v{f}^{-k}(\\v{v}) - \\v{f^{-k}}(\\v{p})| = 0\\] (when \\(C\\) is the unstable manifold.) For linear maps (only linear terms in the definition of the map; alternatively the usual definition of linear maps from MT2501/MT3501), Definition 2.7 gives the whole answer in \\(n\\)-dimensions and not only in the plane. Linear Maps For a linear map, in 2-dimensions the eigenvector corresponding to the contracting eigenvalue determine the stable manifold — the line through the saddle point in the direction of the eigenvector; the eigenvector corresponding to the expanding eigenvalue determines the unstable manifold — the line through the fixed point in the direction of the eigenvector. In higher-dimensions the stable manifold is determined by the subspace spanned by the contracting eigenvectors (we translate so that the origin is moved to the saddle fixed point) and the unstable manifold is determined by the subspace spanned by the contracting eigenvectors (translate such that the origin is moved to the fixed point). Let us do some examples to illustrate this. Example 3.5 Consider the linear map \\(\\v{f}(x,y) = (2x, y/2)\\) from Example 3.2. We showed that \\((0,0)\\) is a saddle point of \\(\\v{f}\\). In particular, we showed that the Jacobian of \\(\\v{f}\\) at \\((0,0)\\) has eigenvalues \\(2, 1/2\\) with corresponding eigenvectors \\(\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}\\) and \\(\\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}\\). We concluded that points lying on the \\(x\\)-axis move away from the origin under iterations of the map \\(\\v{f}\\) while points lying on the \\(y\\)-axis move towards the orgin under applications of the map \\(\\v{f}\\). From this it follows that the \\(x\\)-axis is the unstable manifold/outgoing direction of the saddle point \\((0,0)\\) and the \\(y\\)-axis is the stable manifold/incoming direction of \\((0,0)\\). Example 3.6 Let us again consider a linear map \\(\\v{f}(x,y) = (-2x + 5y/2, -5x + 11y/2)\\). The fixed points of \\(\\v{f}\\) are found by solving \\(\\v{f}(x,y) = (x,y)\\) which gives \\((0,0)\\) as the unique fixed point. The Jacobian of \\(\\v{f}\\) is simply the matrix of coefficients of \\(\\v{f}\\) since \\(\\v{f}\\) is a linear map. That is \\[ \\jacob{(0,0)} = \\begin{pmatrix} -2 &amp; 5/2 \\\\ -5 &amp; 11/2 \\end{pmatrix} \\] We find the eigenvalues in the usual way to be \\(0.5\\) and \\(3\\). The eigenvector corresponding to eigenvalue \\(\\lambda \\in \\{0.5, 3\\}\\) can then be found by solving the equation \\((A- \\lambda I) \\vec{v} = \\vec{0}\\) where \\(A = \\jacob{(0,0)}\\). This gives eigenvectors \\(\\begin{pmatrix}1 \\\\ 1 \\end{pmatrix}\\) and \\(\\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}\\). Thus, we see that points on the line \\(y = x\\) corresponding to the first eigenvalue move closer to the origin under iterations of the map \\(\\v{f}\\) since such vectors are scaled by a factor of \\(0.5\\). Points on the line \\(y = 2x\\) (that is the set of points \\(\\left\\{t \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} : t \\in \\R \\right\\}\\)) move away from the orgin under applications of \\(f\\) as they are scaled by a factor of \\(3\\). Therefore the line \\(y=x\\) is the stable manifold of the saddle \\((0,0)\\) and the line \\(y=2x\\) is the unstable manifold of the saddle \\((0,0)\\). Figure 3.2: Stable and unstable manifolds of a regular saddle Example 3.7 We consider again a linear map \\(\\v{f}(x,y) = (2x+5y, -0.5y)\\). This has a fixed point at \\((0,0)\\). Once more we compute the eigenvalues and eigenvectors of the Jacobian of \\(\\v{f}\\) at the fixed points (just the matrix of coefficients for a linear map) using the usual methods of linear algebra. We get eigenvalues \\(2, -0.5\\) and corresponding eigenvectors \\(\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}\\) and \\(\\begin{pmatrix} 2 \\\\ -1 \\end{pmatrix}\\). We see that the line \\(y = -x/2\\) in the direction of the vector \\((2, -1)\\) is the stable manifold of the saddle \\((0,0)\\) — points on this line move towards the origin under iterations of \\(\\v{f}\\). The \\(x\\)-axis (the line \\(y=0\\)) is the unstable saddle points on this line move away from the origin under iterations of the map. Notice the new interesting behaviour that occurs on the stable manifold of \\((0,0)\\). On each iteration of the map, a point on the saddle flips from one side of the origin to another. Generally this behaviour occurs happens for all fixed points for which the Jacobian has negative eigenvalues. A saddle with at least one negative eigenvalue is sometimes called a flip saddle. Figure 3.3: Stable and unstable manifold of a flip saddle 3.3 Problem Sheet 3 For week 4. Question 3.1 The Hènon map is defined by \\[\\v{f}(x,y) = (a-x^2 + by,x)\\] with real parameters \\(a\\) and \\(b\\). Show that the two fixed points of the Hènon map are given by \\[\\v{p}_{+} = (x_{+}, x_{+}), \\quad p_{-} = (x_{-}, x_{-})\\] with \\[ x_{\\pm} = \\frac{1}{2} \\left(b - 1 \\pm \\sqrt{(b-1)^2 + 4a} \\right), \\quad (b-1)^2 + 4a \\ge 0.\\] Investigate the stability of these fixed points for \\(b=1\\) and \\(a &gt; 0\\) and classify them as sinks, sources or saddles. Show Solution 3.1 Solution 3.1 This is a “show” question so we cannot simply check that \\(\\v{p}_{\\pm}\\) are fixed points of \\(\\v{f}\\), we need to demonstrate it. We solve the equations: \\[\\begin{align} x &amp;= a- x^2 + by \\tag{3.1} \\\\ y &amp;= x \\tag{3.2} \\end{align}\\] Substituting (3.2) in to (3.1) we have: \\[ x^2 + (1-b)x - a = 0.\\] This can now be solved using the quadratic formula: \\[ x _{\\pm} = \\frac{1}{2} \\left(b-1 \\pm \\sqrt{ (b-1)^2 + 4a} \\right)\\] as required. We use Theorem 2.1 to classify the fixed points of the map. The Jacobian \\(\\jacob(x,y)\\) of \\(\\v{f}(x,y)\\) is given by: \\[\\begin{pmatrix} -2x &amp; 1 \\\\ b &amp; 0 \\end{pmatrix} \\] At the points \\((x_{\\pm}, x_{\\pm})\\) we have: \\[A_{\\pm} = \\jacobr(x_{\\pm}, x_{\\pm}) =\\begin{pmatrix} - \\left(b-1 \\pm \\sqrt{(b-1)^2 + 4a}\\right) &amp; 1 \\\\b &amp; 0 \\end{pmatrix}.\\] Eigenvalues are found by solving \\(\\det(\\lambda I - A_{\\pm}) = 0\\). Recalling that \\(b=1\\), we have: \\[ \\lambda ( \\lambda + \\pm 2\\sqrt{a} ) - 1 = \\lambda^2 \\pm 2\\lambda \\sqrt{a} - 1 = 0.\\] For the fixed point \\(\\sqrt{a}\\): \\[\\lambda^2 + 2\\lambda \\sqrt{a} - 1\\] has eigenvalues \\[\\lambda_{\\pm} = -\\sqrt{a} \\pm \\sqrt{a + 1}.\\] Notice that as \\(a&gt; 0\\), \\(|-(\\sqrt{a} +\\sqrt{a + 1})| &gt; 1\\). On the other hand, \\(- (\\sqrt{a} - \\sqrt{a+1})\\), can be written, multiplying top and bottom by \\(\\sqrt{a} + \\sqrt{a+1}\\) as \\(1/(\\sqrt{a} + \\sqrt{a+1}) &lt;1\\) for \\(a&gt;0\\). Therefore, the point \\((\\sqrt{a}, \\sqrt{a})\\) is a saddle point when \\(a&gt;0\\). The eigenvalue \\(-\\sqrt{a}\\) is similarly dealt with. In this the eigenvalues are given by \\(\\lambda^2 + 2\\lambda \\sqrt{a} - 1\\). This gives eigenvalues \\(\\lambda_{\\pm} = -\\sqrt{a} \\pm \\sqrt{a +1}\\). Now \\(|\\lambda_{+}| = |\\sqrt{a} - \\sqrt{a+1}| &lt;1\\) (\\(a&gt;0\\)) as before; \\(|\\lambda_{-}| = |\\sqrt{a} + \\sqrt{a+1}| &gt; 1\\). Therefore the fixed point at \\(-\\sqrt{a}\\) is also a saddle point. Note that When \\(a =0\\), both fixed points coincide at \\((0,0)\\) which is unstable. Question 3.2 Let \\[\\v{f}(x,y,z) = (x^2y, y^2, xz + y)\\] be a map on \\(\\R^3\\). Find the fixed points of \\(\\v{f}\\) and investigate their stability. Show Solution 3.2 Solution 3.2 The fixed points of \\(f\\) are found by solving the system of equations \\[\\begin{align} x^2y &amp;= x \\tag{3.3} \\\\ y^2 &amp;= y \\tag{3.4}\\\\ xz + y &amp;= z \\tag{3.5} \\end{align}\\] From Equation (3.4) we find that \\(y = 1\\) or \\(y=0\\). If \\(y=0\\), then \\(x\\) and \\(z\\) are both also equal to \\(0\\). If \\(y=1\\), then \\(x\\) is equal to \\(0\\) or \\(1\\). If \\(x =0\\), \\(z = 1\\). If \\(x = 1\\), then there is no solution to Equation (3.5). Therefore the fixed points are \\((0,0,0)\\) and \\((0,1,1)\\). We compute \\(\\jacob(x,y,z)\\) in order to investigate the stability of the fixed points. We have \\[ \\jacob(x,y,z) = \\begin{pmatrix} 2xy &amp; x^2 &amp; 0 \\\\ 0 &amp; 2y &amp; 0 \\\\ z &amp; 1 &amp; x \\end{pmatrix}. \\] At \\((0,0,0)\\) \\[ A=\\jacob(0,0,0) = \\begin{pmatrix} 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 \\end{pmatrix}. \\] The eigenvalues of \\(A\\) are the roots of the polynomial \\(\\det(\\lambda I -A) = x^3\\). Therefore \\(0\\) is the sole eigenvalue of \\(A\\) and the point \\((0,0,0)\\) is a sink. At the point \\((0,1,1)\\) we have: \\[ B=\\jacob(x,y,z) = \\begin{pmatrix} 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 2 &amp; 0 \\\\ 1 &amp; 1 &amp; 0 \\end{pmatrix}. \\] The eigenvalues of \\(B\\) are the roots of \\(\\det(\\lambda I - B) = (x)^2 (x-2)\\). This gives two eigenvalues \\(2\\) and \\(0\\). Therefore the point \\((0,1,1)\\) is a saddle point. Question 3.3 Determine the fixed points of the map \\[\\v{f}(x,y) = (x+y,y+a\\sin(bx)),\\] where \\(a\\) and \\(b\\) are real and positive and investigate the stability of the fixed points. Show Solution 3.3 Solution 3.3 The fixed point of \\(\\v{f}\\) are found by solving \\[\\begin{align} x+y &amp;= x \\\\ y+a \\sin(bx) &amp;= y \\\\ \\end{align}\\] This has solutions \\(y= 0\\) and \\(x = n\\pi/b\\) for \\(n \\in \\Z\\). The matrix \\(\\jacob(x,y)\\) is \\[ \\begin{pmatrix} 1 &amp; 1 \\\\ ab\\cos(bx) &amp; 1 \\end{pmatrix}. \\] At \\((n\\pi/n,0)\\) we have \\[ A_n=\\jacob(n\\pi/b,0) = \\begin{pmatrix} 1 &amp; 1 \\\\ ab (-1)^n &amp; 1 \\end{pmatrix}. \\] The eigenvalues are the roots of \\((\\lambda-1)^2 - ab(-1)^n\\), which are \\(\\lambda_{\\pm n} =1\\pm \\sqrt{ab}\\) when \\(n\\) is even and \\(\\lambda_{\\pm n} = 1 \\pm i \\sqrt{ab}\\) when \\(n\\) is odd. For \\(n\\) even, \\(|\\lambda_{+n}| = |1 + \\sqrt{ab}|&gt;1\\). Therefore for \\(n\\) even, \\((n\\pi/b, 0)\\) is unstable. It is a saddle when \\(ab &lt; 4\\). For \\(n\\) odd, \\(|\\lambda_{\\pm n}| = |\\sqrt{1 + ab}| &gt;1\\) and so \\((n\\pi/b,0)\\) is a source/unstable point when \\(n\\) is odd. Question 3.4 Consider the Hènon map \\[\\v{f}(x,y) = (a-x^2 + by,x)\\] for \\(a&gt;0\\) and \\(b = 1- \\sqrt{a}\\). Verify that \\(\\{(\\sqrt{a},0),(0,\\sqrt{a})\\}\\) is a period \\(2\\)-orbit of the Hènon map. Determine the stability of the period-2 orbit. Show Solution 3.4 Solution 3.4 We show that \\(\\v{f}(\\sqrt{a},0) = (0,\\sqrt{a})\\) and \\(\\v{f}(0,\\sqrt{a}) = (\\sqrt{a},0)\\). We have \\[\\begin{align*} \\v{f}(\\sqrt{a},0)&amp;= (a- a, \\sqrt{a}) = (0, \\sqrt{a}) \\\\ \\v{f}(0,\\sqrt{a})&amp;= (a + (1- \\sqrt{a})\\sqrt{a},0) = (\\sqrt{a},0) \\end{align*}\\] as required. The Jacobian of matrix of \\(\\v{f}\\) is given by \\[ \\begin{pmatrix} -2x &amp; 1- \\sqrt{a} \\\\ 1 &amp; 0 \\end{pmatrix}. \\] Using the chain rule for higher dimensional maps, the Jacobian of \\(\\v{f}^2\\) at the period \\(2\\) point is given by \\[\\begin{align*} A=\\jacob(0,\\sqrt{a}) \\cdot \\jacob(\\sqrt{a},0) &amp;= \\begin{pmatrix} 0 &amp; 1- \\sqrt{a} \\\\ 1 &amp; 0 \\end{pmatrix}\\begin{pmatrix} -2\\sqrt{a} &amp; 1- \\sqrt{a} \\\\ 1 &amp; 0 \\end{pmatrix} \\\\ &amp;= \\begin{pmatrix} 1- \\sqrt{a} &amp; 0 \\\\ -2\\sqrt{a} &amp; 1- \\sqrt{a} \\end{pmatrix}. \\end{align*}\\] The eigenvalues of this matrix are the roots of \\(\\det{\\lambda I - A} = (\\lambda -1 + \\sqrt{a})^2\\). There is only one root, \\(\\lambda =1 - \\sqrt{a}\\). The absolute value of \\(\\lambda\\) is strictly less than one precisely when \\(0&lt; a &lt; 4\\). The period \\(2\\) point is stable in this range and unstable for \\(a&gt;4\\). Question 3.5 Find the fixed points of the map \\[\\v{f}(x,y) = \\left(\\frac{4}{\\pi}\\tan^{-1}(x), \\frac{y}{2}\\right)\\] where \\(\\tan^{-1}(x): \\R \\to (-\\pi/2, \\pi/2)\\) is the inverse tangent function. Determine the stability of the fixed points. Show Solution 3.5 Solution 3.5 The fixed points are found by solving: \\[\\begin{align*} &amp;\\frac{4}{\\pi}\\tan^{-1}(x) = x \\\\ &amp;\\frac{y}{2} = y \\end{align*}\\] The second equation gives \\(y = 0\\). For the first let us rewrite the equation as \\(x = \\tan \\frac{\\pi x}{4}\\). Now by definition of \\(\\tan^{-1}\\), \\(x\\) must be between \\(-2\\) and \\(2\\). Clearly \\(x = 0\\) is a solution. For non-zero solutions, it suffices to consider the interval \\((0,2)\\); since \\(x\\) and \\(\\tan\\) are both odd, if \\(\\tan (a\\pi/4 ) = a\\) then \\(\\tan(- a\\pi/4 ) = -a\\). Notice that for \\(x\\) between \\(1\\) and \\(2\\), \\(\\tan\\frac{\\pi x}{4} &gt;x\\) (indeed it has slope bigger than 1 in this interval). Notice also that \\(x \\ge \\tan \\frac{\\pi x}{4}\\) in the interval \\((0,1)\\). Indeed the function \\(x-\\tan (\\pi x/4)\\) has only one turning point in the interval \\((0,1)\\). Therefore as \\(x - \\tan\\frac{\\pi x}{4} = 0\\) when \\(x =1\\), we conclude that \\(x=1\\) is the only non-zero solution to \\(x - \\tan\\frac{\\pi x}{4} = 0\\) in the interval \\((0,1)\\). We conclude that the solutions to \\(x = \\tan \\frac{\\pi x}{4}\\) for \\(x \\in (-2,2)\\) are \\(0\\) and \\(\\pm 1\\). The Jacobian of \\(\\v{f}\\) is given by \\[ \\begin{pmatrix} \\frac{4}{\\pi(1+ x^2)} &amp; 0 \\\\ 0 &amp; 1/2 \\end{pmatrix} \\] This is a diagonal matrix and so its eigenvalue are given by its diagonal entries. In particular we have \\(\\frac{4}{\\pi(1 +x^2)}\\) and \\(1/2\\). Therefore we see that the point \\((0,0)\\) is a saddle point while the points \\((\\pm 1, 0)\\) are both sinks. Notice that the stable manifold of \\((0,0)\\) is the \\(y\\)-axis (which is tangent to the \\(y\\)-axis — the line through the origin the direction of the eigenvector \\((0,1)\\)) and the unstable manifold lies along the \\(x\\)-axis, it is the open interval \\((-1, 1)\\). References "],["Higherdimstability.html", "Chapter 4 Higher-dimensional stability 4.1 Non-linear examples 4.2 Chaotic Orbits 4.3 Fractals and deterministic dynamical systems 4.4 Problem Sheet 4", " Chapter 4 Higher-dimensional stability Covers Chapter 3 Sections 3.1 and 3.2 and Chapter 4 Sections 4.1 to 4.4 (Alligood, Sauer, and Yorke 2000) We concluded Chapter 3 by characterising the stable and unstable manifolds of linear maps. We now turn to non-linear maps. We begin with a map we have already encountered (Examples 2.2 3.1). 4.1 Non-linear examples Example 4.1 (Hènon map III) Recall that the Hènon map is the map \\(\\vec{f}_{a,b}(x,y) = (a-x^2 + by, x)\\). This has an associated discrete time dynamical system: \\[\\begin{align*} &amp;x_{n+1} = a- x_n^2 + by_n \\\\ &amp;y_{n+1} = x_{n} \\end{align*}\\] Notice that the new \\(x\\) terms depends in a non-linear way on the preceding \\(x\\) and \\(y\\) terms. In Example 3.1 we plotted a bifurcation diagram for the Hènon map and saw that it had similar dynamics to the logistic map (2.3). Let us investigate the dynamics of the orbits further. Figure 4.1 show orbits for the Hernon map for \\(b\\) fixed at \\(-0.3\\) and, \\(a = 1.28\\) for the left figure and \\(1.4\\) for the right figure. The figure is obtained by iterating the map for each initial value until the orbits either converge to the period-2 sink (plotted as crosses in both figures) or diverge towards infinity. The initial values that converge to the period \\(2\\) sink are coloured white and initial values that diverge are coloured black. Thus the black points form the basin of infinity of the period \\(2\\)-sink while the white points are the basin of attraction of the period-\\(2\\) sink. Figure 4.1: A square of initial conditions for the Hènon map with b=-0.3 A similar picture is seen when we fix \\(b\\) at \\(-0.3\\) and increase \\(a\\) to \\(2\\): orbits in the black region diverge to infinity, and orbits in the white region are attracted to the “2-piece” attractor in the white region. Figure 4.2: Attractors for the Hènon map with a=2, b=-0.3 Figure 4.3 zooms in on the white region. We choose a value for \\(a\\) (keeping \\(b\\) fixed as \\(0.4\\)), we iterate the Hènon map for different start values in the white region until they settle down to an attracting orbit. Note that as we increase \\(a\\) the length of the attracting orbits increase and then decrease again. Figure 4.3: Attractors for the Hernon map with b=0.4 4.1.1 Chaos in 1-dimensional maps We return to the notion of chaos for \\(1\\)-dimensional maps which we have so far been a little vague about. Recall that in Section 2.2 we said that chaos has at least 2 distinct characteristics Non-periodicity Sensitive dependence on initial conditions. We now introduce a third component in characterising chaotic behaviour. This third characteristic is determined by the Lyapunov exponent (named after the mathematician Aleksandr Mikhailovich Lyapunov ). The Lyapunov exponent estimates the rate of separation of trajectories which are infinitesimally close to each other and gives us a way of making the notion of “sensitive dependence on initial conditions” precise. Let us give a precise definition. Definition 4.1 (Lyapunov exponent) Let \\(f\\) be a (smooth) map defined on a subset of \\(\\R\\). The Lyapunov number \\(L(x_1)\\) of the orbit \\((x_1, x_2, \\ldots )\\) is defined by the following limit (if it exists): \\[ L(x_1) = \\lim_{n\\to \\infty}(|f&#39;(x_1)| |f&#39;(x_2)|\\ldots |f&#39;(x_n)|)^{\\frac{1}{n}} .\\] The Lyapunov exponent \\(h(x_1)\\) is defined by the following limit (if it exists): \\[ h(x_1) = \\lim_{n \\to \\infty} \\dfrac{\\ln|f&#39;(x_1)| + \\ln|f&#39;(x_2)|+ \\ldots + \\ln|f&#39;(x_n)|}{n}.\\] Note that the Lyapunov exponent \\(h\\) exists/is well-defined if and only if the Lyapunov number \\(L\\) exists and is non-zero in which case \\(\\ln L = h\\). The requirement that the limit exists is necessary since the limit might not exist for some orbits. For instance if an orbit with initial point \\(x\\) has \\(f&#39;(x) = 0\\), then automatically the Lyapunov exponent of the orbit will be undefined. Example 4.2 Let \\(f\\) be a 1D map with a fixed point \\(p\\). Then the Lyapunov number of the orbit \\(p\\) is computed as follows: \\[ L(p) = \\lim_{n \\to \\infty} (|f&#39;(p)||f&#39;(p)| \\ldots |f&#39;(p)|)^{\\frac{1}{n}} = \\lim_{n \\to \\infty} (|f&#39;(p)|^n)^{\\frac{1}{n}} = |f&#39;(p)|.\\] Therefore the Lyapunov exponent of the orbit of \\(p\\) is \\(\\ln(|f&#39;(p)|)\\). For a period \\(k\\) orbit \\((x_1, x_2, \\ldots, x_{k})\\), the Lyapunov exponent is given by \\[h(x_1) = \\dfrac{\\ln|f&#39;(x_1)| + \\ln|f&#39;(x_2)|+ \\ldots + \\ln|f&#39;(x_k)|}{k}\\] and the Lyapunov number is \\[(|f&#39;(x_1)| |f&#39;(x_2)|\\ldots |f&#39;(x_k)|)^{\\frac{1}{k}}.\\] The other notion we have been rather vague about so far is what it means to be “non-periodic.” Before we say exactly what we mean by this, we introduce the notion of being “close to” a periodic orbit. Definition 4.2 Let \\(f\\) be a 1D map. An orbit \\((x_1, x_2, \\ldots)\\) is called asymptotically periodic if it converges (pointwise) to a periodic orbit. That is, \\((x_1, x_2, \\ldots)\\) if there exists a periodic orbit \\((y_1, y_2, \\ldots)\\) (of period \\(k\\) say) such that \\[ \\lim_{n\\to \\infty} |x_n - y_n| = 0. \\] The orbit \\((x_1, x_2, \\ldots)\\) is called eventually periodic if there is some \\(N \\in \\N\\) such that \\(|x_m - y_m| = 0\\) for all \\(m&gt; N\\). Note that the orbit of any point in the basin of attraction of a periodic point is asymptotically periodic. When we introduced the Lyapunov exponent, we said it measures how quickly trajectories which are infinitesimally close to one another drift apart. In particular we expect two points whose orbits “eventually coincide” to have the same Lyapunov exponent (if it exists). Thus, the following result which says that the Lyapunov exponent of an orbit asymptotically periodic orbit is equal to the Lyapunov exponent of the periodic orbit it converges to is perhaps not surprising. Theorem 4.1 Let \\(f\\) be a 1D map. Let \\((x_1, x_2, \\ldots)\\) be an orbit which is asymptotically periodic and suppose that it converges to the periodic orbit \\((y_1, y_2, \\ldots)\\). Suppose further that \\(f&#39;(x_i) \\ne 0\\) for all \\(i\\). Then the Lyapunov exponent of the orbits \\((x_1, x_2, \\ldots)\\) and \\((y_1, y_2, \\ldots)\\) are identical (assuming they both exist). 4.2 Chaotic Orbits We can now define formally what it means for an orbit of a 1D map to be chaotic in a special case – bounded orbits. An orbit \\((x_1, x_2, \\ldots)\\) of a 1D map \\(f\\) is said to be bounded if there is an \\(M \\in \\R\\) such that \\(|x_i| &lt; M\\) for all \\(i\\). Definition 4.3 (Chaotic orbits) Let \\(f\\) be a 1D map and \\((x_1, x_2, \\ldots)\\) be a bounded orbit. Then the orbit is chaotic if it is not asymptotically periodic (Non-periodicity); the Lyapunov exponent \\(h(x_1)\\) is greater than zero (Sensitivity to initial conditions). Example 4.3 (Doubling map) Define the map \\(f: [0,1) \\to [0,1)\\) as follows: \\(f(x) = \\begin{cases} 2x \\quad 0 \\le x &lt; 1/2 \\\\ 2x -1 \\quad 1/2 \\le x &lt; 1 \\end{cases}\\) Note that this map can equivalently be written as \\(f(x) = 2x \\mod{1}\\). Figure 4.4 gives a sketch of the function. Figure 4.4: Doubling map Note that \\(f\\) is not a smooth map, it is not continuous or differentiable at a \\(1/2\\) (although it is a piecewise smooth function and so differentiable at all other points). Let us investigate the nature of orbits of points not equal to \\(1/2\\). We begin by computing the Lyapunov exponent. Let \\((x_1, x_2, \\ldots)\\) be an orbit such that \\(x_i \\ne 1/2\\) for all \\(i \\in \\N\\), then: \\[\\begin{align*} h(x) &amp;= \\lim_{n\\to \\infty} \\dfrac{1}{n}\\sum_{i=1}^{\\infty} \\ln |f&#39;(x_i)| \\\\ &amp;= \\lim_{n\\to \\infty} \\dfrac{1}{n}\\sum_{i=1}^{\\infty} \\ln 2 = \\ln 2 &gt; 0 \\end{align*}\\] Therefore an orbit which is not asymptotically periodic (and so which avoids the problematic point at \\(1/2\\)) is a chaotic orbit. Let us see if we can characterise the asymptotically periodic orbits. The nature of the map means that it makes sense to consider binary expansion. That is for each \\(x \\in [0,1)\\) we write \\(x\\) as \\(0. b_1 b_2 \\ldots\\) corresponding to the sum: \\[ x = \\sum_{n=1}^{\\infty} \\dfrac{b_n}{2^{n}}.\\] Now the effect of multiply by \\(2\\) is simply to shift the decimal point rightward, working modulo \\(1\\) means we get rid of the \\(b_1\\) term. That is \\(f(x) = 0.b_2 b_3 \\ldots\\). It therefore follows that a periodic orbit corresponds to an element of \\([0,1)\\) of the form \\(0.(b_1 b_2 \\ldots b_k)(b_1 b_2 \\ldots b_k)\\ldots = 0.\\overline{(b_1 b_2 \\ldots b_k)}\\). It therefore follows that an eventually periodic orbit corresponds to a rational numbers (rational numbers are characterised by the property that they have eventually periodic base \\(n\\) expansions). Now, it is not hard to see that an asymptotically periodic orbit of the map \\(f\\) must in fact be eventually periodic. Thus the asymptotically periodic orbits of the map \\(f(x)\\) are precisely the rational numbers in \\([0,1)\\). Consequently, all irrational points give rise to chaotic orbits of \\(f\\). Figure 4.5 shows a cobweb plot of the doubling map with irrational initial point. Figure 4.5: Cobweb plot of doubling map with irrational initial point 4.2.1 Fractals Although we have thus far not explicitly drawn it out, fractals have been hiding in our discussions of dynamical systems so far. For instance attracting sets dynamical systems with chaotic behaviour are usually fractal sets and the boundaries of basins of attractions can a have a fractal structure. What exactly is a fractal? This is not a course in fractal geometry so we are going to be a little vague. There are two main characteristics of a fractal: complicated structure over a wide range of length scales, self-similarity — repetition of structures at different length scales. A key example of a fractal is the Cantor set. We can construct this set using an iterative process as follows. Consider the unit interval \\(k_0 := [0,1]\\). In the first pass we delete the middle third from the interval so we obtain the set \\(k_1:=[0,1] \\backslash (1/3, 2/3) = [0, 1/3] \\sqcup [2/3, 1]\\). We repeat the process on the two subintervals created, we delete the middle third of each (\\((1/9,2/9), (7/9, 8/9)\\)) to obtain \\(4\\) intervals making up a set \\[ k_2:= [0,1/9] \\sqcup [2/9, 3/9] \\sqcup [6/9, 7/9] \\sqcup [8/9,1].\\] We repeat the process on each of the remaining subintervals. Continuing on in this way indefinitely gives rise to a set \\(k_{\\infty}=\\CC\\) of points on the unit interval. Figure 4.6 gives a graphical depiction of this construction. The resulting set \\(\\CC\\) is call the middle-third Cantor set after the mathematician Georg Cantor who first studied such sets. Figure 4.6: Construction of the middle-third Cantor set We observe an interesting property of the middle-third Cantor set when trying to answer the following question, what is the length of the set \\(\\CC\\)? Notice that there are infinitely many points in the set \\(\\CC\\). After the first pass, the set \\(k_1\\) has length \\(2/3\\) (2 subintervals of length \\(1/3\\)). After the second pass we are left with a set \\(k_2\\) of length \\(4/9\\) (4 subintervals of length \\(1/9\\)). In particular after the \\(n\\)th pass we are left with a set \\(k_n\\) of length \\((2/3)^{n}\\) (\\(2^n\\) intervals of length \\(3^n\\)). In the limit we see that \\(\\CC\\) has length \\(0\\) or measure zero. Thus we have the seemingly contradictory proposition of a set which contains infinitely many points but has no length. Generally a set \\(X \\subset \\R\\) is said to have measure zero if for any \\(\\epsilon\\) greater than zero, there is a choice of intervals of total length strictly less than \\(\\epsilon\\) whose union contains \\(X\\). One can generalise the Cantor set construction from \\(\\R\\) to \\(\\R^2\\) to create interesting fractals. For example Figure 4.7 shows the Sierpinski gasket. Here we begin with an equilateral triangle and at each pass remove the “middle triangle” of the equilateral triangles left over. The resulting set of points in the plane is the Sierpinski gasket. Figure 4.7: 3 steps of the Sierpinski gasket 4.3 Fractals and deterministic dynamical systems At the end of Section 4.2 we introduced a key player in the module who thus far had been lurking in the background of our discussions — fractals. In this section we explore some of the instances in which fractals occur in dynamical system. 4.3.1 Fractals from deterministic dynamical systems Consider the 1D map \\[f_{a}(x) = \\begin{cases} ax \\quad x \\le 1/2 \\\\ a(1-x) \\quad x&gt; 1/2 \\end{cases}\\] for \\(a&gt;0\\). This map is often called the tent map as its graph looks like a tent. As with the doubling map this is a piecewise-smooth and not a smooth map. For differentiable values in \\([0,1]\\), the Lyapunov exponent is equal to \\(\\ln(a)\\). Therefore all non-asymptotically periodic orbits of the tent map are chaotic when \\(\\ln(a)&gt;0\\). Figure 4.8 compares the tent map \\(f = f_{a}\\) (\\(a=2\\)) against the logistic map \\(g = g_{a}\\) (\\(a=4\\)). Figure 4.8: Comparison of the tent and logistic maps The point \\(1/2\\) is a critical point of both maps: it is the local maximum of the logistic map and the joining point of tent map. For both maps \\(1/2\\) is mapped first to \\(1\\) and then to \\(0\\) which is a fixed point of both maps. The other fixed point of the tent map is at \\(2/3\\); for the logistic map it is \\(3/4\\). Both maps have a period two orbit: \\((0.4, 0.8)\\) for the tent map and \\(\\left(\\frac{5 - \\sqrt{5}}{8}, \\frac{5 + \\sqrt{5}}{8}\\right)\\) for the logistic map. The fixed points are sources. Their period \\(2\\) orbits are also sources: \\(|f&#39;(0.4)||f&#39;(0.8)| = 4\\) and \\(\\left|g&#39;\\left(\\frac{5 - \\sqrt{5}}{8}\\right)\\right| \\left|g&#39;\\left(\\frac{5 + \\sqrt{5}}{8}\\right)\\right| = 4\\). In some ways one can think of the tent map as a non-smooth version of the logistic map. Now fix \\(a = 3\\) and consider the tent map \\(f = f_{3}\\) (shown in Figure 4.9). We are going think about the set of points in the unit interval whose orbits under \\(f\\) remain inside the unit square. As with the doubling map, the slope of \\(3\\) means that considering a ternary expansion might prove fruitful. Another way of visualising this is to consider breaking up the unit interval \\([0,1]\\) into blocks of \\(1/3\\), \\(1/9\\) and so on and thinking about which blocks are eventually mapped outside of the square (see Figure 4.9) Figure 4.9: Tent map with a=3 and escaping orbits highlighted Observe that points in the interval \\((1/3, 2/3)\\) are mapped in one iteration of the map \\(f\\) outside of the unit square. Points mapped into the interval \\((1/3, 2/3)\\) in one iteration, are mapped outside of the square after \\(2\\) iterations. Let us delete the interval \\((1/3, 2/3)\\) which leaves us with two subintervals \\([0, 1/3]\\), \\([2/3,1]\\). The middle third of these intervals \\((1/9, 2/9)\\) and \\((7,9, 8/9)\\). Are mapped under one iteration to the middle third of the interval \\([0,1]\\) that is \\((1/3, 2/3)\\). In particular, after two iterations points in \\((1/9, 2/9)\\) and \\((7,9, 8/9)\\) are mapped out of the unit interval. This pattern repeats. If we delete the intervals \\((1/9, 2/9)\\) and \\((7,9, 8/9)\\), the middle third of the intervals that are left will map outside the unit square in \\(3\\) iterations of \\(f\\). Therefore in the limit, the set of points in the unit interval whose orbits under \\(f\\) remain in the unit square is precisely points in the middle third Cantor set \\(\\CC\\) — a fractal set. What about points outside the unit interval? All such points have orbits converging to \\(-\\infty\\) (in the first iteration they are mapped to the negative real line and from then on they remain on the negative real line and triple in size with each application of \\(f\\)). Therefore the basin of infinity (the set of points whose orbits diverge to \\(- \\infty\\)) is the set \\[ (-\\infty,0) \\sqcup (1, \\infty) \\sqcup (1/3, 2/3) \\sqcup (1/9, 2/9) \\sqcup (7/8, 8/9) \\ldots .\\] 4.3.2 Fractal basin boundaries Let us now consider higher dimensional maps to see how such maps might give rise to fractal structures. Let \\(\\v{f}\\) be a map on a subset of \\(\\R^{n}\\) and suppose that \\(\\v{p}\\) is an attracting fixed/periodic point of \\(f\\). Recall that the basin of attraction of \\(p\\) is the set of points \\(\\v{v}\\) such that \\[\\lim_{k \\to \\infty} | \\v{f}^{k}(\\v{v}) - \\v{f}^{k}(\\v{p})| = 0.\\] Figure 4.10 shows self-similarity in an attracting orbit of the Hènon map. The sub-figures are successive magnifications on a portion of the orbit in the top left. Figure 4.10: Zooming in on an orbit of the Hènon map Similarly Figure 4.12 reveals fractal structure in the basin of infinity of the Hènon map. The sub-figures are magnifications of the left portion of figure 4.11 Figure 4.11: Attracting basin of the Hènon map Figure 4.12: Zooming in on the attracting basin of the Hènon map How do fractal basin boundaries arise? Figure 4.13 gives a schematic for how fractal basins might arise. Figure 4.13: Fractal basin schematic. We consider a map \\(\\v{f}\\) of the plane and a square region \\(R\\). The map \\(\\v{f}\\) has two attracting fixed points \\(A_1\\) and \\(A_2\\) to the left and right (respectively) of the square \\(R\\). The image of the region \\(R\\) under the map \\(\\v{f}\\) is the \\(S\\) shaped strip. The sub-figure on the right of Figure 4.13 shows which portions are mapped out of the \\(R\\) to the left and which are mapped (in one iteration) out of \\(R\\) to the right. In particular, the light-grey shaded regions are mapped under \\(\\v{f}\\) to the out of \\(R\\) to the left and the dark shaded regions are mapped out of \\(R\\) to the right. In the next iteration the three white strips remaining will each develop 4 shaded strips (2 light-grey and 2-dark grey) corresponding to points which are mapped under two iterates of \\(\\v{f}\\) out of \\(R\\) to the left and under \\(2\\) iterates of \\(\\v{f}\\) out of \\(R\\) to the right. This process then repeats giving rise to a Cantor-like construction. The set of points in \\(R\\) which remain in \\(R\\) under repeated applications of \\(\\v{f}\\) is a fractal set. 4.4 Problem Sheet 4 For week 5. Question 4.1 Show that \\[ \\v{f}(x,y) = (ax,bx^3 + cy) \\] has a saddle fixed point at \\((0,0)\\) if either \\(|a|&lt;1\\) and \\(|c|&gt;1\\) or \\(|a|&gt;1\\) and \\(|c|&lt;1\\). Find the inverse map \\(\\v{f}^{-1}\\). [Hint: Set \\(f_1(x,y) = ax\\) and \\(f_2(x,y) = bx^3 + cy\\) and solve \\[x = f_1(u,v), \\qquad y = f_{2}(u,v)\\] for \\(u(x,y)\\) and \\(v(x,y)\\). The inverse map is given by \\(\\v{f}^{-1}(x,y) = (u(x,y), v(x,y))\\)] Set \\(q = \\frac{b}{a^3 -c}\\). Show that \\[S = \\{(t,qt^3): t \\in \\R \\} \\] is invariant under \\(\\v{f}\\). That is for \\((x,y) \\in S\\), \\(\\v{f}(x,y)\\) and \\(\\v{f}^{-1}(x,y)\\) are also in \\(S\\). What are the stable and unstable manifold of \\((0,0)\\) in the regimes \\(|a| &lt;1\\) and \\(|c|&gt;1\\); \\(|a|&gt;1\\) and \\(|c|&lt;1\\)? Show Solution 4.1 Solution 4.1 The point \\((0,0)\\) is clearly a fixed point of \\(\\v{f}\\). We compute the Jacobian at \\((0,0)\\) \\[ \\jacob(0,0) = \\begin{pmatrix} a &amp; 0 \\\\ 0 &amp; c \\end{pmatrix}. \\] This is a diagonal matrix and so its eigenvalues are the diagonal entries \\(a\\) and \\(c\\). Thus, if \\(|a|&lt;1\\) and \\(|c|&gt;1\\) or \\(|a|&gt;1\\) and \\(|c|&lt;1\\), the point \\((0,0)\\) is a saddle point. Clearly the map \\(\\v{f}\\) is a bijection on \\(\\R^2\\) so long as \\(a,c \\ne 0\\) in which case it has an inverse. Let \\((x,y) \\in \\R^2\\). Since \\(\\v{f}\\) is invertible there is a point \\((u,v) \\in \\R^2\\) such that \\(\\v{f}(u,v) = (x,y)\\). Therefore \\(au = x\\) and \\(bu^3 + cv = y\\). Solving for \\(u\\) and \\(v\\) in terms of \\(x\\) and \\(y\\) we have: \\[u = x/a \\qquad \\text{ and } \\qquad v = \\frac{y- \\frac{bx}{a} }{c}.\\] We conclude that \\[\\v{f}^{-1}(x,y) = \\left(x/a, \\frac{y- \\frac{bx^3}{a^3} }{c}\\right).\\] Let \\(t\\in \\R\\) and consider the following: \\[\\begin{align*} \\v{f}\\left(t, \\frac{bt^3}{a^3 -c}\\right) &amp;= \\left(at, bt^3 + \\frac{bct^3}{a^3 -c}\\right) = \\left(at, \\frac{ba^3t^3}{a^3 -c}\\right) \\\\ &amp;= (at, q(at)^3) \\\\ \\v{f}^{-1}\\left(t, \\frac{bt^3}{a^3 -c}\\right) &amp; = \\left(t/a, \\frac{\\frac{bt^3}{a^3 -c} - \\frac{bt^3}{a^3}}{c}\\right) = \\left(t/a,\\frac{\\frac{cbt^3}{a^3(a^3 -c)}}{c}\\right) \\\\ &amp;= \\left(t/a, q (t/a)^3\\right). \\end{align*}\\] Since \\(t \\in \\R\\) was arbitrary, we conclude that \\(S\\) is invariant under \\(\\v{f}\\). The unstable manifold of \\((0,0)\\) in this instance is the \\(y\\)-axis. By definition the unstable manifold is the set of points \\((x,y) \\in \\R^2\\) such that \\[\\lim_{n \\to \\infty} |\\v{f}^{-n}(x,y) - \\v{f}^{-n}(0,0)| = 0.\\] Consider the \\(x\\)-coordinate \\(x/a^{n}\\) of \\(\\v{f}^{-n}(x,y)\\). If \\(\\lim_{n \\to \\infty} x/a^{n} = 0\\) then \\(x\\) must be equal to \\(0\\) since \\(\\lim_{n \\to \\infty}1/a^{n} = \\infty\\) (\\(|a|&lt;1\\)). Therefore any point in the unstable manifold of \\((0,0)\\) has \\(x\\)-coordinate equal to \\(0\\). However \\[\\lim_{n \\to \\infty} |\\v{f}^{-n}(0,y)| = \\lim_{n \\to \\infty} (0,y/c^{n}) = 0 \\] since \\(|c|&gt;1\\). Alternatively we can observe that that the \\(y\\)-axis is invariant under \\(\\v{f}\\) and \\(\\v{f}^{-1}\\). The \\(y\\)-axis is certainly tangent to itself and by the calculation above we know that points on the \\(y\\)-axis are repelled from the origin. Thus we again conclude that the \\(y\\)-axis is the unstable manifold of \\((0,0)\\). To characterise the stable manifold first observe that for \\(n \\in \\N\\) \\[ \\lim_{n \\to \\infty} \\v{f}^{n}(x,y) = (a^{n}x, bx^3 \\sum_{n = 0}^{n-1} c^{i} a^{3(n-1-i)} + c^{n}y).\\] Clearly as \\(|a|&lt;1\\), \\(\\lim_{n \\to \\infty} a^{n}x = 0\\). So for \\(x,y\\) to be a point in the stable manifold we must have that \\[ \\lim_{n \\to \\infty} bx^3 \\sum_{i = 0}^{n-1} c^{i} a^{3(n-1-i)} + c^{n}y = 0. \\] Dividing through by \\(c^{n}\\) we have \\[ \\lim_{n \\to \\infty} bx^3 \\sum_{i = 0}^{n-1} c^{-(n-i)} a^{3(n-1-i)} + y = 0. \\] Re-indexing and taking out a \\(1/c\\) term, we have: \\[ \\lim_{n \\to \\infty} \\frac{bx^3}{c} \\sum_{k = 0}^{n-1} c^{-k} a^{3k} + y = 0. \\] Using the formula for the sum of a geometric series we note that \\[ y = \\lim_{n \\to \\infty} bx^3/c \\sum_{k = 0}^{n-1} c^{-k} a^{3k} = -bx^3/c\\cdot \\frac{c}{c-a^3} = \\frac{bx^3}{a^3 -c}. \\] Therefore the stable manifold of \\((0,0)\\) is precisely the set \\(S\\). We can see this alternatively as follows. The curve \\(S = (t, qt^3)\\) has derivative \\[\\der{S}{t} = (1, 3qt^2).\\] Therefore the direction of the tangent to \\(S\\) at the origin is \\((1,0)\\) and we conclude that \\(S\\) is tangent to line through the origin in the direction \\((1,0)\\) i.e \\(S\\) is tangent to the \\(x\\)-axis. We have already shown that \\(S\\) is invariant under \\(\\v{f}\\) and \\(\\v{f}^{-1}\\). One can check that points in \\(S\\) are attracted to the origin under \\(\\v{f}\\). We thus conclude that \\(S\\) is the stable manifold of \\((0,0)\\). In this case the stable manifold is precisely the \\(y\\)-axis since we require \\(\\lim_{n \\to \\infty} a^{n}x = 0\\), and contraction occurs along the \\(y\\) axis (the eigenvalue of \\((0,1)\\) is \\(c\\) and \\(|c|&lt;1\\).) The unstable manifold is again equal to \\(S\\). We can see this by considering the second coordinate of \\(\\lim_{n \\to \\infty}\\v{f}^{-n}(x,y)\\) (the first coordinate clearly limits to \\(0\\)). We have \\[\\begin{align*} \\lim_{n \\to \\infty}\\v{f}^{-n}(x,y) &amp;= \\lim_{n \\to \\infty} \\frac{1}{c^{n}} \\left( y - \\frac{bx^3}{a^3} \\sum_{i =0}^{n} \\frac{c^{i}}{a^{3i}}\\right) \\\\ &amp;= \\lim_{n \\to \\infty} \\frac{1}{c^{n}} \\left( y - \\frac{bx^3}{a^3} \\frac{ 1- \\left(\\frac{c}{a^3}\\right)^{n+1}}{1- \\frac{c}{a}} \\right). \\end{align*}\\] If this limit is equal to \\(0\\) then it follows that \\[y = q x^3.\\] This gives the result. Alternatively, we want to verify that \\(S\\) is the stable manifold of \\(\\v{f}^{-1}\\). Note that the eigenvalues of \\(\\jacob^{-1}(0,0)\\) are \\(\\frac{1}{a}&lt;1\\) and \\(\\frac{1}{c}&gt;1\\), with eigenvalues \\((1,0)\\) and \\((0,1)\\). We have already seen that \\(S\\) is tangent to the \\(x\\)-axis. One can check that points in \\(S\\) are attracted to the origin under \\(\\v{f}^{-n}\\). We therefore conclude that \\(S\\) is the stable manifold of \\(\\v{f}^{-1}\\) and so the unstable manifold of \\(\\v{f}\\). Question 4.2 Consider the map \\[ \\v{f}(x,y,z) = \\left( \\frac{x}{2}, \\frac{y}{2}, 2z - (x^2 +y^2) \\right). \\] Show that \\((0,0,0)\\) is the only fixed point of the map and that it is a saddle point. What are the directions at \\((0,0,0)\\) along which contraction and expansion occur? Show that the unstable manifold \\(\\unstab{(0,0,0)}\\) is the \\(z\\)-axis. Show that the stable manifold of \\(\\stab{(0,0,0)}\\) is the paraboloid \\[ z = \\frac{4(x^2+y^2)}{7}. \\] Show Solution 4.2 Solution 4.2 A point \\((x,y,z)\\) is a fixed point of \\(\\v{f}\\) if \\[\\v{f}(x,y,z) = \\left( \\frac{x}{2}, \\frac{y}{2}, 2z - (x^2 + y^2) \\right) = (x,y,z).\\] From the first two coordinates we find that \\(x = y = 0\\). Using this in the third coordinate then implies that \\(z =0\\) as well. We characterise \\((0,0,0)\\) as a saddle point by using \\(\\jacob(0,0,0)\\). We have \\[ \\jacob(0,0,0) = \\begin{pmatrix} 1/2 &amp; 0 &amp; 0 \\\\ 0 &amp; 1/2 &amp; 0 \\\\ 0 &amp; 0 &amp; 2 \\end{pmatrix}. \\] This is a diagonal matrix and so its eigenvalues are the diagonal entries and the eigenvectors are the unit coordinate vectors \\((1,0,0), (0,1,0)\\) and \\((0,0,1)\\). We clearly have expansion in the \\(z\\) direction and contraction in the \\(x,y\\) plane. The map \\(\\v{f}: \\R^2 \\to \\R^2\\) is a bijection. One can compute that \\[ \\v{f}^{-1} = (2x,2y, \\frac{z}{2} + 2(x^2 + y^2)). \\] In particular if \\(\\v{f}^{-n}(x,y,z)\\) tends to \\(0\\) as \\(n\\) tends to infinity, we must have that \\(x = y = z\\). Points on the \\(z\\) axis limit to \\((0,0,0)\\) under iterates of \\(\\v{f}^{-n}\\) and so we conclude that the unstable manifold of \\((0,0,0)\\) is the \\(z\\)-axis as required. One can demonstrate by induction that \\[ \\v{f}^{n}(x,y,z) = \\left(\\frac{x}{2^n}, \\frac{y}{2^n}, 2^{n}z - (x^2 +y^2) \\sum_{i=0}^{n-1} 2^{-2i}2^{(n-1) - i}\\right). \\] Clearly the first two coordinates tend to zero with \\(n\\), the last coordinate tends to zero when \\[ \\lim_{n \\to \\infty} 2^{n-1}\\left( 2 z -(x^2 + y^2) \\sum_{i=0}^{n-1} 2^{-3i}\\right) = 0. \\] This happens when \\(2z = (x^2 + y^2) \\frac{8}{7}\\). That is, when \\(z = 4(x^2 + y^2)/7\\). Therefore the stable manifold of \\((0,0,0)\\) is the paraboloid \\[\\left(x,y, \\frac{4(x^2 + y^2)}{7} \\right)\\] as required. Note that the paraboloid is invariant under \\(\\v{f}\\) and under \\(\\v{f}^{-1}\\), and points in the paraboloid are attracted to the origin under \\(\\v{f}\\). We can compute the tangent plane of the paraboloid at the origin as follows. Set \\(g(x,y,z) = z - \\frac{4(x^2 + y^2)}{7}\\). A normal vector to the tangent plane of the paraboloid at the origin, is given by \\[ \\v{n} = \\nabla g(0,0,0) = (0,0,1). \\] The equation of the tangent plane is therefore \\(z = 0\\) which is precisely the space spanned by the contracting eigenvectors of the \\(\\jacob(0,0,0)\\). However, in the 3-dimension context, these facts are not enough to conclude that \\(S\\) is indeed the stable manifold of \\((0,0,0)\\). We additionally need to verify that points outside the paraboloid are not attracted to the origin under \\(\\v{f}\\). However, there is a higher-dimensional analogue of the Stable Manifold Theorem that enables us to conclude that the paraboloid is the stable manifold of \\((0,0,0)\\). This result states that the dimension of the stable manifold is equal to the dimension of the vector space spanned by the contracting eigenvectors. In this case, the dimension of the vector space spanned by the contracting eigenvectors is \\(2\\) and so we know that the stable manifold is a \\(2\\)-dimensional manifold and in which case it is the paraboloid Question 4.3 The tent map \\(T_{2}(x): [0,1] \\to [0,1]\\) is defined by \\[ T_2(x) = \\begin{cases} 2x &amp; \\text{ for } x \\le 1/2 \\\\ 2(1-x) &amp; \\text{ for } x&gt;1/2 \\end{cases}. \\] Sketch the map \\(T_{2}(x)\\). For every orbit \\((x_1, x_2, \\ldots)\\) of \\(T_{2}(x)\\) with \\(x_{i} \\ne 1/2\\) for all \\(i \\in \\N\\), calculate the Lyapunov number \\(L(x_1)\\) and the Lyapunov exponent \\(h(x_1)\\). Show that \\(T_{2}(x)\\) does not have any stable period-\\(k\\) orbits or fixed points. Argue that any asymptotically periodic orbit of \\(T_{2}(x)\\) must be eventually periodic. Write \\(L\\) for the set of all points in \\([0,1]\\) strictly less than \\(1/2\\) and \\(R\\) for the set of all points strictly greater than \\(1/2\\). Let \\((x_1, x_2, x_3, \\ldots)\\) be an orbit with \\(x_i \\ne 1/2\\) for all \\(i \\in \\N\\). We assign an infinite sequence, an itinerary, \\(l_1l_2l_3\\ldots \\in \\{L,R\\}^{\\N}\\) to the orbit \\((x_1, x_2, x_3, \\ldots)\\) in the following way: for \\(i \\in \\N\\) \\(l_i = L\\) if \\(x_i \\in L\\) otherwise \\(l_i = R\\). Graphically or otherwise show that each itinerary \\(l_1l_2\\ldots l_k \\in \\{L,R\\}^{k}\\) consisting of \\(k\\) symbols corresponds to an interval of length \\(2^{-k}\\). Explain why each infinite itinerary corresponds to the orbit of exactly one point in \\([0,1]\\). Using points a. to d. show that \\(T_{2}(x)\\) has infinitely many chaotic orbits. Show Solution 4.3 Solution 4.3 The map \\(T_{2}(x)\\) is depicted in Figure 4.14. Figure 4.14: Sketch of the Tent map Notice that the derivative of the \\(T_{2}(x)\\) is undefined at \\(x=1/2\\), hence the need to exclude a \\(1/2\\). For all other points in the domain of the tent map, \\(T_{2}&#39;(x) = 2\\). Thus, the Lyapunov number \\(L(x_1)\\) of the orbit \\((x_1, x_2, \\ldots)\\) is then computed as: \\[ \\lim_{n\\to \\infty} (|T_{2}&#39;(x_1)||T_{2}&#39;(x_2)| \\ldots |T_{2}&#39;(x_n)|)^{1/n} = \\lim_{n\\to \\infty} \\sqrt[n]{2^{n}} = 2. \\] The Lyapunov exponent \\(h(x_1)\\) is then computed as \\(\\ln(L(x_1)) = \\ln(2) &gt;0\\). Let \\((x_1, x_2, \\ldots x_{k})\\) be a period-\\(k\\) orbit for \\(k \\ge 1\\). Notice that this automatically excludes the point \\(1/2\\). We have \\[|T_{2}^{k}(x_i)| = |T_{2}&#39;(x_1)| |T_{2}&#39;(x_2)| \\ldots |T_{2}&#39;(x_k)| = 2^{k} &gt;1.\\] This means that any period \\(k\\) orbit of \\(T_{2}\\) is unstable. In particular the orbit of any point \\(x\\) arbitrarily close to but not in the orbit of a periodic point, eventually moves away from the period \\(k\\) orbit. Therefore only points which eventually map directly onto a point in a period-\\(k\\) orbit can be asymptotically periodic. We demonstrate this by induction. Suppose we have one symbol \\(l_1\\). If \\(l_1 = L\\), then \\(x_1 \\in [0, 1/2)\\) moreover points in the left subinterval \\([0, 1/4)\\) map into \\(L\\) while points in the right subinterval \\((1/4,1/2)\\) map into \\((1/2,1]\\). If \\(l_1 = R\\) then \\(x_1 \\in (1/2, 1]\\) moreover, in this case, points in the left subinterval \\((1/2, 3/4)\\) maps into \\(R\\) while points in the right subinterval \\((3/4,1]\\) map into \\([0,1/2]\\). Assume by induction that any itinerary \\(l_1l_2 \\ldots l_k\\) corresponds to exactly one interval \\(\\left(\\frac{a}{2^{k}}, \\frac{a+1}{2^k}\\right)\\) (we include the left end point only if it is equal to zero and the right end point only if it is equal to \\(1\\)) where \\(0 \\le a &lt; 2^{k}\\). Now consider an itinerary \\(l_1l_2 \\ldots l_{k+1}\\). By induction there is a unique interval \\(\\left(\\frac{a}{2^{k}}, \\frac{a+1}{2^{k}}\\right)\\), \\(0 \\le a &lt; 2^{k}\\) which corresponds to the itinerary \\(l_2 \\ldots l_{k+1}\\). Assume that \\(\\left(\\frac{a}{2^{k}}, \\frac{a+1}{2^{k}}\\right)\\) is a subset of \\(L\\) (the other case is dealt with by a symmetric argument). If \\(l_1 = L\\), then the interval \\(\\left(\\frac{a}{2^{k+1}}, \\frac{a+1}{2^{k+1}}\\right)\\) maps into \\(\\left(\\frac{a}{2^{k}}, \\frac{a+1}{2^{k}}\\right)\\) under \\(T_2\\) and is a subset of \\(L\\). In particular all points in \\(\\left(\\frac{a}{2^{k+1}}, \\frac{a+1}{2^{k+1}}\\right)\\) are such that the first \\(k+1\\) terms of their orbits gives rise to the itinerary \\(l_1l_2\\ldots k_{k+1}\\). Notice that since \\(T\\) is injective on \\(L\\), by induction, \\(\\left(\\frac{a}{2^{k+1}}, \\frac{a+1}{2^{k+1}}\\right)\\) uniquely corresponds to the itinerary \\(l_1l_2\\ldots l_{k+1}\\). If \\(l_1 = R\\), then the interval interval \\(\\left(\\frac{2^{k+1} -(a+1)}{2^{k+1}}, \\frac{2^{k+1}-a}{2^{k+1}}\\right)\\) is a subinterval of \\(R\\) (since \\(\\left(\\frac{a}{2^{k}}, \\frac{a+1}{2^{k}}\\right) \\subseteq R\\) and \\(\\left(\\frac{2^{k+1} -(a+1)}{2^{k+1}}, \\frac{2^{k+1}-a}{2^{k+1}}\\right) = \\left(1-\\frac{(a+1)}{2^{k+1}}, 1-\\frac{a}{2^{k+1}}\\right)\\)). In particular \\(T_{2}\\left(\\frac{2^{k+1} -(a+1)}{2^{k+1}}, \\frac{2^{k+1}-a}{2^{k+1}}\\right) = \\left(\\frac{a}{2^{k}}, \\frac{a+1}{2^{k}}\\right)\\). This means that any point in \\(\\left(\\frac{2^{k+1} -(a+1)}{2^{k+1}}, \\frac{2^{k+1}-a}{2^{k+1}}\\right)\\) has an orbit with the first \\(k+1\\) points corresponding to the itinerary \\(l_1l_2 \\ldots l_{k+1}\\). Again injectitvity of \\(T_{2}\\) on \\(R\\) and the inductive hypothesis guarantees uniqueness. Let \\(l_1l_2 \\ldots\\) be an infinite itinerary. For each \\(k \\in \\N\\) let \\(I_k\\) be the unique subinterval of length \\(2^{-k}\\) corresponding to the itinerary \\(l_{1}l_{2} \\ldots l_{k}\\). Then as \\(I_{1} \\supset I_2 \\supset I_2 \\ldots\\) and \\(\\lim_{n \\to \\infty} 2^{-n} = 0\\), it follows that the intersection \\(\\cap_{k \\in \\N} I_{k}\\), if it is non-empty, contains exactly one point. Notice that the intersection is empty precisely when there is a minimal \\(k \\in \\N\\) with \\(k&gt;1\\) such that \\(l_{i} = l_{i+1}\\) for all \\(i &gt;k\\). That is every point in \\([0,1]\\) with an orbit that does not contain \\(1/2\\) corresponds to exactly one itinerary \\(l_1 l_2\\ldots\\). Observe that a periodic orbit \\((x_1, x_2, \\ldots x_{k})\\) corresponds to a periodic itinerary \\[(l_1 l_2 \\ldots l_{k})(l_1 l_2 \\ldots l_{k}) \\ldots\\] where \\(l_{i} \\in \\{L,R\\}\\) is the subinterval containing \\(x_{i}\\). Since an eventually periodic orbit is an orbit for which deleting some initial terms gives rise to a periodic orbit, it follows that an eventually periodic orbit has an eventually periodic itinerary. Clearly there are (uncountably) infinitely many non-eventually periodic infinite sequences of symbols in \\(\\{L,R\\}\\) (simply take the binary expansion of a non-rational number and write \\(L\\) in place of \\(0\\) and \\(R\\) in place of \\(1\\)). All such sequences correspond to a non-asymptotically periodic orbit (as asymptotically periodic orbits are eventually periodic and give rise to an eventually periodic itinerary (c. and d.)). By b. the Lyapunov exponent of any non-asymptotically periodic orbit is greater than 0. Therefore all non-asymptotically periodic orbit are chaotic and \\(T_{2}(x)\\) has infinitely many chaotic orbits. References "],["Fractals.html", "Chapter 5 Fractals 5.1 Complex maps and Julia sets 5.2 Fractal dimensions 5.3 Problem Sheet 5", " Chapter 5 Fractals Covers Chapter 4 from Section 4.5 to Definition 5.1 of Chapter 5 (Alligood, Sauer, and Yorke 2000). 5.1 Complex maps and Julia sets As another example of how fractals might arise from dynamical systems, consider a complex map \\(P_{c}: \\C \\to \\C\\) defined by \\(P_{c}(z) = z^2 + c\\) for a constant \\(c \\in \\C\\). This defines a complex discrete dynamical system: \\[z_{n+1} = z_n^2 + c.\\] We can also think of this as a map on \\(\\R^2\\) as \\(\\v{f}(x,y)= (x^2 -y^2 + a, 2xy + b)\\) where \\(c = a + ib \\in \\C\\) and so as a discrete dynamical system on \\(\\R^2\\). For \\(c = 0\\), \\(P_{0} = z^2\\) and we have a fixed point at \\(0\\) which is in fact an attracting fixed point. All points \\(z \\in \\C\\) with \\(|z|&lt;1\\) are attracted to \\(0\\) under iterations of the map \\(P_{0}\\). Therefore the interior of the unit disk is the basin of attraction of \\(0\\). Notice that points on the boundary \\(S = \\{ z \\in \\C : |z| = 1 \\}\\) of the unit disk are mapped under \\(P_{0}\\) to other points on the unit disk. While the set \\(K = \\{ z \\in \\C : |z|&gt;1 \\}\\) of points outside the closed unit disk map to infinity under iterations of \\(P_{0}\\). Therefore \\(S\\) forms the boundary between the basin of \\(0\\) and the basin of infinity. The dynamics differ if we change the value of \\(c\\), indeed \\(0\\) is no longer a fixed point once \\(c\\) is non-zero. However the orbit of \\(0\\) play an important role in the dynamics of \\(P_{c}\\). Therefore one might wonder for which values of \\(c\\) does the orbit with initial point \\(0\\) not diverge to infinity? The set of points \\(c \\in \\Z\\) for which the orbit of \\(0\\) is bounded is called the Mandelbrot set (after the mathematician Benoit Mandelbrot) and is denoted \\(M\\) . That is, \\[ M = \\{ c \\in \\C: \\exists M \\in \\R, |P_{c}^{n}(0)|&lt; M \\forall n \\in \\N \\}.\\] Figure 5.1: A picture of the Mandelbrot set. For a fixed \\(c \\in \\C\\), the boundary between orbits which diverge to infinity under \\(P_{c}\\) and orbits which are bounded is an important set. It is the Julia set of \\(P_{c}(z)\\) (after the mathematician Gaston Maurice Julia). The Julia sets are good examples of fractal sets. Figure 5.2 shows examples of Julia sets for values of \\(\\C\\) inside the Mandelbrot set. Figure 5.2: Julia sets for values of \\(c\\) in the Mandelbrot set 5.1.1 Fractal dimension When we constructed the middle third Cantor set, we observed that although the resulting set \\(\\CC\\) contained infinitely many points it had zero length. But perhaps we were using the wrong measure. A fractal dimension is a way of measuring the complexity of a fractal set. Of course we expect such a measure to generalise the normal notion of “dimension” that we are used to. That is we expect a fractal dimension to give the value 1 for the dimension of an interval, 2 for a square 3 for a cube and so on. There are many different ways to measure the dimension of a fractal set and in some instances they coincide. We only introduce a couple in this module. The first is the box counting dimension. Let us first consider the definition of the box-countingdimension for standard subsets of \\(\\R\\) and \\(\\R^2\\) before generalising to subsets of \\(\\R^n\\). Consider the unit interval \\([0,1]\\). Given \\(\\epsilon &gt;0\\), what is the minimum number intervals of size \\(\\epsilon\\) that we need to cover \\([0,1]\\)? That is we want a minimal collection \\(X\\) of intervals \\(U=[a,b]\\) such that \\(|a-b| = \\epsilon\\) and \\(\\bigcup_{U \\in X} U \\supseteq [0,1]\\)? Clearly we need \\(1/\\epsilon\\) intervals of size \\(\\epsilon\\). If we had instead considered the interval \\([0, 42]\\), then the minimal number of intervals of size has size \\(42/\\epsilon\\). In particular the number of intervals is linear in \\(1/\\epsilon\\) (i.e of the form \\(c 1/\\epsilon\\) for a constant \\(c\\) depending on the length of the interval) representing in some sense the \\(1\\)-dimensionality of the interval. What about a square \\(D\\) in \\(\\R^2?\\) Given \\(\\epsilon &gt;0\\), what is the minimum number of squares of size \\(\\epsilon^2\\) that we need to cover the square \\(D\\)? We find in this case that we need \\(c(1/\\epsilon^2)\\) squares of size \\(\\epsilon^2\\) for a constant \\(c\\) depending on the area of the square. In particular the number of squares is quadratic in the \\(1/\\epsilon\\) representing the two dimensionality of the square. In the general case, given a cube \\(D \\in \\R^{d}\\) and writing \\(N(\\epsilon)\\) for the minimum number of boxes of side length \\(\\epsilon\\) in \\(\\R^{d}\\) required to cover the \\(D\\). We find \\(N(\\epsilon) = c(1/\\epsilon^{d})\\) where \\(c\\) is a constant depending on the size of the cube \\(D\\). Thus the exponent give the dimension. We can rearrange this expression by taking logarithms to obtain an equation for the exponent in terms of \\(N(\\epsilon)\\) and \\(c\\). \\[ d = \\dfrac{\\ln(N(\\epsilon)) - \\ln(c)}{\\ln(1/\\epsilon^{d})}.\\] If \\(c\\) roughly constant for all small \\(\\epsilon\\), then the contribution of \\(\\ln(c)\\) is negligible. Thus we have the following definition. Definition 5.1 (Box-counting dimension) A bounded set \\(S \\subseteq \\R^{n}\\) has box-countingdimension \\[ \\bdim(s) = \\lim_{\\epsilon \\to 0} \\dfrac{\\ln N(\\epsilon)}{\\ln(1/\\epsilon)} \\] when the limit exists. See Figure 5.3 for an illustration of applying this in practice. Figure 5.3: Boxcounting dimension for an orbit of the Hènon map Example 5.1 Let us compute the box-counting dimension of the middle-third Cantor set \\(\\CC\\). Now we expect a number between \\(0\\) and \\(1\\) since \\(\\CC\\) is a subset of \\(\\R\\). Essentially the minimal length boxes are given to us by the construction of the middle third Cantor set (Subsection 4.2.1). Taking \\(\\epsilon = (1/3)^{n}\\), from the construction of the middle third Cantor set we deduce that \\(N(\\epsilon) = 2^n\\) (at the \\(n\\)th step of the construction, we have \\(2^n\\) intervals of size \\(1/3^{n}\\)). Therefore \\[\\bdim(\\CC) = \\lim_{\\epsilon\\to 0} \\dfrac{\\ln N(\\epsilon)}{\\ln(1/\\epsilon)} = \\lim_{n \\to \\infty} \\dfrac{\\ln2^{n}}{\\ln 3^n} = \\ln 2/\\ln 3.\\] 5.2 Fractal dimensions 5.2.1 Correlation dimension Another notion of dimension of a fractal set is the so called correlation dimension. As opposed to the box-counting dimension which applies to any bounded subset of \\(\\R^{n}\\) the correlation dimension is only defined for the orbit of a dynamical system. Definition 5.2 (Correlation dimension) Let \\(S= (\\v{v}_{0}, \\v{v}_{1}, \\ldots )\\) be an orbit of a map \\(\\v{f}: \\R^{n} \\to \\R^{n}\\). Let \\(r \\in \\R\\) be a positive number and set \\(S_{N} = (\\v{v}_{0}, \\v{v}_{1}, \\ldots, \\v{v}_{n})\\) to be the first \\(N\\) points in the orbit. The correlation function \\(C(r)\\) is defined as: \\[ C(r) = \\lim_{N \\to \\infty} \\dfrac{|\\{ (i,j) : i \\ne j, 0 \\le i,j \\le N, |\\v{v}_i - \\v{v}_{j}| &lt;r \\} |}{N^2}. \\] The correlation dimension of the orbit \\(S\\) is defined as \\[ \\cdim(S) = \\lim_{r \\to 0} \\dfrac{\\ln C(r)}{\\ln r} \\] when the limit exists. Note For an orbit which is not asymptotically periodic: when \\(r\\) tends to \\(0\\) the correlation function tends to \\(0\\) (since the size of the numerator tends to \\(0\\)); when \\(r\\) approaches infinity then \\(C(r)\\) tends to \\(1\\) since the size of the numerator approaches \\(N^2.\\) If for small \\(r\\) the correlation function is \\(C(r)\\) is of the order \\(r^{d}\\), that is \\(C(r) \\simeq r^{d}\\) then \\(d\\) is the correlation dimension of \\(S\\). Let us compare the box-counting and correlation dimensions of the Hènon attractor from Figure 5.3. Recall that the box-counting dimension of a set \\(S\\) is defined as \\(\\lim_{\\epsilon \\to 0} \\frac{\\ln N(\\epsilon)}{\\ln(1/\\epsilon)}\\). Choose box-sizes of the from \\(\\epsilon = 2^{-2}, 2^{-3}, \\ldots\\). Plotting \\(\\log_{2} N(\\epsilon)\\) against \\(\\log_{2}(1/\\epsilon)\\), the box-counting dimension of \\(S\\) can be estimated as the slope of the resulting graph. The result is approximately \\(1.27\\) Figure 5.4: Box-counting dimension of the Hènon attractor For the correlation dimension we can take a similar approach. We plot \\(\\log_{2}(C(r))\\) against \\(\\log_2(r)\\) where we consider the first \\(1000\\) points of the orbit. We take values of \\(r = 2^{-2}, 2^{-3}, \\ldots\\). The correlation dimension is then the slope of the resulting graph as \\(r\\) tends to \\(0\\). The result is approximately \\(1.23\\) Figure 5.5: Correlation dimension of the Hènon attractor 5.2.2 Chaos in higher-dimensions In Subsection 4.1.1 we gave a precise definition of what is meant by a chaotic orbit for a bounded orbit of a one-dimensional map. We were able to say exactly what is meant by non-periodicity (not asymptotically periodic) and we characterised sensitivity to initial conditions in terms of the Lyapunov exponent of the orbit. We now generalise this to higher-dimensional maps. As we have seen (2.3) a new dynamic emerges in dimensions greater than \\(1\\) — saddle fixed/saddle periodic points — these have have expansion/stretching in some directions and contraction in others. The expansion and compression factors are determined by the eigenvalues of the Jacobian of the map at the fixed point. The Lyapunov number for higher-dimensional maps ought to give the stretching/attracting factor on orbits near the repelling/attracting directions of the saddle point. The Lyapunov number should quantify the stretching/shrinking per iteration of the map on orbits originating near the saddle point. Definition 5.3 (Lyapunov exponent) Let \\(\\v{f}\\) be a smooth map defined on a subset of \\(\\R^{n}\\) and let \\(J_{m} = \\jacob^{m}(\\v{v}_{0})\\) (that is \\(J_{m}\\) is the Jacobian of \\(\\v{f}^{m}\\) at \\(v_0\\)). The matrix \\(J_m\\) induces a linear map on \\(\\R^{n}\\) and maps the \\(n\\)-dimensional unit sphere to an ellipsoid (recall that our maps are invertible). Let \\(r_{k}^{m}\\) be the length of the \\(k\\)th longest orthogonal axis of the ellipsoid (that \\(J_m\\) maps the unit sphere to). Then \\(r^{m}_{k}\\) measures the contraction and expansion near the orbit of \\(\\v{v}_{0}\\) during the first \\(n\\) iterations of \\(\\v{f}\\). The \\(k\\)th Lyapunov number of \\(\\v{v}_{0}\\) is defined as \\[ L_{k} = \\lim_{m \\to \\infty} (r_{k}^{m})^{1/m}\\] when the limit exists. The \\(k\\)th Lyapunov exponent of \\(\\v{v}_{0}\\) is \\(h_{k} = \\ln L_{k}\\). Notice that by choice of the \\(r_{k}\\)’s it follows that \\(L_{1} \\ge L_2 \\ge \\ldots \\ge L_{n}\\) and \\(h_{1} \\ge h_2 \\ge \\ldots \\ge h_{n}\\). Now we have the ingredients required to define chaotic orbits in higher dimensions. 5.3 Problem Sheet 5 For week 6. Question 5.1 Consider the map \\(\\v{f}: \\R^2 \\to \\R^2\\) defined by \\[ \\v{f}(x,y) = (1-ax^2 + y, bx). \\] Verify that a period-\\(2\\) orbit of \\(\\v{f}(x,y)\\) is given by \\[ \\v{p}_{0} = (x_{+}, y_{+}), \\quad \\v{p}_{1} = (x_{-}, y_{-})\\] where \\[\\begin{align} x_{+} &amp;= \\frac{1}{2a} \\left[ 1 - b + \\sqrt{4a - 3(1-b)^2} \\right] \\\\ y_{+} &amp;= \\frac{b}{2a} \\left[ 1 - b - \\sqrt{4a - 3(1-b)^2} \\right] \\\\ x_{-} &amp;= \\frac{1}{2a} \\left[ 1 - b - \\sqrt{4a - 3(1-b)^2} \\right] \\\\ y_{-} &amp;= \\frac{b}{2a} \\left[ 1 - b + \\sqrt{4a - 3(1-b)^2} \\right] \\end{align}\\] where \\(a&gt; 3(1-b)^2/4\\). Let \\(b=0\\). Show that the period \\(2\\)-orbit is stable for \\(3/4 &lt; a &lt; 5/4\\) and unstable for \\(a&gt;5/4\\). Show Solution 5.1 Solution 5.1 This is a verify question so we need only check that \\(\\v{f}(\\v{p}_{i}) = \\v{p}_{i+1}\\) for \\(i \\in \\{0,1\\}\\) indices taken mod 2. We have \\[\\begin{align*} \\v{f}(\\v{p}_{0}) &amp;= \\left(1 - \\frac{1}{4a}\\left[(1-b)^2 + 2(1-b) \\sqrt{4a-3(1-b)^2} \\right. \\right. \\\\ &amp; \\left. \\left. + 4a - 3(1-b)^2 \\right] \\right. \\\\ &amp; \\left. + \\frac{b}{2a} \\left[ 1 - b - \\sqrt{4a - 3(1-b)^2} \\right], y_{-} \\right) \\\\ &amp;= \\left(\\frac{(1-b)^2}{2a} - \\frac{1-b}{2a}\\sqrt{4a - 3 (1-b)^2} \\right. \\\\ &amp; \\left. + \\frac{b}{2a}\\left[ 1 - b - \\sqrt{4a - 3 (1-b)^2} \\right], y_{-} \\right) \\\\ {} &amp;= \\left(\\frac{(1-b)^2}{2a} - \\frac{\\sqrt{4a - 3 (1-b)^2}}{2a} + \\frac{b(1-b)}{2a}, y_{-} \\right) \\\\ {} &amp;= (x_{-}, y_{-}) \\end{align*}\\] and \\[\\begin{align*} \\v{f}(\\v{p}_{1}) &amp;= \\left(1 - \\frac{1}{4a}\\left[(1-b)^2 \\right. \\right. \\\\ &amp; \\left. \\left. - 2(1-b) \\sqrt{4a-3(1-b)^2} + 4a - 3(1-b)^2 \\right] \\right. \\\\ &amp;\\left.+ \\frac{b}{2a} \\left[ 1 - b + \\sqrt{4a - 3(1-b)^2} \\right], y_{+} \\right) \\\\ &amp;= \\left(\\frac{(1-b)^2}{2a} + \\frac{1-b}{2a}\\sqrt{4a - 3 (1-b)^2} \\right. \\\\ &amp; \\left. + \\frac{b}{2a}\\left[ 1 - b + \\sqrt{4a - 3 (1-b)^2} \\right], y_{+} \\right) \\\\ &amp; = \\left(\\frac{(1-b)^2}{2a} + \\frac{\\sqrt{4a - 3 (1-b)^2}}{2a} + \\frac{b(1-b)}{2a}, y_{-} \\right) \\\\ &amp;= (x_{+}, y_{+}) \\end{align*}\\] as required. We compute \\[ \\jacob{(x_{+}, y_{+})} = \\begin{pmatrix} -2ax_{+} &amp; 1 \\\\ 0 &amp; 0 \\end{pmatrix} \\] and \\[ \\jacob{(x_{-}, y_{-})} = \\begin{pmatrix} -2ax_{-} &amp; 1 \\\\ 0 &amp; 0 \\end{pmatrix}. \\] Therefore \\[ \\jacob{(x_{+}, y_{+})}\\jacob{(x_{-}, y_{-})} = \\begin{pmatrix} -4a^2x_{+}x_{-} &amp; -2ax_{+} \\\\ 0 &amp; 0 \\end{pmatrix}. \\] The eigenvalues are given by \\(\\lambda_1 = 0\\) and \\(\\lambda_2 = 4 a^2 x_{+}x_{-}\\). Substituting for \\(x_{+}\\) and \\(x_{-}\\) we have \\(\\lambda_{2} = 4 - 4a\\). When \\(3/4 &lt; a&lt;5/4\\) then \\(|4-4a| &lt; 1\\) and the period-2 orbit is stable. When \\(a&gt; 5/4\\) the period-\\(2\\) orbit is unstable. Question 5.2 A map \\(f\\) of the unit interval is defined as follows \\[ f(x) = 10x \\mod 1 = \\begin{cases} 10x, &amp; 0 \\le x &lt; \\frac{1}{10} \\\\ 10x -1, &amp; \\frac{1}{10} \\le x &lt; \\frac{2}{10} \\\\ 10x -2, &amp; \\frac{2}{10} \\le x &lt; \\frac{3}{10} \\\\ \\quad \\vdots &amp; \\quad \\quad \\quad \\vdots \\\\ 10x -9, &amp; \\frac{9}{10} \\le x &lt; 1 \\\\ 0, &amp; x =1 \\end{cases} \\] Sketch the map and the straight line \\(y=x\\). On the basis of your skecth, how many fixed points do you expect this map to have? State the definition of the Lyapunov number and Lyapunov exponent for one-dimensional maps. Calculate the Lyapunov number and Lyapunov exponent for all orbits of the map \\(f(x)\\) that avoid \\[x_i = \\frac{1}{10},\\frac{2}{10},\\frac{3}{10},\\frac{4}{10},\\frac{5}{10},\\frac{6}{10},\\frac{7}{10},\\frac{8}{10}, \\text{ and } \\frac{9}{10}. \\] Can this map have any stable fixed points or periodic points? State the definition of chaotic orbits for one-dimensional maps. Briefly explain why you expect the map \\(f(x)\\) defined above to have chaotic orbits. [Hint: It might help to use the decimal representation of numbers in the interval \\([0,1]\\).] Show Solution 5.2 Solution 5.2 The sketch is shown in Figure 5.6. Figure 5.6: Sketch of the times ten map Based on the graph we expect \\(f\\) to have 10 fixed points. See Definition 4.1 in the lecture notes. The derivative of \\(f\\) at any point that is not of the form \\(a/10\\) for \\(0 \\le a &lt; 10\\), is exactly 10. Therefore the Lyapunov number of any orbit avoiding the point at which the derivative of \\(f\\) is not defined is exactly \\(10\\). The Lyapunov exponent of such an orbit is therefore \\(\\ln(10)&gt;0\\). The map \\(f\\) does not have stable fixed or periodic orbits. Notice that a fixed or periodic point cannot pass through a non-differentiable point of \\(f\\). The derivative of \\(f^{k}\\) at all points at which \\(f\\) is differentiable is \\(10^{k} &gt; 1\\). See Definition 4.3 in the lecture notes. An orbit is asymptotically periodic if and only if it is eventually periodic. For suppose \\(x\\) is asymptotically periodic to a period-k point \\(y\\). Since \\(y\\) is an unstable periodic point (indeed an unstable fixed point of \\(f^{k}\\)) for every \\(\\epsilon &gt;0\\), for any point \\(u \\ne y \\in N(\\epsilon, y)\\) there is a \\(j \\in \\N\\) with \\(|f^{jk}(u) - y| &gt; \\epsilon\\). Let \\(\\epsilon &gt;0\\), since \\(x\\) is asymptotically periodic, there is an \\(m \\in \\N\\) such that for all \\(n \\ge m\\), \\(|f^{nk}(x) - f^{nk}(y)| &lt; \\epsilon\\). If \\(f^{nk}(x) \\ne \\epsilon\\), then there is a \\(j \\ge n\\) such that \\(|f^{jk}(x) - f^{jk}(y)| &gt; \\epsilon\\) which would be a contradiction. Therefore \\(x\\) must be eventually periodic. In particular, any irrational number will have a non-asymptotically periodic decimal orbit as its decimal expansion is not eventually periodic. Therefore \\(f\\) has infinitely many chaotic orbits by c. Question 5.3 A one-dimensional map on the real numbers is defined by \\[ f(x) = rx(1-x), \\quad 0 \\le r &lt; \\infty. \\] Let \\(r&gt; 2+ \\sqrt{5}\\). For any orbit of \\(f(x)\\) that remains in \\([0,1]\\) find a lower bound for \\(|f&#39;(x)|\\). Hence show that the Lyapunov exponents of such orbits is greater than \\(0\\) if it exists. When would such an orbit be chaotic? Show Solution 5.3 Solution 5.3 Figure 5.7: Sketch of the logistic map Let \\(x_{-} \\in [0,1]\\) be the leftmost point of intersection of the line \\(y=1\\) with the curve \\(y = f(x)\\) and let \\(x_+ \\in [0,1]\\) be the rightmost point of intersection. If a point has an orbit that remains in \\([0,1]\\) then certainly the point lies in the union \\([0, x_-] \\sqcup [x_+, 1].\\) The points \\(x_1\\) and \\(x_2\\) can be found by solving \\(rx - rx^2 = 1.\\) This gives \\(x_{-} = \\frac{1}{2} - \\sqrt{\\frac{r-4}{4r}}\\) and \\(x_{+} =\\frac{1}{2} + \\sqrt{\\frac{r-4}{4r}}\\). Now \\(f&#39;(x) = r - 2rx\\) is a straight line with a negative gradient. In the interval \\([0, x_{-}]\\) we therefore conclude that \\(f&#39;(x) = r- 2rx \\ge f&#39;(x_{-}) &gt; 1\\) since \\(r &gt; 2+ \\sqrt{5}\\). In the interval \\((x_{+}, 1]\\) the minimum value of \\(|f&#39;(x)|\\) occurs when \\(x = x_{+}\\) and \\(|f&#39;(x_{+})| &gt;1\\) . Set \\(l := \\min\\{ |f&#39;(x_{-})|, |f&#39;(x_{+})| \\}\\). The Lyapunov number of an orbit \\((x_1,x_2, \\ldots )\\) which remains in \\([0,1]\\) is given by \\[ \\lim_{n \\to \\infty} (|f&#39;(x_1)| |f&#39;(x_2)| \\ldots |f&#39;(x_n)| )^{\\frac{1}{n}} \\ge \\lim_{n \\to \\infty} \\left( l^{n} \\right)^{1/n} = l &gt; 1.\\] In particular the Lyapunov exponent of such an orbit is greater than \\(1\\) (if it exists). By Definition 4.3, an orbit which remains in \\([0,1]\\) under iterations of \\(f\\) is chaotic precisely when it is not asymptotically periodic. References "],["chaoshigherdim.html", "Chapter 6 Chaos in Higher Dimensions 6.1 Chaotic Orbits in higher dimensions 6.2 Chaotic attractors 6.3 Continuous-time dynamical systems 6.4 Problem Sheet 6", " Chapter 6 Chaos in Higher Dimensions Covers Chapter 5 Sections 5.1 and 5.6; Chapter 6 Sections 6.1 and 6.2; Chapter 7 Section 7.1 (Alligood, Sauer, and Yorke 2000). 6.1 Chaotic Orbits in higher dimensions Definition 6.1 Let \\(\\v{f}\\) be an \\(n\\)-dimensional map \\(n \\ge 1\\). Let \\((\\v{x}_0, \\v{x}_1, \\ldots)\\) be a bounded orbit of \\(\\v{f}\\). The orbit is called chaotic if: it is not asymptotically periodic; no Lyapunov number is exactly one; \\(L_1(\\v{x}_0)&gt;1\\) (alternatively \\(h_1(\\v{x}_{0}) &gt;0\\)). This definition should be compared with Definition 4.3: the first condition is not surprising; while the second 2 characterise sensitivity to initial conditions suitable generalised for higher dimensions. 6.1.1 The horeshoe map Let us consider an example with interesting dynamics. There are two key features of the example which follows: Stretching: nearby points are being pulled further away from one another. folding distant points are being mixed together The aim is to see how chaotic orbits can arise from when stretching and folding are present are present. We schematically describe the mapping (See Figure 6.1). The process is as follows: we have a square \\(W\\) with vertices \\(A,B,C,D\\) embedded in the plane \\(\\R^2\\), a continuous, injective map \\(\\v{h}: \\R^2 \\to \\R^2\\) such that \\[\\v{h}(A) = A*, \\ \\v{h}(B) = B*, \\ \\v{h}(C) = C*, \\ \\v{h}(D) = D*\\] We assume that \\(\\v{h}\\) uniformly contracts distances horizontally and expands distances vertically. Figure 6.1: Stretching and folding of the horseshoe map Stretching and folding in the horseshoe map The fold (upper annulus) is outside the initial square \\(W\\). The intersection \\(W \\cap \\v{h}(W)\\) consists if two strips \\(V_1\\) and \\(V_2\\). On the 2nd iteration of \\(\\v{h}\\), we apply \\(\\v{h}\\) to the horseshoe. This results in a “4-stranded” horseshoe sitting inside the simple “2-stranded” horseshoe. Figure 6.2: Two iterations of the horseshoe map Figure 6.3: Four-stranded orange horseshoe inside original yellow horseshoe. Forward and backward orbits Let \\(\\v{x}_0\\) be a point in the square \\(W\\). Under \\(\\v{h}\\), \\(\\v{x}_0\\) maps to \\(\\v{x}_1\\) and \\(\\v{x}_0\\) maps under \\(\\v{h}^2\\) to a point \\(\\v{x}_2\\). This gives us a forward orbit \\((\\v{x}_0, \\v{x}_{1}, \\v{x}_{2}, \\ldots)\\). Note that the orbits might escape the square at some point, for instance if \\(\\v{x}_{0}\\) lies near the bottom of the square then it is stretched out of the square in the first iteration (as \\(\\v{h}\\)). We can also consider a backward orbit of \\(\\v{x}_0\\) as our map \\(h\\) is injective. We think of the point \\(\\v{x}_{-1} \\in W\\) (if it exists) such that \\(\\v{h}(\\v{x}_{-1}) = \\v{x}_0\\) and a point \\(\\v{x}_{-2}\\) (if it exists) such that \\(\\v{h}(\\v{x}_{-2}) = \\v{x}_{-1}\\) and so on. This gives rise to an orbit \\((\\v{x}_0, \\v{x}_{-1} \\v{x}_{-2} \\ldots)\\) Forward and backward orbits that always remain in the square Let us try to characterise the points whose forwards and backwards orbits never escape the square \\(W\\). Let us first think about the points with images inside of the horseshoe. That is points in \\(W\\) with images lying the two vertical strips \\(V_1\\) and \\(V_2\\) (see figure 6.1). We can figure this out either by unfolding the horseshoe or by applying the inverse of \\(h\\) to the region \\(h(W) \\cap W\\). Such a point \\(x_0\\) whose image \\(\\v{h}(\\v{x}_0)\\) lies in one of the vertical strips must originate from one of the two vertical strips \\(H_0\\) or \\(H_{1}\\) (Figure 6.4) Figure 6.4: Unfolding to find pre-images of vertical strips. Points \\(\\v{x}_0\\) in \\(W\\) whose pre-images also lie in \\(W\\) lie on the vertical strips. Therefore point in \\(W\\) with image and pre-image in \\(W\\) lie on the intersection of the horizontal and vertical strips (see Figure 6.5). Figure 6.5: Points whose image and pre-image lie in the square W. We can see that with successive iterations we obtain a fractal type construction (See Figure 4.13 in Subsection 4.3.2). The horizontal strips double with each step on the bottom and on the top (symmetrically) and become thinner, similarly for the vertical strips. The points in the intersections of the corresponding horizontal and vertical strips which remain in the limit correspond to the set \\[ \\Lambda = \\{ \\v{x} \\in W : \\v{h}^{k}(\\v{x}) \\in W \\forall \\ k \\in \\Z\\}. \\] 6.2 Chaotic attractors Thus far we have seen that the orbits of maps can be attracted to stable fixed points, stable periodic points and saddle fixed and saddle periodic points (along attracting axes). A question one can as is whether or not chaotic orbits can be “attracting”? What do we even mean by “attracting” in the context of chaotic orbits? Roughly speaking, we mean that a significant portion of initial conditions are attracted to the chaotic orbit. Consider Figures 6.6 and 6.7. Figure 6.6: Basin of chaotic attractor of the Hènon map Figure 6.7: Basin of chaotic attractor of the Ikeda map Figure 6.6 shows a chaotic orbit (non-periodic with Lyapunov exponent bigger than \\(0\\)) of the Hènon map for \\(a= 1.4\\) and \\(b =0.3\\). Figure 6.7 shows a chaotic orbit of the Ikeda map. The Ikeda map is the map \\(\\v{f}: \\R^2 \\to \\R^2\\) defined by \\[ \\v{f}(x,y) = (R + C_2(x \\cos \\tau - y \\sin \\tau), C_2(x \\sin \\tau + y \\cos \\tau)) \\] where \\(\\tau = C1 - C3/(1 + x^2 + y^2)\\) and \\(R, C_1, C_2,\\) and \\(C_3\\) are fixed real valued parameters. In Figure 6.7 \\(R=0.9, C_1,C_3= 0.4, 6\\). The grey area containing the black chaotic orbits represent points whose orbits converge to the chaotic orbit. The white region represents points which diverge to infinity or converge to a different attracting orbit. These two examples illustrate two key characteristics of a “chaotic attractor” It contains a contains a chaotic orbit; Attracts a set of initial values which has a non-zero area in the plane. 6.2.1 Forward Limit Set A consequence of the second attribute of a chaotic attractor given above is it is what is a called a forward limit set. We shall say precisely what we mean by this below. For the moment we roughly mean that a chaotic attractor is what is left over after throwing a away a (very) large number of initial points (say 1 million) of the orbit. The attracting nature of the chaotic attractor means we return to the vicinity of set of points that remain again and again. Consider Figure 6.8 Figure 6.8: Two attractors of the Ikeda map The first subplot shows the first 1000 points of two different orbits of the Ikeda map. The second subplot shows iterates 1,000,001 to 2,000,000 of the same two orbits. We can see that one orbit approaches the chaotic attractor and the other approaches a sink. Let us now give a precise definition of the forward limit set. Definition 6.2 (Forward limit set) Let \\(f\\) be a map (1D or ND) and \\(x_0\\) a point in the domain of \\(f\\). The forward limit set of the orbit \\(\\{ f^{n}(x_0): n \\in \\N \\}\\) is the set \\[ \\omega(x_0) = \\{x: \\forall \\ N \\in \\N \\text{ and } \\epsilon &gt;0, \\exists \\ n&gt;N \\text{ such that } |f^{n}(x_0) - x |&lt; \\epsilon \\}\\] The forward limit set is sometimes called the \\(\\omega\\)-limit set (“omega limit set”). Given points \\(x_0, x_1\\) in the domain of a map \\(f\\), We say that the orbit of \\(x_1\\) is attracted to the forward limit set of \\(x_0\\) if \\(\\omega(x_1)\\) is contained in \\(\\omega(x_0)\\). For the examples in Figure 6.8 the \\(\\omega\\)-limit set of the second initial condition, the one attracted to the sink, is the sink. Indeed any fixed point is its own forward limit set. Let us now formally define we mean by a chaotic attractor. Definition 6.3 (Chaotic attractor) Let \\(f\\) be a map and \\(x_0\\) a point in the domain of \\(f\\). Suppose that the orbit of \\(x_0\\) is chaotic. If \\(x_0\\) is in its \\(\\omega\\)-limit set \\(\\omega(x_0)\\), then \\(\\omega(x_0)\\) is called a chaotic set. An attractor is any forward limit set which attracts a set of initial values with a non-zero measure (i.e a measure appropriate to the dimension of the domain of the map: length in \\(\\R\\), area in \\(\\R^2\\), volume in higher dimensions). The set of initial conditions attracted to the attractor is called the basin of attraction of the attractor. A chaotic attractor is a chaotic set that is also an attractor. We conclude our studies of discrete-time dynamical systems. We have characterised key features of the dynamics of discrete dynamical systems in one and higher dimensions and have explored the concept of chaos. We have seen how in the midst of/ out of chaos order can arise. 6.3 Continuous-time dynamical systems As promised, the remainder of the module will be focused on continuous time dynamical systems. Whereas discrete time dynamical systems arose from maps on \\(\\R^{n}\\) (for some \\(n\\)), continuous time dynamical systems are defined by differential equations. In this module we only consider Ordinary Differential Equations (ODE’s) as opposed to partial or stochastic differential equations. ODE’s are differential equations whose solutions are functions of one independent variable \\(t\\) (which in this module represents time). Solutions we seek are of the form \\(x(t)\\) where \\(x\\) typically represents a physical quantity that depends on time; \\(x\\) is a dependent variable. There are two main types of ODE’s Autonomous ODE’s: the independent variable \\(t\\) does not explicitly appear in the ODE e.g. \\[ \\der{x}{t} = ax\\] Non-autonomous ODE’s: the variable \\(t\\) appears explicitly in the ODE. e.g. \\[ \\dern{x}{t}{2} = -c \\der{x}{t} - \\sin x + \\rho \\sin t.\\] We only focus on autonomous ODE’s; any non-autonomous dynamical system can be recast as an autonomous one. For instance, for the system \\[ \\dern{x}{t}{2} = -c \\der{x}{t} - \\sin x + \\rho \\sin t.\\] we can introduce a new variable \\(y\\) satisfying \\(\\der{y}{t} = 1\\). This gives a 2-dimensional continuous time autonomous system governed by the rules \\[\\begin{align*} &amp;\\dern{x}{t}{2} = -c \\der{x}{t} = \\sin x + \\rho \\sin y \\\\ &amp; \\der{y}{t} = 1 \\end{align*}\\] Let \\(\\v{x}(t) = ( x_1(t), x_2(t), \\ldots, x_{n}(t))\\) describe the state of a continuous time dynamical system \\(\\der{\\v{x}}{t} = \\v{R}(\\v{x})\\) on \\(\\R^{n}\\) where \\(\\v{R}: \\R^{n} \\to \\R^{n}\\) is a map. The evolution of the system is governed by the rule \\[\\der{\\v{x}}{t} = \\v{R}(\\v{x}).\\] Example 6.1 The ODE \\(\\der{x}{t} = a x (1-x)\\) describes dynamical system. As the variable \\(x\\) approaches \\(1\\), \\(\\der{x}{t}\\) approaches \\(0\\) and the population \\(x\\) approaches a steady state. This a 1D-non-linear ODE and gives rise to a 1D continuous time dynamical systemm on \\(\\R\\). What about a \\(2D\\) example? Let \\(\\v{R} = (R_x(x,y), R_{y}(x,y))\\) be a map on \\(\\R^2\\). The pair of ODES: \\[\\begin{align*} &amp;\\der{x}{t} = R_{x}(x,y) := ax + by^2 \\\\ &amp;\\der{y}{t} = R_{y}(x,y) := cy + dy^2 \\end{align*}\\] Gives rise to a continuous time dynamical system on \\(\\R^2\\). The technique we applied to recast a non-autonomous ODE as an autonomous one by introducing an extra variable can be repeatedly applied to recast a high-order ODE as a system of first order linear ODE’s. Example 6.2 Consider the non-linear damped oscillator governed by the rule \\[\\begin{equation} \\dern{x}{t}{2} = -c \\der{x}{t} - \\sin x \\tag{6.1} \\end{equation}\\] A second order ODE. Introduce a new variable \\(y\\) satisfying \\(y = \\der{x}{t}\\) so that \\(\\der{y}{t} = \\dern{x}{t}{2}\\). Then we can rewrite (6.1) as the system: \\[\\begin{align*} &amp;\\der{x}{t} = y \\\\ &amp;\\der{y}{t} = -cy - \\sin x. \\end{align*}\\] To solve a system of linear ODE’s we need to have two conditions satisfied: Initial conditions for each variable \\(x_i\\) of the ODE. That is for a system of \\(n\\) linear ODE’s with variables \\(x_1, x_2, \\ldots, x_{n}\\) we need initial conditions \\[ x_1(0) = x_{1,0}, x_2(0) = x_{2,0}, \\ldots, x_n(0) = x_{n,0}\\] For a given set of initial conditions, the ODE must have a unique solution. Moreover, this solution should be continuous (no singularities). The set of all solutions of an ODES is called the flow of the ODE. To be more precise Definition 6.4 The flow of an autonomous ODE is the function \\(\\v{F}\\) of time \\(t\\) and the initial value \\(\\v{x}_0\\) which represents the set of solutions. So \\(\\v{F}(t, \\v{x}_0)\\) (alternatively \\(\\v{F}_{t}(\\v{x}_0)\\)) is the value at time \\(t\\) of the solution with initial value \\(\\v{x}_0\\). The reason for the alternative notation is that in some situations we might want to think of the evolution of the dynamical system at a fixed time \\(t=T\\) units later (the time-T-map), the notation \\(\\v{F}_{T}(\\v{x}_0)\\) makes it apparent that we are fixing \\(t=T\\) and looking at the solution \\(T\\) time units later of the initial condition \\(\\v{x}_0\\). By considering the time \\(T\\)-map we discretise our dynamical system: \\(\\v{x}_{n+1} = \\v{F}_{T}(\\v{x}_{n})\\). The resulting discrete time dynamical system gives the evolution of the system at time units of \\(T\\). Example 6.3 (Example of a flow) Consider the ODE \\[ \\der{x}{t} = a x \\] for \\(a\\) a real constant. This is a separable ODE and has solutions \\(x(t) = Ce^{at}\\) where \\(C = x(0)\\). Given an initial value \\(x(0) = x_0\\), the solution of the initial value problem \\[ \\der{x}{t} = a x, \\ x(0) = x_0 \\] is \\(x(t) = x_0 e^{at}\\). The flow of the ODE is the function \\(F(t, x) = x e^{at}\\), for initial condition \\(x = x_0\\), we have \\(F(t,x_0) = x_0 e^{at}\\). Figure 6.9 show solutions for various values of \\(x_0\\) in the regimes \\(a&gt;0\\) and \\(a&lt;0\\). Figure 6.9: Flow of linear ODE dx/dt = ax 6.3.1 Equilibria When we considered discrete time dynamical systems we found it useful to study fixed points and their stability. For continuous time dynamical systems, as these are governed by ODE’s, the equivalent of a fixed point is called an equilibrium these are solutions that do not change in time. Definition 6.5 (Equilibrium) A constant solution of the autonomous differential equation \\(\\der{x}{t} = f(x)\\) is called an equilibrium of the equation. Example 6.4 Consider the ODE \\(\\der{x}{t} = a x\\). The solution \\(x=0\\) is an equilibrium of the equation. In general equilibria of ODE’s \\(\\der{\\v{x}}{t} = \\v{R}(\\v{x})\\) are constant solutions. 6.4 Problem Sheet 6 For week 7. Question 6.1 Let \\(\\mathfrak{C}_{5}\\) denote the middle-1/5 Cantor set. This set is defined similarly to the middle-third Cantor set only at each step we remove the middle 5th part of the intervals remaining. Determine the box-counting dimension of \\(\\mathfrak{C}_{5}\\). Show Solution 6.1 Solution 6.1 The argument proceeds very similarly to Example 5.1 in the notes. After step 1 of the construction we have two intervals of length \\(2/5\\). After step \\(2\\) of the construction we have \\(4\\) intervals of length \\(4/25\\). After step \\(3\\) we have \\(8\\) intervals of length \\(8/125\\). Inductively, Suppose after step \\(n\\) of the process we have \\(2^{n}\\) intervals of length \\((2/5)^{n}\\). Consider an interval of length \\((2/5)^{n}\\). It’s middle fifth has size \\(2^{n}/5^{n+1}\\). After deleting this middle fifth the combined length of the two remaining intervals is \\(2^{n+2}/5^{n+1}\\), and so the two remaining intervals have length \\(2^{n+1}/5^{n+1}\\) each. In particular after step \\(n+1\\), there are \\(2^{n+1}\\) intervals of length \\(2^{n+1}/5^{n+1}\\). Taking \\(\\epsilon = (2/5)^{n}\\), then we need \\(N(\\epsilon) = 2^{n}\\) intervals to cover \\(\\mathfrak{C}_{5}\\). Taking the limit we have \\[ \\bdim(\\mathfrak{C}_{5}) = \\lim_{n \\to \\infty}\\frac{\\ln 2^{n}}{\\ln(5/2)^{n}} = \\lim_{n \\to \\infty}\\frac{\\ln(2)}{\\ln(5/2)} = \\frac{\\ln(2)}{\\ln(5/2)}. \\] Question 6.2 The skinny baker’s map is a map from \\([0,1] \\times [0,1]\\) to itself defined as follows: \\[ \\v{B}(x,y) = \\begin{cases} \\begin{pmatrix} \\frac{1}{3} &amp; 0 \\\\ 0 &amp; 2\\end{pmatrix} \\begin{pmatrix} x \\\\ y\\end{pmatrix} &amp; \\text{ if } 0 \\le y \\le \\frac{1}{2} \\\\ \\begin{pmatrix} \\frac{1}{3} &amp; 0 \\\\ 0 &amp; 2\\end{pmatrix} \\begin{pmatrix} x \\\\ y\\end{pmatrix} + \\begin{pmatrix} \\frac{2}{3} \\\\ -1\\end{pmatrix} &amp; \\text{ if } \\frac{1}{2} &lt; y \\le 1 \\end{cases} \\] Sketch the image of the unit square under the action of the map. What image do you expect after two and three iterates? Can you describe the set of points the original unit square is mapped onto if the number of iterations goes to infinity? Calculate the Lyapunov numbers and exponents of orbits of the skinny baker map which never map onto the line \\(y = 1/2\\). [Hint: use the fact that as the skinny baker’s map is a linear map, up to translation, it is equal to the map defined by its Jacobian matrix. You can then use the fact that the expansion/contraction factors \\(r^{n}_{k}\\) are given by the square roots of the eigenvalues of \\(\\jacob^{n} \\cdot (\\jacob^{n})^{t}\\). Here, for a matrix \\(A\\), we write \\(A^{t}\\) for the transpose of \\(A\\).] What can you conclude about the possibility of chaotic orbits? Show Solution 6.2 Solution 6.2 First we divide the unit square with the line \\(y = 1/2\\). The bottom half is mapped into the grey-shaded vertical strip (Figure 6.10): here we are uniformly stretching vertically by \\(2\\) and uniformly compressing horizontally by \\(1/3\\). The top-half maps into blue shaded vertical strip. Therefore after one application of the baker map, the middle-third square has been deleted. In the second application, the bottom half of the grey shaded strip is compressed by \\(1/3\\) and stretched by \\(2\\). The top-half is likewise compressed by a \\(1/3\\) and stretched by \\(2\\) and is also shifted to the right by \\(2/3\\). The bottom half of the blue shaded strip is compressed by a \\(1/3\\) and streched by a 2 into the a vertical strip in the interval \\((2/9, 1/3)\\). The top half is compressed and stretched into the vertical strip in the interval \\([8/9,1]\\). After \\(2\\) applications of the baker map, the “middle-third of the middle-thirds” have been deleted. The process now repeats. In the limit, the set of points that remain are line segments of length one at each point in the middle third Cantor set i.e. the set \\(\\mathfrak{C}_{3} \\times [0,1]\\). Figure 6.10: Sketch of skinny baker’s map The Jacobian matrix \\(\\vec{{\\mathrm{D}}B}\\) is given by the coefficients of \\(x\\) and \\(y\\) since \\(\\v{B}\\) is a linear map. We have: \\[ \\vec{{\\mathrm{D}}B} = \\begin{pmatrix} \\frac{1}{3} &amp; 0 \\\\ 0 &amp; 2 \\end{pmatrix}. \\] This is a diagonal matrix and so equal to its transpose. We therefore compute \\[ \\vec{{\\mathrm{D}}B}^{k} (\\vec{{\\mathrm{D}}B}^{t})^{k} = \\vec{{\\mathrm{D}}B}^{2k} \\begin{pmatrix} \\frac{1}{3^{2k}} &amp; 0 \\\\ 0 &amp; 2^{2k} \\end{pmatrix}. \\] Therefore the eigenvalues of \\(\\vec{{\\mathrm{D}}B}^{k} (\\vec{{\\mathrm{D}}B}^{t})^{k}\\) are \\(1/3^{2k}\\) and \\(2^{2k}\\). This means that \\(r_1^{k} = 2^{k}\\) and \\(r_2^{k} = 1/3^{k}\\). This gives Lyapunov numbers \\(L_1 = 2\\) and \\(L_2 = 1/3\\) and Lyapunov exponent \\(h_1 = \\ln(2)&gt;1\\) and \\(h_2 = \\ln(1/3) &lt;0\\). From b. it follows that any non-asymptotically periodic orbit will be chaotic. Question 6.3 Consider Smale’s Horseshoe map \\(\\v{h}\\) (Subsection 6.1.1 in the notes). Recall that \\(\\Lambda\\) is defined to be the set of points whose forwards and backwards orbits always remain in the square \\(W\\). We can associate to each point of \\(\\Lambda\\) a sequence of \\(0\\)’s and \\(1\\)’s as follows The intersection of the image of the unit square with the unit square defines two vertical strips \\(V_{1}\\) and \\(V_{2}\\). \\(\\v{h}^{n}(\\v{x})\\) must be in \\(V_{1}\\) or \\(V_{2}\\) if \\(\\v{x} \\in \\Lambda\\) since \\(\\Lambda\\) is a subset of \\(V_{1} \\cup V_{2}\\). If \\(\\v{x} \\in V_{1}\\) the sequence begin with \\(0\\), otherwise \\(\\v{x} \\in V_{2}\\) and the sequence begins with \\(1\\). If \\(\\v{h}(\\v{x}) \\in V_{1}\\) the sequence continues with \\(0\\) otherwise \\(\\v{h}(\\v{x}) \\in V_{2}\\) and the sequence continues with \\(1\\). If \\(\\v{h}^{n}(x) \\in V_{1}\\) then the \\((n+1)\\)st symbol in the sequence is \\(0\\), otherwise it is \\(1\\) and so on. One application of the horseshoe map can be thought of as shifting our position in the sequence one symbol to the right. Using this analogy show that Smale’s horseshoe map has two fixed points. To what symbols do the fixed points correspond? Show Solution 6.3 Solution 6.3 Notice that an infinite sequence of zeros and ones corresponding to the forward orbit of a point in \\(\\Lambda\\) as described above, actually represents vertical line of points in \\(V_1\\). In order to describe a point in \\(\\Lambda\\) we apply a similar logic to the horizontal strips. This means that each point \\(x \\in \\Lambda\\) can be represented by a bi-infinite sequence of \\(0\\)’s and \\(1\\)’s as \\(\\ldots a_{-2}a_{-1}a_0\\circ a_1 a_2 \\ldots\\) where \\(a_i \\in \\{0,\\}\\) for all \\(i \\in \\Z\\) and \\(\\circ\\) comes right after the \\(0\\) index (i.e it separates the forward itinerary from the backward). Let \\(x_0 \\in \\Lambda\\) and let \\(\\ldots a_{-2}a_{-1}a_0\\circ a_1 a_2 \\ldots\\) be its symbolic representation. For \\(k \\in \\Z\\), the point \\(f^{k}(x_0)\\) has symbolic representation \\(\\ldots a_{k-2}a_{k-1}a_{k}\\circ a_{k+1} a_{k+2}\\ldots\\). If \\(x_0\\) is a fixed point then the equality \\[\\ldots a_{k-2}a_{k-1}a_{k}\\circ a_{k+1} a_{k+2}\\ldots = \\ldots a_{-2}a_{-1}a_{0}\\circ a_{1} a_{2}\\ldots\\] holds for all \\(k \\in \\N\\). In particular \\(a_i = a_{j}\\) for all \\(j \\in \\Z\\). Therefore the two fixed points of Smale’s horseshoe map are represented by the infinite sequences \\(\\ldots 000\\circ 000 \\ldots\\) and \\(\\ldots 111\\circ 111 \\ldots\\). References "],["continuous-time-dynamical-systems.html", "Chapter 7 Equilibria and stability in continuous time dynamical systems 7.1 Equilibria 7.2 Lyapunov Functions I 7.3 Problem Sheet 7", " Chapter 7 Equilibria and stability in continuous time dynamical systems Covers Chapter 7 Sections 7.2 to 7.5 (Alligood, Sauer, and Yorke 2000). 7.1 Equilibria We concluded the last chapter by stating that the analogue of fixed points in continuous time dynamical system is an equilibrium. To reiterate, equilibria occur as solutions to the equation \\[ \\der{\\v{x}}{t} = \\v{R}(\\v{x}) = 0. \\] Example 7.1 The ODE \\(\\der{x}{t} = ax(1-x)\\) has equilibria at \\(x = 0\\) and \\(x =1\\). Writing \\(\\v{x}=(x,y)\\) for an arbitrary point in \\(\\R^2\\), the ODE \\(\\der{\\v{x}}{t} = \\v{R}(\\v{x}) = (y, -ay - \\sin x)\\). Has equilibria at points in the set \\(\\{ (n \\pi, 0) : n \\in \\Z \\}\\). Since these are the points at which \\(\\v{R}(\\v{x}) = 0\\). Now that we have analogues of fixed point for continuous time dynamical systems, we introduce the notion of stability in these systems. Definition 7.1 (Continuous stability) Consider an autonomous differential equation with flow \\(\\v{F}(t,x)\\). An equilibrium of \\(\\v{v}\\) of the system is called stable if all nearby solutions stay close to the equilibrium for all future times. Formally for any neighbourhood \\(N\\) of \\(\\v{v}\\) there is a neighbourhood \\(N_1 \\subseteq N\\) of \\(\\v{v}\\) such that for all points \\(\\v{x} \\in N_1\\), \\(\\v{F}(t, \\v{x})\\) remains in \\(N_1\\) for all \\(t \\ge 0\\). unstable if it is not stable. asymptotically stable if it is both stable and attracting (nearby solutions converge to the equilibrium) globally asymptotically stable if it is asymptotically stable and all initial values converge to the equilibrium. The example below generalises a scheme we applied when investigating stability of fixed points for discrete time dynamical systems (see Subsections 2.1 and 2.3.1). Example 7.2 Consider an ODE \\[ \\der{\\v{x}}{t} = \\v{R}(\\v{x}) \\] and suppose \\(\\v{x}_{e}\\) is an equilibrium of the ODE. Let \\(\\epsilon&gt;0\\) be very small so that \\(\\v{x} = \\v{x}_{e} + \\epsilon \\v{u}\\) is an initial condition very close to the equilibrium \\(\\v{x}_{e}\\). Then \\[\\begin{equation} \\der{\\v{x}}{t} = \\v{R}(\\v{x}_{e} + \\epsilon \\v{u}) = \\der{\\v{x}_{e}}{t} + \\epsilon \\der{\\v{u}}{t} \\tag{7.1} \\end{equation}\\] Now using the fact that \\(\\v{x}_{e}\\) is an equilibrium, and taking a Taylor series approximation of \\(\\v{R}\\) at \\(\\v{x}_{e}\\) Equation (7.1) becomes: \\[ \\epsilon \\der{\\v{u}}{t} \\simeq \\epsilon \\jacobr(\\v{x}_{e}) \\cdot \\v{u} \\] Cancelling out \\(\\epsilon\\) (which is non-zero by assumption) we have: \\[ \\der{\\v{u}}{t} \\simeq \\jacobr(\\v{x}_{e}) \\cdot \\v{u} \\] A linear ODE with constant coefficients for \\(u\\). Our analysis now follows as in the discrete time case. Let \\(\\lambda_{i}\\), \\(i = 1,2,\\ldots, n\\) be the eigenvalues of \\(\\jacobr(\\v{x}_{e})\\) and \\(\\v{v}_{i}\\) the corresponding eigenvectors. The general solution for \\(\\v{u}\\) is given by \\[\\v{u}(t) = \\sum_{i =1}^{n} {u}_i \\v{v}_{i} e^{\\lambda_i t} \\] where the \\(u_i\\)’s are constants and \\(\\v{u}_{0} = \\sum_{i =1}^{n} {u}_i \\v{v}_{i}\\). Thus we expect that if the real part of all eigenvalues of \\(\\jacobr(\\v{x}_{e})\\) are strictly less than \\(0\\) then the equilibrium is stable; if the real part of one of the eigenvalues is positive, the equilibrium is unstable. The following result sums up this conclusion. Theorem 7.1 Let \\(\\v{x}_{e}\\) be an equilibrium of \\(\\der{\\v{x}}{t} = \\v{R}(\\v{x})\\). If the real part of each eigenvalue of \\(\\jacobr(\\v{x}_{e})\\) is strictly less than zero, then \\(\\v{x}_{e}\\) is asymptotically stable. If the real part of at least one eigenvalue is strictly positive, then \\(\\v{x}_{e}\\) is unstable. Example 7.3 Let us apply Theorem 7.1 to classify the equilibria of the system: \\[\\begin{align*} &amp;\\der{x}{t} = x^2 - y^2 \\\\ &amp;\\der{y}{t} = xy -4 \\end{align*}\\] There equilibria occur at \\((-2,-2)\\) and \\((2,2)\\). Write \\(\\v{f}(x,y)\\) for the function on \\(\\R^2\\) given by \\((x,y) \\mapsto (x^2 - y^2, xy-4)\\). The Jacobian of \\(\\v{f}\\) is: \\[\\begin{pmatrix} 2x &amp; -2y \\\\ y &amp; x \\end{pmatrix}\\] At the point \\((x,y) = (2,2)\\) we have: \\[\\jacob(2,2) = \\begin{pmatrix} 4 &amp; -4 \\\\ 2 &amp; 2 \\end{pmatrix}\\] The eigenvalues of this matrix are the roots of the equation \\(x^2 - 6x + 16 = 0\\). This has complex solutions \\(\\lambda_1,\\lambda_2 = 3 \\pm i\\sqrt{7}\\). Therefore the point \\((2,2)\\) is an unstable equilibrium of the system. At the point \\((x,y) = (-2,-2)\\), the Jacobian matrix is: \\[\\jacob(-2,-2) = \\begin{pmatrix} -4 &amp; 4 \\\\ -2 &amp; -2 \\end{pmatrix}\\] This matrix has eigenvalues \\(\\lambda_1, \\lambda_2 = -3 \\pm i\\sqrt{7}\\). Therefore the point \\((-2,-2)\\) is an asymptotically stable fixed point. As with higher-dimensional discrete time dynamical systems, it is possible that an equilibrium of a continuous time system, has at least one attracting direction and at least one repelling direction. In this case we again apply the term saddle to describe such an equilibrium. The following definition should be compared with 2.7. Definition 7.2 An equilibrium \\(\\v{x}_{e}\\) of a system \\(\\der{\\v{x}}{t} = \\v{f}(\\v{x})\\) is called hyperbolic if none of the eigenvalues of \\(\\jacob(\\v{x}_{e})\\) has real part equal to \\(0\\). If an equilibrium \\(\\v{x}_{e}\\) of \\(\\der{\\v{x}}{t} = \\v{f}(\\v{x})\\) is hyperbolic and has at least one eigenvalue with a positive real part and at least one eigenvalue with a negative real part, then \\(\\v{x}_{e}\\) is called a saddle. We can similarly extend Definition 3.2 to continuous time dynamical systems using the flow \\(\\v{F}(t,\\v{x})\\) of the differential equation. Definition 7.3 Let \\(\\v{x}_{e}\\) be a saddle of a system \\(\\der{\\v{x}}{t} = \\v{f}(\\v{x})\\). Let \\(\\v{F}(t,\\v{x})\\) be the flow of the system. The stable manifold of \\(\\v{x}_{e}\\) is the set \\(\\v{x}\\) of points in \\(\\R^{n}\\) such that \\[\\lim_{t \\to \\infty} |\\v{F}(t,\\v{x}) - \\v{F}(t, \\v{x}_e)| = 0.\\] The unstable manifold of \\(\\v{x}_{e}\\) is the set \\(\\v{x}\\) of points in \\(\\R^{n}\\) such that \\[\\lim_{t \\to \\infty} |\\v{F}(-t,\\v{x}) - \\v{F}(-t, \\v{x}_e)| = 0.\\] 7.2 Lyapunov Functions I Looking over the argument in Example 7.2, we see that it is only valid for deducing stability in a small neighbourhood of the equilibrium point i.e for small perturbations from the equilibrium point. This is a consequence of approximating the function \\(\\R(x)\\) with a linear function via its Taylor expansion (this technique is commonly referred to as linearisation). Figure 7.1 shows an equilibrium point which is stable against small perturbations to the left and to the right, but is unstable for large perturbations. Figure 7.1: Ball in a potential well We need to take a different approach then when investigating stability against large perturbations which occurs for example for globally asymptotically stable equilibria. The approach which is of use in this situation is the method of Lyapunov functions. Example 7.4 Perhaps the best way of motivating Lyapunov functions is to consider the motion of a dynamical system through a potential field. That is, we have a potential field \\(V = V(x(t))\\) (which tells us the potential energy of at a point \\(x\\)), and a dynamical system governed by the rules \\[\\begin{align} &amp;\\der{x}{t} = y \\\\ &amp;\\der{y}{t} = - \\pder{V}{x} \\tag{7.2} \\end{align}\\] One way of thinking about this is as follows. If \\(x\\) represents position, then \\(\\der{x}{t}\\) is velocity (change of position with time) and \\(\\der{y}{t}\\) is acceleration. Now acceleration is proportional to the force at the point \\(x\\) and the force is equal to minus the gradient of the velocity (\\(-\\nabla{V} = -\\pder{V}{x}\\) in this example). Thus the dynamical system moving through a potential can be thought of in terms of Newton’s 2nd Law of motion. From equation (7.2) we have \\[\\begin{equation} \\dern{x}{t}{2} + \\pder{V}{x} = 0 \\tag{7.3} \\end{equation}\\] Multiplying by equation (7.3) by \\(\\der{x}{t}\\) and using \\(\\der{V}{t} = \\pder{V}{x} \\der{V}{t}\\) we get: \\[\\begin{equation} \\der{x}{t}\\dern{x}{t}{2} + \\der{V}{t} = \\der{}{t}\\left(1/2 \\left(\\der{x}{t}\\right)^2 + V(x)\\right) = 0. \\tag{7.4} \\end{equation}\\] Lastly observe that the total energy is the sum of the potential and kinetic energy and so the term \\(1/2 \\left(\\der{x}{t}\\right)^2 + V(x)\\) is just the total energy \\(E(x,y)\\). Equation (7.4) can now be interpreted as saying that the total energy in the system is conserved along an orbit — it does not change with time; in symbols for an initial value \\((x,y)\\) and \\(F(t, (x,y))\\) the flow of the system of differential equations, \\(\\der{E}{t}(F(t, (x,y))) = 0\\) for all \\(t\\). Note The inclusion of the phrase “along a trajectory” is essential, since we considered the motion of a particle (i.e the orbit of an initial value) in the vector field. In particular for different orbits the total energy \\(E\\) along each orbit might be different. For a dynamical system moving in a potential field as above, we have two ways of visualising the orbits of the dynamical system. By sketching the potential field \\(V(x)\\) By plotting phase plane trajectories. That is at each point \\(\\left(x, y = \\der{x}{t}\\right)\\) we plot the gradient vector \\(\\left( \\der{x}{t}, \\der{y}{t}\\right)\\) at the point. Let us illustrate approach i. using Example 7.4 Example 7.5 Suppose we are in the context of Example 7.4 and the potential \\(V(x)\\) is as in Figure 7.2 Figure 7.2: Sketch of potential field Thus the potential has a local minimum at \\(x_{min}\\) and a local maximum at \\(x_{max}\\), and \\(E_1 = V(x_1)\\) is the potential energy at \\(x_1\\). We suppose the trajectory begins at rest from the point \\(x_{1}\\), so that initially there is no kinetic energy and the total energy is equal to the potential energy (note that this implies that \\(y_1 = 0\\) since the kinetic energy at \\((x_1,y_1)\\) is equal to \\(y_1^2/2\\)). This means that the energy along the trajectory/orbit is constantly equal to \\(E_1\\). Thus, to figure out the subsequent behaviour of the trajectory the key value to consider is \\(E_1 - V(x,y) = 1/2 y^2 = E_{kin}\\) where \\(E_{kin}\\) is the kinetic energy. Now at points where \\(V(x) = E_1\\), there is no kinetic energy and so \\(y = \\der{x}{t} =0\\) for such points. Points at which \\(V(x) = E_1\\) are called turning points — the velocity changes direction around these points. If \\(\\der{x}{t} = 0\\) and \\(\\pder{V}{x} =0\\), then \\(x\\) is an equilibrium point: the particle is at rest and has no forces acting on it. For this example, \\(x_{min}\\) is an equilibrium point. If orbits originating near an equilibrium point oscillate around it, then in particular they never move far away from it, this means that the equilibrium is stable. For instance, the equilibrium at \\(x_{min}\\) is stable, since orbits originating near \\(x_{min}\\) remain stuck in the potential well between the points \\(x_1\\) and \\(x_2\\). For orbits originating at rest from the local maximum \\(x_{max}\\), they either get stuck in a potential well to the left of \\(x_{max}\\) or move away from \\(x_{max}\\) towards \\(+ \\infty\\) — \\(x_{max}\\) is an unstable equilibrium. 7.3 Problem Sheet 7 For week 8. Question 7.1 Write the following equations describing continuous-time dynamical systems as a set of first order autonomous ODEs. What is the dimension of the phase space of these dynamical systems? \\(\\dern{x}{t}{2} + (x^2 -1) \\der{x}{t} + x = 0\\), \\(\\dern{x}{t}{2} - x\\sin^2 t =0\\) Show Solution 7.1 Solution 7.1 Set \\(y = \\der{x}{t}\\). We can rewrite the ODE as a set of first order autonomous ODE’s as: \\[\\begin{align*} \\der{y}{t} &amp;= (1-x^2) y - x \\\\ \\der{x}{t} &amp;= y. \\end{align*}\\] The phase space has dimension 2. Set \\(y = \\der{x} t\\) and \\(z = t\\). We can rewrite the ODE as a set of first order autonomous ODE’s as: \\[\\begin{align*} \\der{x}{t} &amp;= y, \\\\ \\der{y}{t} &amp;= x \\sin^2 z, \\\\ \\der{z}{t} &amp;= 1. \\end{align*}\\] The phase space has dimension 3. Question 7.2 Solve the ODE \\[ \\der{x}{t} = x^2\\] with initial condition \\(x(t_0) = x_0 &gt;0\\). Show that the solution goes to infinity (blows up) at a finite time. Show Solution 7.2 Solution 7.2 Using separation of variables we have: \\[ \\int x^{-2} \\d x = \\int \\d t. \\] Integrating we get \\[ -\\frac{1}{x} = t + c. \\] For some constant \\(c\\). Using the initial condition \\(x(t_0) = x_0\\), we find \\(c = -\\left(\\frac{x_0t_0 + 1}{x_0}\\right)\\). Rearranging we get: \\[ x = \\frac{x_0}{1-x_0(t-t_0) }. \\] Clearly, as \\(t\\) gets closer and closer to \\(\\frac{ 1 + x_0 t_0}{x_0}\\) the solutions “blow up” (they become very large very quickly). Question 7.3 Consider the \\(2\\)D dynamical system give in polar coordinates \\(r\\) and \\(\\theta\\) by \\[ \\der{r}{t} = r(1-r), \\quad \\der{\\theta}{t} =1. \\] Solve the differential equations. Sketch in the \\((x,y)\\)-plane, indicating typical behaviour, solutions corresponding to initial conditions \\(r_0&lt;1\\), \\(r_0 =1\\) and \\(r_0 &gt;1\\) where \\(r_0 = r(0)\\). Determine the time-2\\(\\pi\\) map of the system. Consider only the \\(r\\)-part of the time-2\\(\\pi\\) map. Determine the fixed points and their stability. To which solutions of the differential equations do the fixed points correspond? Show Solution 7.3 Solution 7.3 Solving the second ODE first, we find \\(\\theta = t + \\theta_0\\) where \\(\\theta_0 = \\theta(0)\\). For the first ODE, we use separation of variables and partial fractions. Write \\[ \\frac{1}{1-r} = \\frac{ 1}{r} + \\frac{1}{1-r}. \\] We have: \\[\\begin{align*} &amp;\\int \\frac{ 1}{r} + \\frac{1}{1-r} \\d r = \\int \\d t \\\\ &amp; \\ln \\left|\\frac{r}{1-r}\\right| = t + c \\\\ &amp; \\frac{r}{1-r} = Ae^{t}, \\quad A = \\frac{r_0 }{1-r_0} \\\\ &amp; r = \\frac{Ae^{t}}{1+ Ae^{t}} \\\\ &amp; r = \\frac{r_0 e^{t}}{ 1- r_0 + r_0 e^{t}} \\\\ &amp; r = \\frac{r_0}{(1-r_0)e^{-t} + r_0}. \\end{align*}\\] We sketch solutions in the \\((x,y)\\)-plane using the fact that \\[x = r\\cos \\theta = \\frac{r_0}{(1-r_0)e^{-t} + r_0} \\cos (\\theta_0 + t),\\] and \\[\\quad y = \\frac{r_0}{(1-r_0)e^{-t} + r_0} \\sin (\\theta_0 + t).\\] Notice that as \\(t\\) tends to infinity \\(r\\) tends to 1. For \\(r_0 &lt;1\\) our solutions spiral out towards the circle of radius \\(1\\). For \\(r_0 &gt;1\\) solutions spiral in towards the circle of radius \\(1\\). When \\(r_0 = 1\\) then \\(r = 1\\), and we simply have the circle of radius \\(1\\). In Figure 7.3 the blue curve corresponds to \\(r_0 &lt;1\\), the black is the circle of radius \\(1\\) (corresponding to \\(r_0 = 1\\)) and the red curve is for \\(r_0 &gt;1\\). Figure 7.3: Sketch of solutions for r&lt;1, r=1 and r&gt;1. The flow of the system is given by \\(F_{t}(r, \\theta) = \\left(\\frac{r_0}{(1-r_0)e^{-t} + r_0}, \\theta_0 + t\\right)\\). The time-\\(2\\pi\\) map is given by \\[F_{2\\pi}(r, \\theta) = \\left(\\frac{r_0}{(1-r_0)e^{-2\\pi} + r_0}, \\theta_0 + 2\\pi \\right).\\] This defines a dynamical system: \\[ (r_{n+1}, \\theta_{n+1}) = \\left(\\frac{r_n}{(1-r_n)e^{-2\\pi} + r_n}, \\theta_n + 2\\pi \\right). \\] The \\(r\\)-part of the time-\\(2\\pi\\) map is given by \\[ r_{n+1} = \\frac{r_n}{(1-r_n)e^{-2\\pi} + r_n}. \\] The fixed points are occur when \\[ r = \\frac{r}{(1-r)e^{-2\\pi} + r} \\] Which is when \\(r=0\\) or \\(r =1\\). The fixed point \\(r=0\\) and \\(r=1\\) correspond to the equilibria of the ODE \\(\\der{r}{t} = r(1-r)\\). We have already seen that initial points very near but not equal to \\(0\\) move away from \\(0\\) as \\(t\\) gets larger. While orbits near \\(1\\) move closer to \\(1\\) as \\(t\\) gets larger. Since \\(r\\) part of the time-\\(2\\pi\\) simply discretises the continuous time dynamical system given by the ODE, we conclude that the fixed point at \\(0\\) is unstable and the fixed point at \\(1\\) is stable. Note that one may also investigate the stability of fixed points of the discrete-dynamical system using the techniques of Chapter 1, that is by computing the absolute value of the derivative of \\(f\\) at the fixed points (where \\(f(r) = r/\\left((1-r)e^{-2\\pi} + r\\right)\\)). References "],["Lyapunov-functions.html", "Chapter 8 Lyapunov Functions 8.1 Lyapunov Functions II 8.2 Equilibira and Lyapunov functions 8.3 Periodic orbits and limit sets 8.4 Problem Sheet 8", " Chapter 8 Lyapunov Functions Covers Chapter 7 Section 7.6 to Chapter 8 Section 8.1 (Theorem 8.3) (Alligood, Sauer, and Yorke 2000). 8.1 Lyapunov Functions II We continue with Example 7.4 and illustrate method ii. (plotting phase plane trajectories) for visualising the orbit of a dynamical system moving in a potential field. Example 8.1 The context is as follows. We have a dynamical system governed by the rule: \\[\\begin{align} &amp;\\der{x}{t} = y \\\\ &amp;\\der{y}{t} = - \\pder{V}{x} \\tag{8.1} \\end{align}\\] where \\(V(x)\\) is a potential field (see 8.2). We examine how \\(y = \\der{x}{t}\\) changes as \\(x\\) increases and \\(E_1 - V(x)\\) changes. As \\(x\\) increases from \\(x_1\\) to \\(x_2\\), the difference \\(E_1 - V(x)\\) representing the kinetic energy, increases from \\(0\\) to a maximum value at \\(x_{min}\\) and then decreases to \\(0\\) again. Consequently the velocity \\(\\der{x}{t}\\) also increases from \\(0\\) to some maximum value at \\(x_{min}\\) and then decreases to \\(0\\) again. Now recollecting that \\(x_1\\) and \\(x_2\\) are turning points, the velocity changes direction and reverses the process describes above: it moves from \\(x_2\\) to \\(x_1\\), with the velocity (now negative) decreasing from \\(0\\) to a minimum at \\(x_{min}\\) and then increasing back to \\(0\\) at \\(x_2\\) at which point the whole process repeats. Therefore we have a closed orbit between \\(x_1\\) and \\(x_2\\) and initial values in this region gives rise to periodic orbits: (as noted before) the system oscillates between the values \\(x_1\\) and \\(x_2\\). Figure 8.1 illustrates the trajectory of orbits originating nearby \\(x_{min}\\), Figure 8.1: Dynamical system in a potential well: higher energy trajectory. For a trajectory originating near \\(x_{min}\\) with a higher total energy E2 &gt; E1 but less than the value at the local maximum \\(x_{max}\\), a similar behaviour occurs. We have oscillation about \\(x_{min}\\) between two new values \\(x_{3}\\) and \\(x_4\\). See Figure 8.2. Figure 8.2: Dynamical system in a potential well: higher energy trajectory. What if we introduce a damping term \\(c \\dern{x}{t}{2}\\) for \\(c&gt;0\\)? In this situation the dynamical system is now governed by the rules: \\[\\begin{align} &amp;\\der{x}{t} = y \\\\ &amp;\\der{y}{t} = - \\left(c y + \\pder{V}{x}\\right) \\tag{8.2} \\end{align}\\] Thus we have: \\[ \\dern{x}{t}{2} + c \\der{x}{t} + \\pder{V}{x} = 0.\\] Multiplying through by \\(\\der{x}{t}\\) and using the product rule gives: \\[ \\der{}{t} \\left(1/2 \\left(\\der{x}{t}\\right)^2 + \\v{V}(x) \\right) + c \\left( \\der{x}{t}\\right)^2 = 0.\\] Recognising the term in the first bracket as the energy at the point \\((x,y)\\), we have \\[ \\der{E}{t} = -c \\left( \\der{x}{t}\\right)^2.\\] Since \\(c\\) is positive, we conclude that the energy decreases with time. The system eventually settle to an equilibrium and so we will need energy to perturb the equilibrium. Let us now return to our key aim — understanding stability under large perturbations. The idea from the example we have considered is to make use of functions which behave like an energy function for the system. These are Lyapunov functions. What behaviour do we expect such a function to have? Consider a dynamical system \\[ \\der{\\v{x}}{t} = \\v{R}(\\v{x}) = (R_1(\\v{x}), R_2(\\v{x}), \\ldots, R_{n}(\\v{x}))\\] and an initial point \\(\\v{x} = (x_1, x_2, \\ldots, x_n)\\). Suppose we have a function \\(E(\\v{x})\\), a real-valued function which acts like an energy function for the system. Now observing that \\(E\\) is a function of \\(\\v{x}\\) which is an implicit function of \\(t\\), by the chain rule we have: \\[\\begin{align*} \\der{E}{t} &amp;= \\der{x_1}{t} \\pder{E}{x_1} + \\pder{x_2}{t} \\pder{E}{x_2} + \\ldots + \\der{x_n}{t} \\pder{E}{x_n} \\\\ &amp;= R_1(\\v{x}) \\pder{E}{x_1} + R_2(\\v{x}) \\pder{E}{x_2} + \\ldots + R_n(\\v{x}) \\pder{E}{x_n} \\end{align*}\\] Since \\(\\v{R}(x) = 0\\) when \\(x\\) is an equilibrium point, then \\(E\\) satisfies \\(\\der{E}{t} = 0\\) at equilibrium points. As \\(E\\) acts like an energy function, then it increases away from a stable equilibrium. That is as a trajectory moves towards a stable steady point, \\(E\\) decreases \\(\\left(\\der{E}{t} \\le 0\\right)\\). Using this key observation we can formally defined Lyapunov functions. Definition 8.1 (Lyapunov Functions) Consider a dynamical system \\[ \\der{\\v{x}}{t} = \\v{R}(\\v{x})\\] with an equilibrium at a point \\(\\v{x}_{e}\\). A function \\(E: \\R^{n} \\to \\R\\) is called a Lyapunov function for \\(x_{e}\\), if for some neighbourhood \\(N\\) of \\(\\v{x}_{e}\\), the following things hold: \\(E(\\v{x}_{e}) = 0\\) and \\(E(\\v{x}) &gt;0\\) for all \\(\\v{x} \\in N \\backslash \\{\\v{x}_{e}\\}\\); \\(\\der{E}{t}(\\v{x}) \\le 0\\) for all \\(\\v{x} \\in N\\). If, in place of \\(2\\) \\(E\\) satisfies the stronger condition 2’. \\(\\ \\der{E}{t} (\\v{x}) &lt; 0\\) for all \\(\\v{x} \\in N \\backslash \\{\\v{x}_{e}\\}\\), then it is called a strict Lyapunov function. 8.2 Equilibira and Lyapunov functions The following theorem characterises when an equilibrium point of a continuous dynamical system is stable using Lyapunov functions. Theorem 8.1 Let \\[ \\der{\\v{x}}{t} = \\v{R}(\\v{x})\\] be the governing rule of a continuous time dynamical system. Suppose that \\(\\v{x}_{e}\\) is an equilibrium point of the system. If there exists a Lyapunov function for \\(\\v{x}_{e}\\), then \\(\\v{x}_{e}\\) is stable. If there is a strict Lyapunov function for \\(\\v{x}_{e}\\) then \\(\\v{x}_{e}\\) is asymptotically stable. Note If \\(\\v{x}_{e}\\) is an equilibrium point of a dynamical system which has a strict Lyapunov function, \\(E\\) then any neighbourhood \\(N\\) on which \\(\\der{E}{t} (\\v{x}) &lt; 0\\) for all \\(\\v{x} \\in N\\) is contained in the basin of attraction of \\(\\v{x}_{e}\\). The derivative of a Lyapunov function \\(E = E(\\v{x})\\) is computed using the chain rule as follows: \\[\\begin{align*} \\der{E}{t} &amp;= \\der{\\v{x}}{t}\\cdot \\nabla E \\\\ &amp;= \\der{x_1}{t} \\pder{E}{x_1} + \\der{x_2}{t} \\pder{E}{x_2} + \\ldots + \\der{x_n}{t} \\pder{E}{x_n}\\\\ &amp; = \\v{R}(\\v{x}) \\cdot \\nabla E \\end{align*}\\] The following is a strengthening of theorem 8.1 where we have written \\(\\der{E}{t}\\) as \\(\\v{R}(\\v{x}) \\cdot \\nabla E\\). Note the stronger assumption that \\(E\\) is smooth — all derivatives exist and are continuous. This will mainly be a formality in this module as we mainly on deal with smooth functions in this module. Theorem 8.2 Let \\[ \\der{\\v{x}}{t} = \\v{R}(\\v{x})\\] be the governing rule of a continuous time dynamical system with \\(\\v{x}_{e}\\) an equilibrium point of the system. Suppose there is a function \\(E: \\R^{n} \\to \\R\\) such that \\(E\\) and its derivatives are continuous; there is a neighbourhood \\(N\\) of \\(\\v{x}_{e}\\) on which \\(E(\\v{x}) &gt; 0\\) for all \\(\\v{x} \\in N \\backslash \\{\\v{x}_{e}\\}\\) and \\(E(\\v{x}_e) = 0\\). If \\(\\v{R}\\cdot \\nabla E \\le 0\\) for all \\(\\v{x} \\in N\\), then \\(\\v{x}_e\\) is stable. If \\(\\v{R}\\cdot \\nabla E &lt; 0\\) for all \\(\\v{x} \\in N \\backslash \\{\\v{x}_{e}\\}\\), then \\(\\v{x}_e\\) is asymptotically stable. if \\(\\v{R}\\cdot \\nabla E &gt;0\\) for all \\(\\v{x} \\in N \\backslash \\{\\v{x}_{e}\\}\\), \\(\\v{x}_e\\) is unstable. Let us do some examples. Example 8.2 Consider the dynamical system governed by the rules: \\[\\begin{align*} &amp;\\der{x}{t} = y \\\\ &amp;\\der{y}{t} = -(cy + \\sin x) \\end{align*}\\] for \\(c \\ge 0\\). The trajectories of this dynamical system can model, for instance, a damped pendulum (when \\(c&gt;0\\)). For \\(c=0\\) the system neither gains nor looses energy. In this case, the energy in the system is given by: \\[ E = y^2/2 + V(x).\\] We can find \\(V(x)\\), \\(\\sin x\\) (the negative of the force). This gives \\(V(x) = -\\cos x + b\\) for some constant \\(b\\). Therefore \\[E = y^2/2 - \\cos x + b\\] for (In the specific instance of an undamped pendulum, it is natural assume that at angle \\(0\\) the potential energy of the particle is \\(0\\), and so \\(V(x) = -\\cos x + 1\\).) In order to have a physical analogy in mind, we take \\(b=1\\). The equilibria occur at \\(y = 0\\) and \\(x = n \\pi\\) for \\(n \\in \\Z\\). Note that \\(E(2n \\pi,0) = 0\\) for all \\(n \\in \\Z\\). Whilst for \\(x \\ne 2n\\pi\\), \\(\\cos(x)&lt;1\\) and so \\(E(x,y)&gt;0\\). By construction we know that \\(\\der{E}{t} = 0\\) since in the undamped context we have conservation of energy. (One can also verify this fact by direct computation.) It therefore follows that \\(E = y^2/2 - \\cos x + 1\\) satisfies the two conditions (Definition 8.1) required to be a Lyapunov function at \\((2n\\pi,0)\\) for a suitably chosen neighbourhood about \\((2n\\pi,0)\\) (e.g \\(N_{\\pi}((2n\\pi,0))\\)). Notice that \\(E\\) always satisfies condition 1 of Definition 8.1 at \\((2n\\pi,0)\\) regardless of the value of \\(c\\). To see whether \\(E\\) remains a Lyapunov function for these equilibria even when \\(c \\ne 0\\) we compute \\(\\der{E}{t}\\). \\[\\der{E}{t} = y \\der{y}{t} + \\sin x \\der{x}{t} = -cy^2 - y \\sin x + y \\sin x = -cy^2 &lt;0\\] Notice that \\(-cy^2 \\le 0\\) and is equal to \\(0\\) only when \\(y = 0\\). However, any neighbourhood of \\((2n\\pi,0)\\) contains arbitrarily many points where \\(y=0\\). Therefore \\(E(x,y)\\) is again a non-strict Lyapunov function for \\((2n\\pi, 0)\\) when \\(c&gt;0\\). However, we know, using the method of linearisation, that \\((2n\\pi, 0)\\) is asymptotically stable. Example 8.3 Consider the system of ODE’s \\[\\begin{align*} &amp; \\der{x}{t} = a x + y -x(x^2 +y^2) \\\\ &amp; \\der{y}{t} = -x + ay -y(x^2 + y^2) \\end{align*}\\] Defining \\(\\v{R}: \\R^2 \\to \\R^2\\) by \\[\\v{R}(x,y) = (a x + y -x(x^2 +y^2), -x + ay -y(x^2 +y^2))\\] we can write the ODE as \\(\\der{\\v{x}}{t} = \\v{R}(x,y)\\). Clearly \\((x,y) = (0,0)\\) is an equilibrium of the system. What about its stability? We apply Theorem 8.2. We need to find a (smooth) function \\(E: \\R^2 \\to \\R\\) such that \\(E((0,0)) = 0\\) and \\(E(x,y)&gt;0\\) for all \\((x,y) \\ne (0,0)\\) in a neighbourhood around \\((0,0)\\). Clearly \\(E(x,y) = 1/2(x^2 + y^2)\\) satisfies both conditions. Thus we can determine stability at \\((0,0)\\) by computing \\(\\v{R} \\cdot \\nabla E\\): \\[\\begin{align*} \\v{R} \\cdot \\nabla E &amp;= x (a x + y -x(x^2 +y^2)) + y (-x + ay -y(x^2 + y^2)) \\\\ &amp;= ax^2 - x^2 (x^2 + y^2) + ay^2 - y^2(x^2 + y^2) \\\\ &amp;= a(x^2 + y^2) - (x^2 + y^2)^2 \\\\ &amp;= (x^2 + y^2) (a - (x^2 + y^2)) \\end{align*}\\] For \\(a \\le 0\\) and all \\((x,y) \\ne (0,0)\\), \\(\\v{R} \\cdot \\nabla E &lt;0\\) and so \\((0,0)\\) is asymptotically stable. For \\((x^2 + y^2)&lt; a\\), \\(\\v{R} \\cdot \\nabla E &gt;0\\) and \\((0,0)\\) is unstable. 8.3 Periodic orbits and limit sets We have encountered periodicity in continuous time dynamical system (Example 8.1), as with discrete time dynamical systems we now investigate stability of period orbits and orbits more generally. For autonomous differential equations, bounded trajectories may converge to closed curves called periodic orbits/cycles. Now when we studied stability of orbits for discrete dynamical systems, we found the notion of a forward limit set helpful (Definition 6.2) in characterising the dynamics around the orbit. The definition that follows extends this definition to continuous time dynamical system, and essentially defines the forward limit set as the set of points towards which all initial orbits converge to as \\(t\\) gets larger and larger. Definition 8.2 (omega-limit set) Let \\[\\der{\\v{x}}{t} = \\v{R}(\\v{x})\\] be a differential equation and let \\(\\v{F}(t,\\v{x})\\) be its flow. A point \\(\\v{z} \\in \\R^{n}\\) is in the \\(\\omega\\)-limit set/forward limit set \\(\\omega(\\v{x}_0)\\) of the trajectory \\(\\v{F}(t,\\v{x}_0)\\) if there is a sequence of points “far out” along the orbit which converges to \\(\\v{z}\\). That is \\(\\v{z}\\in \\omega(\\v{x}_0)\\) if there is an increasing sequence \\((t_1 \\le t_2 \\le t_3 \\ldots )\\) with \\(\\lim_{n \\to \\infty} t_n = \\infty\\) and \\[\\lim_{n \\to \\infty} \\v{F}(t_n,\\v{x}_0) = \\v{z}.\\] A point \\(\\v{z} \\in \\R^{n}\\) is in the \\(\\alpha\\)-limit set/backward limit set \\(\\alpha(\\v{x}_0)\\) if there is a decreasing sequence \\((t_1 \\ge t_2 \\ge t_3 \\ge \\ldots)\\) with \\(\\lim_{n \\to \\infty} t_n = -\\infty\\) such that \\[ \\lim_{n\\to \\infty} \\v{F}(t_n, \\v{x}_0) = \\v{z}.\\] Note The \\(\\omega\\)-limit \\(\\omega(\\v{x}_0)\\) set of a point \\(\\v{x}_0\\) for the ODE \\(\\der{\\v{x}}{t} = \\v{R}(\\v{x})\\) is equal to the \\(\\alpha\\) limit set \\(\\alpha(\\v{x}_0)\\) of \\(\\v{x}_0\\) for the ODE \\(\\der{\\v{x}}{t} = -\\v{R}(\\v{x})\\). If \\(\\v{x}_{0}\\) is an equilibrium point, then \\(\\omega(x_0) = \\alpha(x_0)\\). Example 8.4 Let \\(r\\) and \\(\\theta\\) be polar coordinates (so \\(r&gt;0\\), \\(0 \\le \\theta \\le 2\\pi\\), \\(x,y = r \\cos \\theta, r \\sin \\theta\\)) in the plan and consider the differential equation below for \\(a,b &gt;0\\). \\[\\begin{align*} &amp;\\der{r}{t} = r(1-r) \\\\ &amp;\\der{\\theta}{t} = 8 \\end{align*}\\] There is an equilibrium when \\(r = 0\\) (i.e at the origin). Therefore \\(\\omega(0,0) = \\alpha(0,0) = \\{ (0,0)\\}\\). When \\(r=1\\) we have a periodic orbit/cycle. Solutions spiral in towards the periodic solution at \\(r =1\\). The point \\(p\\) on the unit circle is in the \\(\\omega\\)-limit set of the orbit depicted in Figure 8.3 since there are points \\(\\v{F}(t_1, \\v{x_0}), \\v{F}(t_2, \\v{x_0}), \\v{F}(t_3, \\v{x_0}) \\ldots\\) which converge to \\(p\\). The entire unit circle is the \\(\\omega\\)-limit set of the trajectory of any point in \\(\\R^{2} \\backslash\\{(0,0)\\}\\) (see Figure 8.3). Figure 8.3: omega-limit set Example 8.5 Consider the differential equation \\(\\der{x}{t} = x (a -x)\\) for \\(a&gt;0\\). Equilibria occur at the points \\(x=0, x= a\\). All trajectories with \\(x_{0} &gt;0\\) converge to the point \\(x =a\\) and so \\(a\\) is an asymptotically stable equilibrium and \\(\\omega(x_0) = \\{a\\}\\) for all \\(x_0 &gt;0\\). All trajectories with \\(x_0 &lt;0\\) diverge to -infinity. In this case \\(\\omega(x_0) = \\{\\}\\) when \\(x_0 &lt;0\\). Note The above examples are characteristic of \\(\\omega\\)-limit sets in one-dimension. In particular, for one-dimensional differential equations, \\(\\omega\\)-limit sets are either singletons sets or they are empty. Thus a trajectory either diverges to infinite or converges to a single equilibrium. This is precisely the content of the theorem that follows. Theorem 8.3 Let \\(\\der{x}{t} = R(x)\\) be a differential equation. All solutions to the differential equation are either monotonically increasing or monotonically decreasing as a function of \\(t\\). For \\(x_0 \\in \\R\\) if the orbit \\(\\v{F}(t, x_0)\\), \\(t \\ge 0\\), is bounded then \\(\\omega(x_0)\\) consists solely of an equilibrium. Example 8.6 Consider the solution curve shown in Figure 8.4 Figure 8.4: Non-monotonic curve The curve is monotonically decreasing \\(\\left(\\der{x}{t}&lt;0\\right)\\) until the turning point at which it begins to increase monotonically \\(\\left(\\der{x}{t}&gt;0\\right)\\). In particular, this curve cannot be a solution to any differential equation of the form \\(\\der{x}{t} = R(x)\\). What about the solution curve in Figure 8.5 Figure 8.5: Monotonic curve For all initial conditions below the equilibrium value at \\(x_1\\), the solution curve increases monotonically to the equilibrium value \\(x_1\\). The \\(\\omega\\)-limit set is just the singleton consisting of the equilibrium value. We have already seen that 2D systems can have more complicated behaviour: there are periodic orbits/cycles which can attract solutions and are themselves \\(\\omega\\)-limit sets. 8.4 Problem Sheet 8 For week 9. Question 8.1 Consider the nonlinear system \\[\\begin{align*} &amp;\\der{x}{t} = ax + y - x \\sqrt{x^2 +y^2} \\\\ &amp;\\der{y}{t} = -x + ay - y \\sqrt{x^2 + y^2} \\end{align*}\\] where \\(a\\) is a real parameter. Show that \\((x,y) = (0,0)\\) is the only equilibrium point. Investigate the linear stability of this equilibrium and how it depends on the parameter \\(a\\). Show Solution 8.1 Solution 8.1 We solve \\[\\begin{align} 0 &amp;= ax + y - x \\sqrt{x^2 +y^2} \\tag{8.3} \\\\ 0 &amp;= -x + ay - y \\sqrt{x^2 + y^2} \\tag{8.4}. \\end{align}\\] Multiplying Equation (8.3) by \\(y\\) and subtracting \\(x\\) times Equation (8.4) from it, gives \\(x^2 + y^2 = 0\\). The only solution is when \\((x,y) = (0,0)\\). Set \\[\\v{R} = (R_{x}, R_{y}) = \\left(ax + y - x \\sqrt{x^2 +y^2}, -x + ay - y \\sqrt{x^2 + y^2} \\right). \\] To investigate the stability of \\((0,0)\\) we compute \\(\\jacobr(0,0)\\) \\[ \\jacobr(x,y) = \\begin{pmatrix} a - \\sqrt{x^2 + y^2} - \\frac{x^2}{\\sqrt{x^2 + y^2}} &amp; 1 - \\frac{xy}{\\sqrt{x^2 + y^2}} \\\\ -1 - \\frac{xy}{\\sqrt{x^2 + y^2}} &amp; a - \\sqrt{x^2 + y^2} - \\frac{y^2}{\\sqrt{x^2 + y^2}}. \\end{pmatrix} \\] Notice that at \\((0,0)\\), \\(\\jacobr(x,y)\\) is undefined. What we can do is to consider the limiting value of \\(\\jacobr(x,y)\\) as \\((x,y) \\to (0,0)\\) (assuming it exists). Observe that \\[\\lim_{(x,y) \\to (0,0)} \\frac{x^2}{\\sqrt{x^2 + y^2}} \\le \\lim_{(x,y) \\to (0,0)} \\frac{x^2+y^2}{\\sqrt{x^2 + y^2}} = 0.\\] Also \\[ \\lim_{(x,y) \\to (0,0)} \\left|\\frac{xy}{\\sqrt{x^2 + y^2}}\\right| \\le \\lim_{(x,y) \\to (0,0)} \\frac{|x|^2+ |y|^2}{\\sqrt{x^2 + y^2}} = 0. \\] Since \\(|xy| \\le \\max\\{|x|^2, |y|^2\\}\\). Therefore \\[ \\lim_{(x,y) \\to (0,0)} \\jacobr(x,y) = \\begin{pmatrix} a &amp; 1 \\\\ -1 &amp; a . \\end{pmatrix} \\] The eigenvalues of this matrix are the roots of \\((\\lambda - a)^2 +1\\) which are \\(\\lambda_{\\pm} = a \\pm i\\). The real part of the eigenvalues is \\(a\\). Therefore \\((0,0)\\) is asymptotically stable for \\(a&lt;0\\) and unstable for \\(a&gt;0\\). Question 8.2 The Lorenz equations are given by \\[\\begin{align} &amp;\\der{x}{t} = \\sigma(y-x) \\tag{8.5} \\\\ &amp;\\der{y}{t} = rx -y -xz \\tag{8.6} \\\\ &amp;\\der{z}{t} = -bz + xy \\tag{8.7} \\end{align}\\] For positive real parameters \\(\\sigma, r\\) and \\(b\\). Determine the equilibria of the Lorenz equations. Assume that \\(b =1\\). Sketch the bifurcation diagram by plotting the \\(x\\)-value of each equilibrium as a function of \\(r\\). Investigate how the stability of the equilibrium \\(x =y = z = 0\\) depends on \\(r\\) when \\(\\sigma\\) and \\(b\\) are fixed. Show that for the Lorenz equations \\[ \\nabla \\cdot \\v{R} = \\pder{R_{x}}{x} + \\pder{R_{y}}{y} + \\pder{R_{z}}{z} &lt; 0. \\] [Note that dynamical systems with this property are called dissipative.] Show Solution 8.2 Solution 8.2 From Equation (8.5) we find that \\(y = x\\). Using this in Equation (8.6) we find that \\(z = r-1\\), when \\(x \\ne 0\\) otherwise \\(x=y=z=0\\). From Equation (8.7) we find that, if \\(x \\ne 0\\), then \\(x = \\pm \\sqrt{b(r-1)} = y\\). Therefore the equilibria are \\[(0,0,0), \\quad \\left(\\sqrt{b(r-1)},\\sqrt{b(r-1)}, (r-1)\\right),\\] and \\[\\left(-\\sqrt{b(r-1)},-\\sqrt{b(r-1)}, (r-1)\\right).\\] Figure 8.6 shows the \\(x\\)-values of the equilibria plotted as a function of \\(r\\) where \\(b\\) is chosen to be \\(1\\). Figure 8.6: Bifurcation diagram We compute \\(\\jacobr(0,0,0)\\). We have \\[ \\jacobr(0,0,0) = \\begin{pmatrix} -\\sigma &amp; \\sigma &amp; 0 \\\\ r &amp; -1 &amp; 0 \\\\ 0 &amp; 0 &amp; -b \\end{pmatrix}. \\] The eigenvalues are roots of \\((\\lambda+b)[(\\lambda+ \\sigma)(\\lambda+1) - r\\sigma]\\). This has solutions \\(\\lambda_1 = -b\\) and \\(\\lambda_{\\pm} = \\frac{-(\\sigma + 1) \\pm \\sqrt{(\\sigma-1)^2 + 4\\sigma r}}{2}\\). Notice that since \\(r,\\sigma&gt;0\\) then \\(\\sqrt{(\\sigma-1)^2 + 4\\sigma r}\\) is always real. This means that \\(\\lambda_{-} = \\frac{-(\\sigma + 1) - \\sqrt{(\\sigma-1)^2 + 4\\sigma r}}{2}\\) is always negative. Let us consider \\(\\lambda_{+} = \\frac{-(\\sigma + 1) + \\sqrt{(\\sigma-1)^2 + 4\\sigma r}}{2}\\). The equality \\[ \\sqrt{(\\sigma-1)^2 + 4\\sigma r} = \\sqrt{(\\sigma +1)^2 - 4\\sigma(1-r)}\\] holds. When \\(r&lt;1\\), \\(4\\sigma (1-r) &gt;0\\) and so \\(\\sqrt{(\\sigma +1)^2 - 4\\sigma(1-r)}&lt; \\sigma+1\\) and \\(\\lambda _{+}&lt;0\\). When \\(r &gt;1\\), \\(\\lambda_{+}&gt;0\\). Therefore, for \\(r&lt;1\\) the equilibrium \\((0,0,0)\\) is stable since all three eigenvalues have negative real part, while for \\(r&gt;1\\), the equilibrium \\((0,0,0)\\) is unstable, since the real part of one of its eigenvalues is positive. We have \\[ \\nabla \\cdot \\v{R} = - \\sigma -1-b = -(\\sigma +1 + b)&lt;0 \\] since \\(\\sigma,b&gt;0\\). References "],["limit-sets-2d.html", "Chapter 9 Limit sets in 2-dimensions 9.1 Limit cycles 9.2 Planar dynamics of continuous time dynamical systems 9.3 Problem Sheet 9", " Chapter 9 Limit sets in 2-dimensions Covers Chapter 8 Section 8.1 and 8.2 and Sections 9.1 and 9.2 of Chapter 9 (Alligood, Sauer, and Yorke 2000). 9.1 Limit cycles Let us formally define a cycle/periodic orbit of a continuous time dynamical system. Definition 9.1 Consider the differential equation \\[ \\der{\\v{x}}{t} = \\v{R}(\\v{x})\\] with flow \\(\\v{F}(t,\\v{x})\\). Let \\(\\v{x}_{0}\\) be a point and suppose that \\(\\v{x}_{0}\\) is not an equilibrium point. If there is a \\(T&gt;0\\) such that \\[\\begin{equation} \\v{F}(t+T, \\v{x}_{0}) = \\v{F}(t, \\v{x}_{0}) \\tag{9.1} \\end{equation}\\] for all \\(t\\), then the orbit \\(\\v{F}(t, \\v{x}_{0})\\) is called a periodic orbit/cycle. The smallest such \\(T\\) such that Equation (9.1) holds is called the period of the orbit. Note A period orbit/cycle is a simple closed curve in \\(\\R^{n}\\). Simple means that the curve does not repeat points apart from the end points (this follows from the minimality of the period) and closed means that the curve ends where it begins (a consequence of Equation (9.1)). As with discrete time dynamical systems, periodic orbits of continuous time dynamical system can also be attracting. Definition 9.2 A limit cycle is a periodic orbit which attracts nearby solutions. Example 9.1 Consider the differential equation \\(\\der{\\v{x}}{t} = \\v{R}(x)\\) given by \\[\\begin{align} \\der{x}{t} &amp;= ax -by - x \\sqrt{x^2 + y^2} \\\\ \\der{y}{t} &amp;= bx +ay -y \\sqrt{x^2+y^2} \\tag{9.2} \\end{align}\\] The point \\((x,y) = (0,0)\\) is an equilibrium point. Consider the function \\(E: \\R^2 \\to \\R\\) given by \\(E(x,y) = (x^2 + y^2)/2\\). Clearly \\(E(0,0) = 0\\) and \\(E\\) is always strictly bigger than zero at non-zero coordinates. Computing \\(\\v{R} \\cdot \\nabla E\\) we have: \\[\\v{R} \\cdot \\nabla E = (x^2 +y^2)\\left(a- \\sqrt{x^2 + y^2}\\right).\\] If \\(a\\le 0\\) then \\(\\v{R} \\cdot \\nabla E\\) is strictly less than \\(0\\) whenever \\((x,y) \\in \\R^2\\) does not lie on the origin and \\((0,0)\\) is a globally asymptotically stable equilibrium. If \\(a&gt;0\\), then there is a neighbourhood of \\((0,0)\\) on which \\(a - \\sqrt{x^2 + y^2} &gt;0\\) and so \\(\\v{R} \\cdot \\nabla E &gt;0\\) at all points \\((x,y) \\ne (0,0)\\) in some neighbourhood of \\(a\\), we conclude that \\((0,0)\\) is an unstable equilibrium. We can confirm this by computing the eigenvalues of the Jacobian of \\(\\v{R}\\) at \\((0,0)\\). \\[ \\jacobr(0,0) = \\begin{pmatrix} a - \\left( \\sqrt{x^2 + y^2} + \\frac{x^2}{\\sqrt{x^2 + y^2}} \\right) &amp; -b - \\frac{xy}{\\sqrt{x^2 + y^2}} \\\\ b - \\frac{xy}{\\sqrt{x^2 + y^2}} &amp; a - \\left( \\sqrt{x^2 + y^2} + \\frac{y^2}{\\sqrt{x^2 +y^2}} \\right) \\end{pmatrix} .\\] Now the terms with denominator equal to \\(\\sqrt{x^2 + y^2}\\) cause problems. To get around this, observe that \\[\\lim_{(x,y) \\to (0,0)} \\frac{x^2}{\\sqrt{x^2 + y^2}} = \\lim_{(x,y) \\to (0,0)} \\frac{y^2}{\\sqrt{x^2 + y^2}} = \\lim_{(x,y) \\to (0,0)}= \\frac{xy}{\\sqrt{x^2 + y^2}} = 0.\\] This can be seen by noting that \\(0 \\le \\frac{x^2}{\\sqrt{x^2 + y^2}} \\le \\sqrt{x^2 + y^2}\\) and \\(\\lim_{(x,y) \\to (0,0)} \\lim_{(x,y) \\to (0,0)} \\sqrt{x^2 + y^2} = 0\\). Therefore \\[ \\jacobr(0,0) = \\begin{pmatrix} a &amp; -b \\\\ b &amp; a \\end{pmatrix} .\\] The eigenvalues of this matrix are \\(a \\pm i b\\). Therefore Theorem 7.1 now implies that \\((0,0)\\) is stable for \\(a &lt; 0\\) and unstable for \\(a &gt;0\\). We can verify this by solving the differential equation. While it looks a little imposing in Cartesian coordinates, it becomes rather tame in polar coordinates. Recall that for polar coordinates we take \\(x = r \\cos \\theta\\) and \\(y= r \\sin \\theta\\) where, plotting the point \\((x,y)\\) in the plane, \\(\\theta\\) is the angle, moving clockwise, from the positive real axis to the line from the origin to the point \\((x,y)\\). Thus \\(r&gt;0\\) and \\(0 \\le \\theta \\le 2 \\pi\\). Notice that \\(r^2 = x^2 + y^2\\) and \\(\\tan \\theta = y/x\\). We therefore compute \\(\\der{r}{t}\\) and \\(\\der{\\theta}{t}\\) as follows. \\[\\begin{align*} 2r\\der{r}{t} &amp;= 2\\left(x \\der{x}{t} + y \\der{y}{t}\\right) = 2\\left(a(x^2 + y^2) - (x^2 + y^2)\\sqrt{x^2 + y^2}\\right)\\\\ \\sec^2 \\theta \\der{\\theta}{t} &amp;= \\frac{x \\der{y}{t} - y \\der{x}{t}}{x^2} = \\frac{b(x^2 + y^2)}{x^2} \\end{align*}\\] Substituting \\(x = r \\cos \\theta\\), \\(y= r \\sin \\theta\\) and \\(r^2 = x^2 + y^2\\) we get: \\[\\begin{align*} \\der{r}{t} &amp;= r (a - r) \\\\ \\der{\\theta}{t} &amp;= b \\end{align*}\\] The differential equation for \\(r\\) can be solved by separating the variables and using partial fractions. With some algebraic manipulations we get: \\[ r = \\frac{a r_0}{r_0 + (a-r_0)e^{-at}}.\\] The differential equation for \\(\\theta\\) gives \\(\\theta = b t + \\theta_0\\). Thus, solutions are given by: \\[\\begin{align*} x(t) &amp;= r(t) \\cos(bt + \\theta_0) \\\\ y(t) &amp;= r(t) \\sin(bt + \\theta_0) \\end{align*}\\] In order to understand the behaviour of the system as \\(t\\) grows towards infinity, \\(r\\) is the crucial variable (since \\(\\theta\\) determines the angle in the plane). If \\(a&lt; 0\\) then as \\(t\\) tends to positive infinity, \\(e^{-at}\\) tends to positive infinity (\\(a\\) is negative) and \\(r\\) tends to \\(0\\): all initial conditions tend to the stable equilibrium at \\((0,0)\\). See figure 9.1. Figure 9.1: Origin is stable equilibrium for a&lt;0 If \\(a&gt;0\\), then \\(\\lim_{t \\to \\infty} e^{-at}\\) is \\(0\\) and so \\(\\lim_{t \\to \\infty} r(t) = a\\). All solutions tend to the limit cycle — the circle of radius \\(a\\) centred at the origin (see Figure 9.2) Figure 9.2: Limit cycle for a&gt;0 Example 9.1 shows a periodic orbit which is stable i.e attracting. We determined this by solving the differential equation. But how might one determine the stability of a general cycle? We use the same strategy we successfully applied in previous contexts (see Example 7.2 and Subsections 2.1 and 2.3.1). We linearise by considering a small perturbation from the limit cycle. This gives rise to a system of 1st order linear ODES. Alternatively, if we are able to compute the flow of the ODE, then we can use the stability of fixed point of the flow. Let us consider Example 9.1. We computed the flow of the ODE: \\[ \\v{F}(t,r, \\theta) = \\left(\\frac{ ar}{ r + (a-r) e^{(-at)}}, bt + \\theta\\right).\\] To examine the stability of periodic solutions with period \\(t = 2\\pi\\), say. We can examine the “\\(r\\)-part” of the time-2\\(\\pi\\) map of the flow: \\[f(r) = \\frac{ ar}{ r + (a-r) e^{(-2\\pi a)}}\\] noting that \\(r= a\\) is a fixed point of this map since \\(r=a\\) corresponds to the initial condition \\((r(0), \\theta(0)) = (a, \\theta_0)\\) which is on the limit cycle. we compute \\(\\left| \\der{f}{r}(a)\\right|\\) to investigate the stability of the fixed point \\(a\\) of \\(f\\). \\[\\begin{align*} \\der{f}{r} &amp;= \\frac{a ( r + (a-r)e^{-2\\pi a}) - ar(1- e^{-2\\pi a})}{(r + (a-r)e^{-2\\pi a})^2 } \\\\ &amp;= \\frac{ a^2 e^{-2 \\pi a} }{(r + (a-r)e^{-2\\pi a})^2} \\end{align*}\\] Therefore \\(\\left|\\der{f}{r} (a) \\right | = e^{-2\\pi a}\\). Now \\(e^{-2\\pi a} &gt; 1\\) when \\(a \\le 0\\) otherwise \\(e^{-2\\pi a} &lt;1\\) in which case \\(a &gt;0\\). Therefore the periodic orbit is unstable for \\(a\\le 0\\) and stable for \\(a&gt;0\\). 9.2 Planar dynamics of continuous time dynamical systems For 1 dimensional ODE’s we were able to complete characterise \\(\\omega\\)-limit sets — they are either the \\(\\emptyset\\) (in which case the corresponding trajectory diverges to \\(0\\)) or they consist of a single equilibrium point (see Theorem 8.3). Can we similarly characterise \\(\\omega\\)-limit sets for 2 dimensional ODE’s? The answer is yes. Note The \\(\\omega\\)-limit set of a bounded trajectory \\(\\v{F}(t, \\v{v}_0)\\) in 2D is of one of the following forms: an equilibrium; a limit cycle; for all \\(\\v{u} \\in \\omega(\\v{v}_{0})\\), \\(\\omega(\\v{u})\\) is an equilibrium. Said differently, the chaotic phenomenon that we encountered in discrete time dynamical systems (see Chapter 6) does not occur in 2D continuous time dynamical systems. Once we get to \\(3\\)-dimensions, chaotic behaviour emerges. Example 9.2 (The Lorenz equations) Consider the Lorenz equations: \\[\\begin{align} \\der{x}{t} &amp;= -\\sigma x + \\sigma y \\tag{9.3}\\\\ \\der{y}{t} &amp;= - x z + rx -y \\tag{9.4}\\\\ \\der{z}{t} &amp;= xy - bz \\tag{9.5} \\end{align}\\] for positive real parameters \\(\\sigma, r\\) and \\(b\\). The Lorenz equations were derived to model convection in a fluid heated from below. We assume there are two parallel plates \\(T_{l}\\) and \\(T_{u}\\) with some fluid between the two plates which is at rest at time \\(t = 0\\). (See Figure 9.3) Figure 9.3: Two plates with fluid heated from below If the difference \\(T_{l} - T_{u}\\) in temperature between the bottom and top plates is small, then heat is transported upwards via thermal conduction. If \\(T_{l} - T_{u}\\) exceeds a critical value, an instability arises and the fluid itself moves in convection rolls transporting heat upwards. The Lorenz equations describe how the warm fluid below rises and the cool fluid above sinks setting up a clockwise or counter-clockwise current. Lorenz showed that the equations display chaotic (sensitivity to initial conditions &amp; non-periodicity) solutions and for certain values of \\(\\sigma\\), \\(r\\) and \\(b\\) chaotic attractors emerge. The Lorenz equations roughly say that: \\(x\\) is proportional to the circulatory fluid flow velocity; \\(y\\) is proportional to the temperature difference between ascending and descending fluid elements; \\(z\\) is proportional to the distortion of the vertical temperature profile from its equilibrium; the width of the flow rolls is proportional to the parameter \\(b\\); \\(\\sigma\\) and \\(r\\) are dimensionless numbers describing properties of the fluid; \\(\\sigma\\) is the Prandtl number and \\(r\\) is the Rayleigh number. Lorenz found that for parameter values \\(\\sigma = 10, b= 8.3\\) and \\(r\\) just greater than \\(24.74\\) chaotic behaviour emerges. 9.2.1 Properties of the Lorenz dynamical system The Lorenz system is dissipative This roughly means that the systems is volume decreasing — the volume of a given phase space decreases with time. Definition 9.3 A dynamical system \\[ \\der{\\v{x}}{t} = \\v{R}(\\v{x}) = (R_{1}(\\v{x}), R_2(\\v{x}), \\ldots, R_{n}(\\v{x}))\\] is called dissipative if \\[\\nabla \\cdot \\v{R} = \\pder{R_1}{x_1} + \\pder{R_2}{x_2} + \\ldots + \\pder{R_n}{x_n} &lt;0\\] Dissipative systems are examples of thermodynamically open systems. That is a system which is far from thermodynamic equilibrium and which can exchange energy and matter with its environment. Figure 9.4: A thermodynamically open system For the Lorenz equations: \\[ \\nabla \\cdot \\v{R} = \\pder{}{x}(-\\sigma x + \\sigma y) + \\pder{}{y}(-xz + rx -y) + \\pder{}{z}(xy -bz) = -\\sigma -1 -b &lt;0\\] Equilibria of the Lorenz system. suppose \\(\\sigma\\) and \\(b\\) are fixed at \\(10\\) and \\(8/3\\) respectively. The point \\((x,y,z) = (0,0,0)\\) is an equilibrium for all \\(r\\). When \\(r&lt;1\\), \\((0,0,0)\\) is a stable attractor and for \\(r \\ge 1\\) \\((0,0,0)\\) is unstable (compute the Jacobian at \\((0,0,0)\\) for instance). The orbit with initial conditions \\((x,y,z) = (0,0,0)\\) at \\(t=0\\) corresponds to the fluid at rest with a linear temperature profile — hot at the bottom and cool at the top. For \\(r\\ge 1\\), two new equilibria exist: \\[\\begin{align*} C_{+} &amp;= (x_{+}, y_{+}, z_{+}) = \\left(\\sqrt{b(r-1)},\\sqrt{b(r-1)}, r-1\\right) \\\\ C_{-} &amp;= (x_{-}, y_{-}, z_{-}) = \\left(-\\sqrt{b(r-1)},-\\sqrt{b(r-1)}, r-1\\right) \\\\ \\end{align*}\\] these two equilibria \\(C_{\\pm}\\) correspond to convective rolls; they branch off from the origin at \\(r=1\\) and move away as \\(r\\) increases. At \\(r=1\\), \\(C_{\\pm}\\) are stable and they remain stable for \\(r&lt; r_u \\simeq 24.74\\). For \\(r&gt; r_u\\) all three equilibria are unstable and chaotic behaviour emerges. Below (Fig 9.5) are some images of the chaotic attractor for fixed \\(r=28\\). Figure 9.5: Rotated views of the Lorenz chaotic attractor r=28, sigma=10, b=8/3 9.3 Problem Sheet 9 For week 10. Question 9.1 Consider the nonlinear system \\[\\begin{align*} &amp;\\der{x}{t} = ax + y - x \\sqrt{x^2 +y^2} \\\\ &amp;\\der{y}{t} = -x + ay - y \\sqrt{x^2 + y^2} \\end{align*}\\] where \\(a\\) is a real parameter. In Tutorial 8 we showed that \\((0,0)\\) is the only equilibrium point of the system and that it is asymptotically stable when \\(a&lt;0\\) and unstable when \\(a&gt;0\\). Use the Lyapunov function \\[ E(x,y) = \\frac{x^2 + y^2}{2}\\] to show that the origin is a stable equilibrium for \\(a \\le 0\\) and unstable for \\(a&gt;0\\). For which values of \\(a\\) is the origin asymptotically stable? Show that the system can be written using polar coordinates as: \\[\\begin{align} \\der{r}{t} &amp;= (a-r)r, \\\\ \\der{\\theta}{t}&amp;= -1. \\end{align}\\] Verify that the solution of the transformed system with initial conditions \\(r(0) = r_0\\) and \\(\\theta(0)= \\theta_0\\) is given by: \\[\\begin{align*} r &amp;= \\frac{ar_0}{r_0 + (a-r_0)e^{-at}}, \\\\ \\theta &amp;= -t + \\theta_0. \\end{align*}\\] Show, provided \\(a&gt;0\\), that all solutions tend to a limit cycle as \\(t \\to \\infty\\). Use the solution in c. to show that for all \\(a&gt;0\\) one can define a Poincaré map \\(P: \\R^{+} \\to \\R^{+}\\) by \\[ r_{n} = P(r_{n-1}) = \\frac{ar}{r + (a-r)e^{-2\\pi a}}. \\] [Note a Poincaré map is similar to a time-T map, however instead of orbits at fixed time intervals, we consider the intersection point of the orbit with an \\((n-1)\\)-dimensional disk transverse to the orbit. In two dimensions, we’re looking at a line transverse to the orbit. See Section 11.7 of (Alligood, Sauer, and Yorke 2000) for more detail.] Using the Poincaré map, or otherwise, show that the limit cycle is stable for \\(a&gt;0\\). Show Solution 9.1 Solution 9.1 Clearly \\(E(0,0) = 0\\) and \\(E(x,y)&gt;0\\) for all \\((x,y) \\ne (0,0)\\). The function \\(E\\) is therefore a Lyapunov function if \\(\\der{E}{t}(x,y)&lt;0\\) in a neighbourhood of the origin. We have: \\[\\begin{align*} \\der{E}{t} &amp;= \\nabla E \\cdot \\v{R} = x \\der{x}{t} + y \\der{y}{t} \\\\ &amp;= ax^2 + xy - x^2 \\sqrt{x^2 + y^2} -xy + ay^2 - y^2 \\sqrt{x^2 + y^2}\\\\ &amp;= a(x^2 +y^2) - (x^2 + y^2)\\sqrt{x^2 + y^2}\\\\ &amp;= (x^2+y^2)\\left(a - \\sqrt{x^2 + y^2}\\right) \\end{align*}\\] If \\(a \\le 0\\) then clearly \\(\\der{E}{t}&lt;0\\). If \\(a&gt;0\\), then for \\(x,y &lt; \\frac{\\sqrt{a}}{2}\\) \\(x^2 + y^2 &lt;a\\). In particular \\(\\der{E}{t}&gt;0\\) at all points in \\(N_{\\frac{\\sqrt{a}}{2}}((0,0))\\). Thus we see that \\((0,0)\\) is stable, and even asymptotically stable, for \\(a \\le 0\\) and unstable for \\(a&gt;0\\). For polar coordinates we have: \\[\\begin{align} x,y &amp;= r \\cos \\theta, r \\sin \\theta \\tag{9.6} \\\\ r^2 &amp;= x^2 + y^2 \\tag{9.7} \\\\ \\tan(\\theta) &amp;= \\frac{y}{x}. \\tag{9.8} \\end{align}\\] Differentiating (9.7), we have \\[\\begin{align} 2r \\der{r}{t} &amp;= 2x \\der{x}{t} + 2y \\der{y}{t} \\\\ &amp;= 2(ax^2 + xy -x^2 r - xy + ay^2 -y^2 r)\\\\ &amp;= 2(a r^2 -r^3) \\\\ &amp;= 2r^2(a-r). \\end{align}\\] Therefore \\(\\der{r}{t} = r(a-r)\\) as required. Differentiating (9.8), we have: \\[\\begin{align} \\frac{1}{\\cos^2 \\theta} \\der{\\theta}{t} &amp;= \\frac{x \\der{y}{t} - y \\der{x}{t}}{x^2} \\\\ &amp;= \\frac{-x^2 +axy - xyr - axy - y^2 -+xy r + }{r^2 \\cos^2 \\theta}\\\\ &amp;= \\frac{-r^2}{r^2 \\cos^2 \\theta} \\\\ &amp;= \\frac{-1}{\\cos^2 \\theta}. \\end{align}\\] Therefore \\(\\der{\\theta}{t} = -1\\) as required. This is a verify question so we need only check that the solution give is in fact a solution. Clearly \\(r(0) = r_0\\) and \\(\\theta(0) = 0\\). We now compute \\[\\begin{align*} \\der{r}{t} &amp;= \\frac{ar_0}{ r_0 + (a-r_0)e^{-at}} \\cdot \\frac{-a(a-r_0)e^{-at}}{r_0 + (a-r_0)e^{-at}} \\\\ &amp;= r \\cdot \\left(\\frac{-a(a-r_0)e^{-at} + ar_0 - ar_0}{r_0 + (a-r_0)e^{-at}}\\right) \\\\ &amp;= r \\cdot \\left(\\frac{-a\\left(( a-r_0)e^{-at} + r_0\\right)}{r_0 + (a-r_0)e^{-at}} + \\frac{ar_0}{r_0 + (a-r_0)e^{-at}} \\right) \\\\ &amp;= r (a-r), \\text{ and } \\\\ \\der{\\theta}{t} &amp;= -1. \\end{align*}\\] as required. As \\(t\\) tends to infinity, \\(r\\) tends to \\(a\\). Since \\(r&gt;0\\), this limit exists provided that \\(a&gt;0\\). Since \\(\\theta_{t} = -t\\) this solution corresponds to the circle of radius \\(a\\) about the origin — a limit cycle. Let us consider intersections with the positive \\(x\\)-axis. These occur when \\(\\theta(t) = -2n\\pi\\) for \\(n \\in \\Z\\). Supposing that \\(r_{n-1}\\) is the previous intersection. Then next value of \\(r_n\\) is found by taking \\(r_0 = r_{n-1}\\) as our initial point and \\(t = 2 \\pi\\) (we need to orbit \\(2\\pi\\) from the previous intersection before we make the next intersection since \\(\\theta = - t\\)). In particular, in this instance, the Poincaré map coincides with the time-\\(2\\pi\\) map. The result is: \\[ r_{n} = \\frac{ar_{n-1}}{ r_{n-1} + (a-r_{n-1})e^{-2\\pi a}}. \\] Notice that \\(r=a\\) is a fixed point of \\(P\\). To investigate stability of the limit cycle \\(a = r\\), we compute the derivative of \\(P\\) with respect to \\(r\\): \\[\\begin{align*} \\der{P}{r} &amp;=\\frac{a(r+ (a-r)e^{-2\\pi a}) - ar(1 - e^{-2\\pi a})}{(r + (a-r)e^{-2\\pi a})^2} \\\\ &amp;= \\frac{a^2}{{(r + (a-r)e^{-2\\pi a})^2}} \\end{align*}\\] Hence, \\[ \\left|\\der{P}{r}(a)\\right| = e^{-2\\pi a} &lt; 1 \\] for \\(a&gt;0\\). Therefore the limit cycle \\(r=a\\) is stable for \\(a&gt;0\\). Question 9.2 Consider the Lorenz equations: \\[\\begin{align} &amp;\\der{x}{t} = \\sigma(y-x) \\tag{9.9} \\\\ &amp;\\der{y}{t} = rx -y -xz \\tag{9.10} \\\\ &amp;\\der{z}{t} = -bz + xy \\tag{9.11} \\end{align}\\] For positive real parameters \\(\\sigma, r\\) and \\(b\\). Use the Lyapunov function \\[ E(x,y,z) = \\frac{x^2 + \\sigma y^2 + \\sigma z^2}{2} \\] to show that the equilibrium \\(x=y=z=0\\) is stable for \\(r\\le 1\\). Show Solution 9.2 Solution 9.2 Notice that \\(E(x,y,z)&gt;0\\) for all \\((x,y,z) \\in \\R^3 \\backslash\\{(0,0,0)\\}\\). We now show that \\(\\der{E}{t} \\le 0\\) when \\(r\\le 1\\) in order to show that \\(x = y = z = 0\\) is a stable point. We have: \\[\\begin{align*} \\der{E}{t} = \\nabla E \\cdot \\v{R} = \\sigma x(y-x) + \\sigma y(rx - y - xz) - \\sigma b z^2 + \\sigma xyz \\\\ =\\sigma xy - \\sigma x^2 + \\sigma xyr - \\sigma y^2 - b \\sigma z^2 \\\\ = \\sigma xy (1+r) - \\sigma (x^2 + y^2 + bz^2) \\\\ = -\\sigma ( x^2 + y^2 - xy(1+r) + bz^2) \\end{align*}\\] If \\(xy \\le 0\\) then \\(-xy (1+r) \\ge 0\\) and \\((x^2 + y^2 - xy(1+r)) \\ge 0\\) with equality only if \\(x = y =0\\). This means, for \\(xy \\le 0\\), \\(\\der{E}{t} \\le 0\\). If \\(xy \\ge 0\\), then for \\(r \\le 1\\), \\(xy(1+r) \\le 2xy\\). In this case \\(x^2 + y^2 - xy(1+r) \\ge x^2 + y^2 - 2xy = (x-y)^2 \\ge 0\\). Therefore \\(\\der{E}{t} \\le 0\\) for \\(r \\le 1\\). This means that for \\(r \\le 1\\), the point \\((0,0,0)\\) is stable. If \\(r&lt;1\\) then one can show, using the same Lyapunov function \\(E\\), that \\((0,0,0)\\) is asymptotically stable. References "],["Loren-chaos-and-bifurcation.html", "Chapter 10 Lorenz chaos and bifurcation 10.1 Properties of the Lorenz dynamical system II 10.2 Bifurcation 10.3 More types of Bifurcations 10.4 Problem Sheet 10", " Chapter 10 Lorenz chaos and bifurcation Covers Chapter 11 Sections 11.1 and 11.2 of (Alligood, Sauer, and Yorke 2000). 10.1 Properties of the Lorenz dynamical system II We continue our study of the Lorenz dynamical system. Recall that this dynamical system is governed by the Lorenz equations: \\[\\begin{align} \\der{x}{t} &amp;= -\\sigma x + \\sigma y \\tag{10.1}\\\\ \\der{y}{t} &amp;= - x z + rx -y \\tag{10.2}\\\\ \\der{z}{t} &amp;= xy - bz. \\tag{10.3} \\end{align}\\] We have seen that the system is dissipative and characterises the behaviour of some of its equilibria. The next observation we make about the system is on a so-called trapping region. Trapping region In the Lorenz dynamical system all orbits eventually enter and never leave a neighbourhood (sphere) around the origin. Let us give an argument that sketches out how this can occur. Define \\(\\v{E}(x,yz) = x^2/2 + y^2/2 + ( z - (\\sigma + r))^2/2\\) (the \\(-(\\sigma +r)\\) is added in so we have nice cancellations). Notice that \\(\\v{E}\\) is \\(0\\) at the point \\((0,0 (\\sigma+r))\\) and strictly greater than \\(0\\) otherwise. We apply a similar strategy as with Lyapunov functions. We compute \\(\\der{\\v{E}}{t}\\). \\[\\begin{align*} \\der{\\v{E}}{t} &amp;= x \\der{x}{t} + y \\der{y}{t} + \\left(z-(\\sigma + r)\\right) \\der{z}{t}\\\\ &amp;= - \\sigma x^2 + \\sigma xy -xyz + rxy - y^2 + xyz - bz\\^2 - (\\sigma + r)xy +bz(\\sigma +r)\\\\ &amp;= -\\sigma x^2 - y^2 -bz^2 + bz(\\sigma + r) \\end{align*}\\] Notice that \\(-\\sigma x^2 - y^2 -bz^2\\) is negative. Since we are thinking about convergence towards a sphere, our analysis is helped by considering spherical coordinates: \\(R^2 = x^2 + y^2 + z^2\\), \\(x = R \\sin \\theta \\cos \\phi\\), \\(y= R \\sin \\theta \\sin \\phi\\) and \\(z = R \\cos \\theta\\) (\\(R\\) is the line from the origin to the point \\((x,y,z)\\), \\(\\theta\\) is the angle from the positive \\(z\\) axis to the line from the origin to the point \\((x,y,z)\\), \\(R \\sin \\theta\\) is the the projection of the line in the \\(x,y\\) plane, \\(\\phi\\) is the angle (clockwise) from the positive \\(x\\)-axis to the projected line). Set \\(d := \\min \\{\\sigma, 1, b\\}\\). Then \\[\\begin{align*} \\der{\\v{E}}{t} &amp;\\le -d(x^2 + y^2 + z^2) + bz (\\sigma + r) = -dR^2 +b \\cos\\theta R (\\sigma +r)\\\\ &amp; \\le -R (dR - b(\\sigma + r)) \\end{align*}\\] Therefore \\(\\der{\\v{E}}{t}&lt;0\\) when \\(dR -b (\\sigma + r) &gt;0\\). Hence, for \\(R&gt; \\frac{-b(\\sigma + r)}{d}\\), \\(\\der{\\v{E}}{t}&lt;0\\). This means that all solutions outside the sphere of radius \\(R = \\frac{-b(\\sigma + r)}{d}\\) move towards the sphere and eventually enter the sphere. All solutions inside the sphere cannot leave it (the sphere is in a potential well). 10.1.1 Lyapunov Exponents in Flows Recall the definition of the Lyapunov exponent (5.3). We can extend this definition to orbits of continuous time dynamical system using the flow \\(\\v{F}(t, \\v{x})\\) of the differential equation governing the system. We define the Lyapunov number and exponent of an orbit as the Lyapunov number of the time-1 flow \\(\\v{F}_{1}(\\v{x})\\). Recall that the time-1 map of the flow gives rise to a dynamical system defined by the rule: \\[\\v{x}_{n+1} = \\v{F}_{1}(\\v{x}_{n}) = \\v{F}(1, \\v{x}_{n}).\\] We can therefore apply Definition 5.3 using \\(\\v{F}_{1}\\) to define Lyapunov numbers and exponents of an orbit of a continuous time dynamical system. For the the Lorenz dynamical system, one can show that a typical orbit has one positive Lyapunov exponent which is approximate \\(0.905\\). Now that we have the definition of Lyapunov numbers for continuous time dynamical system, then we can give a precise definition of a chaotic orbit. Definition 10.1 Consider a dynamical system governed by the rule \\(\\der{\\v{x}}{t} = \\v{R}(\\v{x})\\) and with flow \\(\\v{F}_{t}(\\v{x})\\). Let \\(\\v{x}_{0} \\in \\R^{n}\\). The orbit \\(\\v{F}(t, \\v{x}_{0})\\) is called chaotic if the following things hold: The orbit \\((\\v{F}(t, \\v{x}_{0}))_{t \\ge 0}\\) is bounded (it is not in the basin of infinity.) The orbit \\(\\v{F}(t, \\v{x}_{0})\\) has one positive Lyapunov exponent. (Sensitivity to initial conditions) The \\(\\omega\\)-limit set \\(\\omega(\\v{x}_{0})\\) of \\(\\v{x}_{0}\\) is not periodic and does not consist only of equilibria (or equilibria and connecting arcs). (non-periodicity). A typical chaotic attractor of the Lorenz system is shown in Figure 10.1. It has positive Lyapunov exponent and is not asymptotically periodic. Figure 10.1: Rotated views of the Lorenz chaotic attractor r=28, sigma=10, b=8/3 Computation estimates give the Lyapunov numbers \\(L_i\\) and Lyapunov exponents \\(h_i\\) of the above attractor as: \\[\\begin{align*} &amp;h_1 \\simeq 0.905 \\pm 0.005; \\qquad L1 \\simeq 2.47 \\\\ &amp;h_2 \\simeq 0.0; \\quad \\qquad \\qquad \\quad \\ \\ L2 \\simeq 1 \\\\ &amp;h_3 \\simeq -14.57 \\pm 0.01; \\quad \\ \\ L_3 \\simeq 0.00000047 \\end{align*}\\] The distance between orbits of initial values that start of quite close together on the chaotic attractor increases by a factor of \\(\\simeq 2.47\\) per time unit. Let us examine Figure 10.1. The existence of a chaotic attractor in the orbit displayed is numerically implied by the fact that almost any initial condition in a close vicinity of the set displayed gives rise to a similar plot. Which suggests robustness. A trajectory appears to initially to spiral around one equilibrium \\(C_{+}\\) or \\(C_{-}\\) with increasing amplitude. Once the distance of the trajectory from the equilibrium exceeds a critical distance, the trajectory spirals about the other equilibrium with increasing amplitude until the critical distance is again exceeded and the process repeats. 10.1.2 Bifurcation (Chapter 11 of (Alligood, Sauer, and Yorke 2000)) In the last few sections we return to the idea of bifurcation. We encountered the phenomenon of bifurcation early on in the module (see Subsection 2.2). Qualitatively, for a given dynamical system bifurcation points are points in the parameter space at which qualitative change in the dynamics occur. Consider a system of ODE’s \\(\\der{\\v{x}}{t} = \\v{R}(\\v{x}, a)\\) where \\(a\\) is a parameter. Let \\(\\v{x}_{e}(a)\\) be an equilibrium of the system (typically this will depend on the parameter value \\(a\\)). Stability of \\(\\v{x}_{e}(a)\\) depends on the real part of the eigenvalues of the Jacobian of \\(\\v{R}\\) at the \\(\\v{x}_{e}\\). Again these typically depend on the parameter \\(a\\). For values of \\(a\\) for which the real part of the eigenvalues are negative, the equilibrium \\(\\v{x}_{e}(a)\\) is stable; for values of \\(a\\) for which the real part of at least one of the eigenvalues is positive, \\(\\v{x}_{e}(a)\\) is unstable. Therefore we have a bifurcation occurring at the parameter point at which the equilibrium moves from stability to instability (or vice versa). 10.2 Bifurcation The aim of this section is to try to understand the ways in which bifurcation can occur. Therefore as opposed to studying a fixed dynamical system we shall study how a parametrised dynamical system changes as its parameter values change. We will see that there are a limited number of ways the dynamics can change. Let us give a few more definitions to enrich our discussion. Definition 10.2 A bifurcation value is a parameter value at which the number or stability of fixed/periodic points/orbits changes. The orbit/fixed point itself is called a bifurcation orbit/bifurcation point. There are two basic types of bifurcation (we discuss a few more in Subsection 10.3): Saddle-node : fixed points emerge Period doubling : a fixed point loses stability and a new orbit of double period is born. Both of these behaviours occur in discrete dynamical systems corresponding to 1D maps. (For instance we encountered period-doubling bifurcation in the logistic map in Section 2.2.) 10.2.1 Saddle-node bifurcation Let \\(f_{a}(x) = a-x^2\\) be a 1D map with a single (real) parameter \\(a\\). The map has no fixed points for \\(a &lt; -1/4\\). When \\(a = -1/4\\), there is a fixed point at \\(x = -1/2\\) and when \\(a&gt; -1/4\\), there are two fixed points: \\[ x_{\\pm}= \\frac{-1 \\pm \\sqrt{1+ 4a}}{2}.\\] Figure 10.2: A saddle-node bifurcation The point \\(a =-1/4\\) is a bifurcation value and \\(-1/2\\) is a bifurcation point. The case in which a pair of fixed points emerge in a region where there were none, as \\(a\\) is varied, is called a saddle-node bifurcation. At a saddle-node bifurcation, 2 fixed points emerge – one stable and one unstable – as \\(a\\) is increased. The unstable point is a saddle and the stable fixed point is an attractor or ‘node’, hence the terminology “saddle-node”. Figure 10.3: Bifurcation diagram of a saddle-node bifurcation In Figure 10.3 we have plotted the fixed points of the map \\(f_{a}\\) as a function of \\(a\\). The solid curve represents attracting fixed points (sinks) and the dotted regions are repelling fixed points (sources). The highlighted points \\((-1/4, -1/2)\\) and \\((3/4,1/2)\\) are respectively the location of the saddle-node and period doubling bifurcation. At \\(a = 3/4\\), the fixed point at \\(1/2\\) becomes unstable and a period \\(2\\) orbit emerges. For a just above \\(3/4\\) one point in the period \\(2\\) orbit is larger than \\(1/2\\) and the other point is less than \\(1/2\\) — a period doubling bifurcation. Of course, period-2 points are fixed points of \\(f_{a}^2\\) (Definition 2.1) and so we gain more insight about the period \\(2\\) orbits by plotting the graph \\(f_{a}^2\\) (see Figure 10.4). Figure 10.4: A saddle-node bifurcation Figure 10.4 shows plots of \\(f_{a}^2\\) for \\(a = 0.5, 0.75\\) and \\(a-1\\). The point \\(a=0.5\\) is just before bifurcation occurs. At \\(a=0.75\\), there is a fixed point (of \\(f_{a}^2\\); a period-2 point of \\(f_{a}\\)) at the tangent. For \\(a&gt;0.75\\), a new dynamic emerges — there are now \\(3\\) non-negative fixed points of \\(f_{a}\\): a flip repeller of \\(f_a\\) followed surrounded by a period-2 attractor of \\(f_{a}\\). Figure 10.5: Bifurcation diagram of a saddle-node bifurcation In Figure 10.5 we have plotted the period-2 and fixed points of \\(f_a\\) as a function of \\(a\\). The solid curves are attracting fixed/period-2 points; the dotted curves are repelling fixed/period-2 points. The circled points are the regions where bifurcation occurs. At \\(a = 5/4\\) a further period-doubling bifurcation occurs and a period-4 sink emerges. 10.3 More types of Bifurcations In the previous Subsection we introduced two basic types of bifurcations — saddle-node bifurcations (a pair of fixed points, one stable and one unstable, emerge) and period doubling bifurcations (a new orbit of double period emerges). We continue our discussion of bifurcations in this lecture by considering more ways in which they can arise. Transcritical bifurcations This type of bifurcation is a basic mechanism by which fixed points change stability as the parameter is varied. For example consider the map \\(f_{r} = rx - x^2\\) and the continuous time dynamical system \\(\\der{x}{t} = f_{r}(x)\\). There are equilibria at \\(x =0\\) and \\(x =r\\). As \\(r\\) is varied the stability of these equilibrium points change. See Figure 10.6 Figure 10.6: Plot of fr for varying values of r When \\(r&lt;0\\), the non-zero equilibrium is unstable while the \\(0\\) equilibrium is stable. When \\(r =0\\), the two equilibria coincide to a single equilibrium at \\(x=0\\) which is unstable. When \\(r&gt;0\\), the equilibrium at \\(0\\) becomes unstable and the non-zero equilibrium is stable. Figure 10.7 plots the equilibrium points of \\(\\der{x}{t} = f_{r}(x)\\) as a function of \\(r\\). The dotted lines are unstable equilibria and the solid lines are the stable equilibria. This is an example of a transcritical bifurcation diagram. Figure 10.7: Plot of fr for varying values of r We use the stability test for continuous time dynamical systems to determine the stability of the respective fixed points. That is, we compute the Jacobian of \\(f_{r}\\) at the fixed points — this is simply the derivative of \\(f_{r}\\) at \\(x=r\\) and \\(x=0\\). we have \\[ f&#39;(0) =r \\qquad \\text{and} \\qquad f&#39;(r) = -r.\\] For \\(r&lt;0\\), \\(0\\) is unstable (the real part of the eigenvalue of the Jacobian of \\(f\\) at \\(0\\) is simply \\(r\\) which is negative); \\(0\\) is stable for \\(r&gt;0\\). The opposite is true of the equilibrium point at \\(x=r\\) — it is unstable when \\(r&gt;0\\) and stable when \\(r&lt;0\\). Therefore, as \\(r\\) is varied, the equilibrium points \\(x\\) and \\(r\\) simply interchange stability properties. Note that unlike the saddle-node case, the equilibrium points do not disappear. Pitch-fork bifurcation This type of bifurcation generally occurs in systems with symmetry and involves fixed/equilibrium points that emerge and vanish in symmetrical pairs. Consider a continuous time dynamical system governed by the rule: \\[ \\der{x}{t} = rx - x^3 = f_{r}(x). \\] The equilibrium points of the system occur when \\(x=0\\) and \\(x_{\\pm} = \\pm \\sqrt{r}\\); note that for \\(r\\le0\\) only one equilibrium point exists. For \\(r&gt;0\\) two additional fixed points emerge and so \\(r=0\\) is a bifurcation value and \\(0\\) is a bifurcation point. We investigate stability of the equilibria by computing the derivative at the equilibria. For \\(x = 0\\), \\(f_{r}&#39;(0) = r\\). therefore \\(0\\) is stable when \\(r&lt;0\\) and unstable when \\(r&gt;0\\). For \\(x = \\pm \\sqrt{r}\\); \\(f_{r}&#39;(x_{\\pm}) = -2r\\). Therefore the equilibria \\(x_{\\pm}\\) are stable when \\(r&gt;0\\) and unstable when \\(r&lt;0\\). Figure 10.8: Plot of f for different parameter values. The bifurcation diagram is as in Figure 10.9. We continue with the convention that solid curves represent stable equilibria and dotted curves unstable equilibria. Note that the diagram resembles a pitch-fork. The “branches” of the pitch-fork are to the right of the bifurcation/critical point — this is called a super-critical bifurcation. Figure 10.9: Bifurcation diagram of a pitchfork bifurcation The other situation that can arise is when the branches are to the left of the critical point (see Figure 10.10). Notice that the stability behaviour is the inverse of the super-critical pitchfork bifurcation in Figure 10.9. This type of bifurcation, where the branches are to the left of the critical point is called a sub-critical bifurcation. Figure 10.10: Bifurcation diagram of a pitchfork bifurcation An example of a sub-critical bifurcation is the dynamical system governed by the ODE \\(\\der{x}{t} = ax + x^3\\). Further examples can be found in Chapter 11 of (Alligood, Sauer, and Yorke 2000): a transcritical example is given in Example 11.4 and a pitchfork example in Example 11.5. Note that these examples are for discrete dynamical systems associated to 1D maps and so the stability of the fixed points are determined by the modulus of the derivative at the fixed point (see Subsection 2.1). 10.4 Problem Sheet 10 For Week 11. Question 10.1 Consider the Lorenz equations \\[\\begin{align} &amp;\\der{x}{t} = \\sigma(y-x) \\tag{10.4} \\\\ &amp;\\der{y}{t} = rx -y -xz \\tag{10.5} \\\\ &amp;\\der{z}{t} = -bz + xy \\tag{10.6} \\end{align}\\] with \\(r,b, \\sigma\\) positive real parameters. We have seen (Sheet 8) that the equilibria of the Lorenz equations are: \\[ (0,0,0)\\] and \\[ x_{\\pm} = y_{\\pm} = \\pm \\sqrt{b(r-1)}, z_{\\pm} = r-1. \\] We have seen (Sheet 8, Sheet 9) that the equilibrium \\((0,0,0)\\) is stable when \\(r \\le 1\\) and unstable for \\(r&gt;1\\). Show that for \\((x{\\pm}, y_{\\pm}, z_{\\pm})\\) the characteristic equation for the eigenvalues \\(\\lambda\\) of the Jacobian matrix \\(\\jacobr(x_{\\pm}, y_{\\pm}, z_{\\pm})\\) at the equilibrium point is \\[ \\lambda^3 + (\\sigma + b + 1) \\lambda^2 + (r+ \\sigma)b \\lambda + 2\\sigma b(r-1) =0. \\] The non-zero equilibria becomes unstable at the value of \\(r\\) at which the real part of at least one eigenvalue vanishes. By seeking solutions of the form \\(\\lambda = i w\\) (\\(w\\) a real variable), show that there is a pair of purely imaginary eigenvalues when \\[ r = r_{u} = \\sigma \\left( \\frac{\\sigma + b + 3}{\\sigma - b - 1} \\right). \\] Why do we need to assume that \\(\\sigma &gt; b+1\\) for this result to be meaningful. Show Solution 10.1 Solution 10.1 The Jacobian matrix \\(\\jacobr(x,y,z)\\) is: \\[ \\jacobr(x,y,z) = \\begin{pmatrix} -\\sigma &amp; \\sigma &amp; 0 \\\\ r-z &amp; -1 &amp; -x \\\\ y &amp; x &amp; - b \\end{pmatrix}. \\] At \\((x_{\\pm}, y_{\\pm}, z_{\\pm})\\), \\[ \\jacob(x_{\\pm}, y_{\\pm}, z_{\\pm}) = \\begin{pmatrix} -\\sigma &amp; \\sigma &amp; 0 \\\\ 1 &amp; -1 &amp; \\mp \\sqrt{b(r-1)} \\\\ \\pm \\sqrt{b(r-1)} &amp; \\pm \\sqrt{b(r-1)} &amp; -b \\end{pmatrix}. \\] The characteristic equation is therefore given by \\[\\begin{align} &amp;(\\lambda + \\sigma) \\left( \\lambda^2 + (b+1) \\lambda + br \\right) + \\sigma (-\\lambda - 2b + br) = \\nonumber \\\\ &amp;\\lambda^3 + \\lambda^2 ( b+1 + \\sigma) + \\lambda (br - \\sigma + \\sigma(b+1)) \\nonumber \\\\ &amp;+ \\sigma br -2b \\sigma + br \\sigma = \\nonumber \\\\ &amp;\\lambda^3 + \\lambda^2 (b+\\sigma +1) + \\lambda b (\\sigma + r) + 2\\sigma b(r-1) = 0. \\tag{10.7} \\end{align}\\] Substituting \\(\\lambda = i \\omega\\) into Equation (10.7) and equating real and imaginary parts we have: \\[\\begin{align} &amp;-w^2(b+ \\sigma +1) + 2\\sigma b(r-1) = 0 \\tag{10.8} \\\\ &amp;-w^3 + w b(\\sigma + r)= 0 \\tag{10.9} \\end{align}\\] If \\(w = 0\\), then \\(r =1\\), however we need \\(r &gt; 1\\) for the non-zero fixed points. Therefore, assume that \\(w \\ne 0\\). In this case Equations (10.8) and (10.9) imply that: \\[ b(\\sigma + r) = \\frac{2\\sigma b(r-1)}{b + \\sigma + 1 }. \\] Rearranging to get an expression for \\(r\\) in terms of \\(\\sigma\\) and \\(\\beta\\) gives: \\[\\begin{align*} r &amp;= \\frac{b\\sigma(3 + b + \\sigma)}{b(\\sigma -b -1)} \\\\ &amp;= \\frac{\\sigma(3 + b + \\sigma)}{\\sigma -b -1} = r_u. \\end{align*}\\] By assumption \\(\\sigma, b\\) and \\(r\\) are positive constants, and so we require \\(\\sigma &gt; b+1\\) in order to have \\(r_u &gt;0\\). Question 10.2 For each of the systems below sketch the bifurcation diagrams of the equilibrium points \\(x_{e}\\) as functions of \\(r\\) and classify the bifurcations you find. \\(\\der{x}{t} = rx + x^2\\), \\(\\der{x}{t} = rx - \\sinh x\\), \\(\\der{x}{t} = r - \\cosh x\\). Show Solution 10.2 Solution 10.2 The equilibria are given by \\(x=0\\) and \\(x = -r\\). This is a transcritical bifurcation (see Figure 10.11). The fixed point at \\(x = 0\\) is stable for \\(r&lt;0\\) and unstable for \\(r&gt;0\\) since \\(\\der{R}{t}(0) =r\\). The fixed point at \\(x= -r\\) is unstable for \\(r&lt;0\\) and stable for \\(r&gt;0\\) since \\(\\der{R}{t}(-r) = -r\\). Figure 10.11: Bifurcation Sketch i. From Figure 10.12 there are three equilibria when \\(r\\ge 1\\) and \\(1\\) when \\(r &lt;1\\). This gives a bifurcation diagram as in Figure 10.14 — a pitchfork bifurcation. The equilibrium at \\(0\\) is stable for \\(r&lt;1\\) and unstable for \\(r&gt;1\\) since \\(\\der{R}{t} = r -1\\). The other equilibria can be investigated by plotting the graph \\(rx - \\sinh(x)\\) for \\(r&gt;1\\). From figure 10.13 we see that for \\(r&gt;1\\) the non-zero equilibria are stable. Figure 10.12: Equilibria sketch ii. Figure 10.13: Stability sketch ii. Figure 10.14: Bifurcation sketch ii. In this case the equilibria are \\(x_{\\pm} = \\cosh^{-1}r = \\ln(r \\pm \\sqrt{r^2 -1})\\). This has solutions only when \\(r&gt; 1\\) in which case there are \\(2\\) solutions for \\(r&gt;1\\) and \\(1\\) when \\(r =1\\) — a saddle-node bifurcation. The positive equilibrium in stable since \\(\\der{R}{t}(x_{+}) = 1- r - \\sqrt{r^2 -1} &lt;0\\) for \\(r&gt;1\\). The negative equilibrium is unstable since \\(\\der{R}{t} = 1 -\\frac{1}{r + \\sqrt{r^2 -1}} &gt;0\\). Figure 10.15: Bifurcation sketch iii. References "],["revision.html", "Chapter 11 Revision Guide 11.1 General advice 11.2 What to Learn", " Chapter 11 Revision Guide The aim of this section is to provide some guidance on what you should focus on when revising for the exam. Note that this is not a comprehensive guide, and you should utilise this more as a prompt than anything else. 11.1 General advice The exam will only assess material that has been covered in lectures and tutorials. In light of this, the following actions are a good way to revise: Learn the statements of definitions and theorems. Make sure you understand all worked examples: those covered in lectures, those in the lecture notes and those in the form of mini-quizzes which began lectures (see the lecture slides). Go over tutorial questions and make sure you understand the solutions. Go over past exams (these can be found on the exams archive here). Note that solutions are not always provided and past exams might assess slightly different material, that said, most of the questions should be accessible. If in doubt do feel free to send me an email fo55@st-andrews.ac.uk. If, having done all the actions above, you still require additional practice, then you can also attempt the exercises in the recommended textbook (Alligood, Sauer, and Yorke 2000). Beneath each chapter heading in the lecture notes is a description of the relevant section of (Alligood, Sauer, and Yorke 2000) that portion of the notes corresponds to. Attempt all questions that you can (i.e relative to the material that was covered in Lectures) in the relevant section of the textbook. A final tip — the html version of the notes is searchable. Click on the little magnifying glass icon and type in the dialogue box that appears a word or phrase and the chapters/sections in which the word or phrase appears will be listed. 11.2 What to Learn Maps Definitions of fixed points (sources, sinks, saddles) and periodic orbits (1D and nD). Linear stability of fixed and periodic points in 1D and nD . Know how to compute the Jacobian matrix and its eigenvalues at the fixed points, and the relevant stability criteria. Basic understanding of period doubling bifurcation. Definition of stable and unstable manifolds of saddle points and how to compute them. Sensitive dependence on initial conditions. Definition of Lyapunov numbers and exponents (1D and nD). Definition of chaotic orbits (1D and nD) Simple examples demonstrating how to calculate Lyapunov numbers/exponents and illustrating maps with chaotic orbits. Definitions of the box-counting and correlation dimensions and how to compute these for simple fractal sets. Stretching and folding as illustrated by Smale’s horseshoe map. Definition of Chaotic attractors. Continuous time dynamical systems Rewriting higher order and/or non-autonomous systems in normal form: that is as a system of 1st order autonomous ODEs. Definitions of the flow of an ODE and the time-\\(T\\) map. Equilibria and linear stability (Jacobian matrix, eigenvalues and stability criteria). Definition of Lyapyunov functions (strict and non-strict) and the implication of the existence of such functions for stability. How to calculate \\(\\der{E}{t} = \\v{R} \\cdot \\nabla E\\). Definition of limit cycles. Use of polar coordinates for 2D systems. Use of time-\\(T\\) maps to investigate stability of cycles. Properties of the Lorenz equations. Definition of dissipative systems. Common types of bifurcations (saddle-node, pitchfork and transcritical). The End References "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
